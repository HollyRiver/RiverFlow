[
  {
    "objectID": "posts/R Programming/Economatrics_hw2.html",
    "href": "posts/R Programming/Economatrics_hw2.html",
    "title": "강신성(202014107).html",
    "section": "",
    "text": "————————————————homework 2————————————————"
  },
  {
    "objectID": "posts/R Programming/Economatrics_hw2.html#we-learned-the-following-r-code-in-class.-answer-the-following-questions-using-this-code.",
    "href": "posts/R Programming/Economatrics_hw2.html#we-learned-the-following-r-code-in-class.-answer-the-following-questions-using-this-code.",
    "title": "강신성(202014107).html",
    "section": "We learned the following R code in class. Answer the following questions using this code.",
    "text": "We learned the following R code in class. Answer the following questions using this code.\n————————example: Scatter Plot————————\n\nn&lt;-1000\nx&lt;-4+rnorm(n,mean=1,sd=5)\ny&lt;-1+2*x+rnorm(n,mean=0,sd=4)\n\ndev.new()\nplot(x,y, pch=16, col=\"blue\", \n     main=expression(paste(\"Sampling under \", beta[0], \n                           \"=1\", \" \", \"and\", \" \", beta[1], \"=2\")))\ntext(10, 2, \"scatter plot\", cex=1.5)\nabline(a=1,b=2, col=\"red\", lwd=3)\n\n\n\nquestion 1: Compute the mean values of x and y using “for loop”!\nDo not use built-in functions!!!\n\n평균을 내주는 함수 : mean_values() 정의\n\n\nmean_values &lt;- function(values) {\n  output &lt;- 0\n  \n  for (i in values) {\n    output &lt;- output + i\n  }\n\n  output / length(values)   ## 평균을 구하기 위해 자료의 수(length)로 나누어준다.\n}\n\nmean_values(x)   ## x의 평균을 계산\n\n[1] 5.063285\n\nmean_values(y)   ## y의 평균을 계산\n\n[1] 11.18455\n\n\n\n\nquestion 2: Compute the covariance between x and y using “for loop”!\nDo not use built-in functions!!!\n\n공분산을 내주는 함수 : cov_values() 정의\n\n\ncov_values &lt;- function(data_1, data_2) {\n  x_diff &lt;- data_1 - mean_values(data_1)   ## 위에서 정의했던 함수 \"mean_values()\" 사용\n  y_diff &lt;- data_2 - mean_values(data_2)\n\n  xy_product &lt;- x_diff * y_diff\n  \n  product_sum &lt;- 0\n  \n  for (i in xy_product) {\n    product_sum &lt;- product_sum + i\n  }\n  \n  cov = product_sum / length(xy_product)\n  \n  cov\n}\n\ncov_values(x,y)   ## output\n\n[1] 47.40633\n\n\n\n\nquestion 3: Compute the variance x using “for loop”!\nDo not use built-in functions!!!\n\n분산을 내어주는 함수 : var_values() 정의\n\n\nvar_values &lt;- function(values) {\n  x_diff_sq &lt;- (values - mean_values(values))^2   ## 위에서 정의했던 함수 \"mean_values()\" 사용하여 차의 제곱 행렬 생성\n  \n  sum_x_sq &lt;- 0\n  \n  for (i in x_diff_sq) {\n    sum_x_sq &lt;- sum_x_sq + i\n  }\n  \n  var_x &lt;- sum_x_sq / length(values)  ## 자료의 수로 나누어 분산 산출\n  \n  var_x\n}\n\nvar_values(x)     ## output\n\n[1] 23.59972\n\n\n\n\nquestion 4: Compute the parameter beta[1] (slope of the regression line)!\n\n최소제곱법으로 beta[1]의 값을 추정해보자\n\n\nbeta_1_hat &lt;- cov_values(x, y) / var_values(x)  ## 위에서 정의한 함수를 사용 : x와 y의 공분산 / x의 분산\n\nbeta_1_hat  ## output\n\n[1] 2.008767"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html",
    "href": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html",
    "title": "Kaggle | 결측치의 처리",
    "section": "",
    "text": "Titanic 데이터에는 결측치가 상당히 많았는데, 그것을 처리해서 분석해보자."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#라이브러리-imports",
    "title": "Kaggle | 결측치의 처리",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\n#!pip install missingno\n\nimport pandas as pd\nimport numpy as np\nimport sklearn.impute\nimport sklearn.linear_model\nimport matplotlib.pyplot as plt\nimport missingno as msno"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#데이터-불러오기",
    "href": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#데이터-불러오기",
    "title": "Kaggle | 결측치의 처리",
    "section": "2. 데이터 불러오기",
    "text": "2. 데이터 불러오기\n\n#!kaggle competitions download -c titanic\n#!unzip titanic.zip -d ./titanic\n#df_train = pd.read_csv('titanic/train.csv')\n#df_test = pd.read_csv('titanic/test.csv')\n#!rm titanic.zip\n#!rm -rf titanic/\n\n## 리눅스 서버가 구축되어 있다면 데이터를 바로 불러오기가 편리하다.\n\n\ndf_test = pd.read_csv('./data/test.csv')\ndf_train = pd.read_csv('./data/train.csv')"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#결측치-확인-및-처리",
    "href": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#결측치-확인-및-처리",
    "title": "Kaggle | 결측치의 처리",
    "section": "3. 결측치 확인 및 처리",
    "text": "3. 결측치 확인 및 처리\n결측치 확인\n\ndf_train.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n시각화\n\nmsno.matrix(df_train)\n\n&lt;Axes: &gt;\n\n\n\n\n\n결측치 처리\n\n수치형은 수치형끼리, 범주형은 범주형끼리 처리하자.\n\n\ndf_imputed = df_train.copy()\n\ntrain_num = df_train.select_dtypes(include = 'number')\ntrain_obj = df_train.select_dtypes(exclude = 'number')\n\ndf_imputed[train_num.columns] = sklearn.impute.SimpleImputer(strategy = 'mean').fit_transform(train_num)\ndf_imputed[train_obj.columns] = sklearn.impute.SimpleImputer(strategy = 'most_frequent')\n\ndf_imputed.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    float64\n 1   Survived     891 non-null    float64\n 2   Pclass       891 non-null    float64\n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          891 non-null    float64\n 6   SibSp        891 non-null    float64\n 7   Parch        891 non-null    float64\n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        891 non-null    object \n 11  Embarked     891 non-null    object \ndtypes: float64(7), object(5)\nmemory usage: 83.7+ KB\n\n\n\n결측치가 완전히 메꿔진 것을 확인할 수 있다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#분석",
    "href": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#분석",
    "title": "Kaggle | 결측치의 처리",
    "section": "4. 분석(?)",
    "text": "4. 분석(?)\n늘 해왔던 것처럼…\n\nset(df_train.columns) - set(df_test.columns)\n\n{'Survived'}\n\n\n\nSurvived : 반응변수\n\n- 근데 몇 번 결측치 처리를 반복해야 하므로 위에서의 과정을 함수로 만들어버리자.\n\ndef impute_missing(df):\n    \"\"\"\n    imputing missing and output whole dataframe\n    \n    df : DataFrame include NaN value\n    \"\"\"\n    df_ = df.copy()  ## 데이터를 복사\n    \n    df_num = df_.select_dtypes(include = 'number')  ## 해당하는 데이터 타입만 선택\n    df_obj = df_.select_dtypes(exclude = 'number')\n    \n    df_[df_num.columns] = sklearn.impute.SimpleImputer(strategy = 'mean').fit_transform(df_num)\n    df_[df_obj.columns] = sklearn.impute.SimpleImputer(strategy = 'most_frequent').fit_transform(df_obj)\n    \n    return df_\n\n\npd.get_dummies(impute_missing(df_train.drop(['Survived'], axis = 1)))\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nAge\nSibSp\nParch\nFare\nName_Abbing, Mr. Anthony\nName_Abbott, Mr. Rossmore Edward\nName_Abbott, Mrs. Stanton (Rosa Hunt)\nName_Abelson, Mr. Samuel\n...\nCabin_F G73\nCabin_F2\nCabin_F33\nCabin_F38\nCabin_F4\nCabin_G6\nCabin_T\nEmbarked_C\nEmbarked_Q\nEmbarked_S\n\n\n\n\n0\n1.0\n3.0\n22.000000\n1.0\n0.0\n7.2500\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1\n2.0\n1.0\n38.000000\n1.0\n0.0\n71.2833\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n2\n3.0\n3.0\n26.000000\n0.0\n0.0\n7.9250\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n3\n4.0\n1.0\n35.000000\n1.0\n0.0\n53.1000\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n4\n5.0\n3.0\n35.000000\n0.0\n0.0\n8.0500\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n887.0\n2.0\n27.000000\n0.0\n0.0\n13.0000\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n887\n888.0\n1.0\n19.000000\n0.0\n0.0\n30.0000\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n888\n889.0\n3.0\n29.699118\n1.0\n2.0\n23.4500\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n889\n890.0\n1.0\n26.000000\n0.0\n0.0\n30.0000\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n890\n891.0\n3.0\n32.000000\n0.0\n0.0\n7.7500\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n\n\n891 rows × 1730 columns\n\n\n\n\n늘 그랬던 것처럼 get_dummies를 해줬는데… 뭔가 이상하다.\n\n\npd.get_dummies(impute_missing(df_train.drop(['Survived'], axis = 1))).shape\n\n(891, 1730)\n\n\n행이 1730개??? &gt; 이러한 상황에서는 선형 모델이 제대로 작동하지 않는다…!\n\n# step 1\nX = pd.get_dummies(impute_missing(df_train.drop(['Survived'], axis = 1)))\ny = df_train.Survived\nXX = pd.get_dummies(impute_missing(df_test))\n\n# step 2\npredictr = sklearn.linear_model.LogisticRegression()\n\n# step 3\npredictr.fit(X, y)\n\n# step 4\npredictr.predict(XX)\n\nC:\\Users\\hollyriver\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\nValueError: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Cabin_A11\n- Cabin_A18\n- Cabin_A21\n- Cabin_A29\n- Cabin_A9\n- ...\nFeature names seen at fit time, yet now missing:\n- Cabin_A10\n- Cabin_A14\n- Cabin_A16\n- Cabin_A19\n- Cabin_A20\n- ...\n\n\n\n{c:len(set(df_train[c])) for c in df_train.select_dtypes(include=\"object\").columns}\n\n{'Name': 891, 'Sex': 2, 'Ticket': 681, 'Cabin': 148, 'Embarked': 4}\n\n\n\n형식이 object인 것들이 가지고 있는 유니크한 값들이 몇개인지를 딕셔너리 컴프리헨션 해봤다.\n\n\n사실상 해당 수가 엄청나게 많은 Name, Ticket, Cabin의 경우 없애는 편이 더 좋아보인다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#진짜-분석",
    "href": "posts/Machine Learning in Practice/Titanic/4. 로지스틱_결측치 처리.html#진짜-분석",
    "title": "Kaggle | 결측치의 처리",
    "section": "5. 진짜 분석",
    "text": "5. 진짜 분석\n\n## step 1\nX = pd.get_dummies(impute_missing(df_train).drop(['Name', 'Ticket', 'Cabin', 'Survived'], axis = 1))\ny = df_train.Survived\nXX = pd.get_dummies(impute_missing(df_test).drop(['Name', 'Ticket', 'Cabin'], axis = 1))\n\n## step 2\npredictr = sklearn.linear_model.LogisticRegression()\n\n## step 3\npredictr.fit(X, y)\n\n## step 4\ndf_test[['PassengerId']].assign(Survived = predictr.predict(XX))\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\n\n\n\n\n0\n892\n0\n\n\n1\n893\n1\n\n\n2\n894\n0\n\n\n3\n895\n0\n\n\n4\n896\n1\n\n\n...\n...\n...\n\n\n413\n1305\n0\n\n\n414\n1306\n1\n\n\n415\n1307\n0\n\n\n416\n1308\n0\n\n\n417\n1309\n0\n\n\n\n\n418 rows × 2 columns\n\n\n\n\ndf_test[['PassengerId']].assign(Survived = predictr.predict(XX)).to_csv(\"submission\", index = False)\n\n\n이렇게 하면 된다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html",
    "href": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html",
    "title": "Kaggle | Alexis Cook의 코드",
    "section": "",
    "text": "Discussion 탭에서 가장 상위에 있는 안내 자료를 살펴보자."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#라이브러리-import",
    "href": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#라이브러리-import",
    "title": "Kaggle | Alexis Cook의 코드",
    "section": "1. 라이브러리 import",
    "text": "1. 라이브러리 import\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#data-불러오기",
    "href": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#data-불러오기",
    "title": "Kaggle | Alexis Cook의 코드",
    "section": "2. Data 불러오기",
    "text": "2. Data 불러오기\n\ntrain_data = pd.read_csv(\"./data/train.csv\")\ntrain_data.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\ntest_data = pd.read_csv(\"./data/test.csv\")\ntest_data.head()\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#alexis의-코드-forecast",
    "href": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#alexis의-코드-forecast",
    "title": "Kaggle | Alexis Cook의 코드",
    "section": "3. Alexis의 코드 | forecast",
    "text": "3. Alexis의 코드 | forecast\n\nA. Alexis Cook의 분석은 train에서 얼마나 잘 맞출까?\n\n- 원래코드\n\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]  ## 결측치가 많은 것들과 이상한 녀석들을 배제했다.\nX = pd.get_dummies(train_data[features])  ## 변수들 중 범주형 자료를 더미변수로 만든다.\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)  ## 예측값을 담아둔다. predictr.predict(XX)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n##output.to_csv('submission_AlexisCook.csv', index=False)  ##파일을 자꾸 만들어서 주석처리했다.\nprint(\"Your submission was successfully saved!\")\n\nYour submission was successfully saved!\n\n\n\nRandomForestClassifier 모듈을 사용하여 fitting 하였다.\n\n- 간단한 수정\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\n\n####\n\npredictions = model.predict(X)  ## predict를 train data에 실시\n\n\n(predictions == y).mean()\n\n0.8159371492704826\n\n\n\nmodel.score(X, y)\n\n0.8159371492704826\n\n\n\nscore는 모델이 데이터와 맞는 정도를 내준다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#alexis-cook의-코드를-수정해보자",
    "href": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#alexis-cook의-코드를-수정해보자",
    "title": "Kaggle | Alexis Cook의 코드",
    "section": "### Alexis Cook의 코드를 수정해보자!",
    "text": "### Alexis Cook의 코드를 수정해보자!\n- 코드를 수정해보자.\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\n## hyper parameter 조정\nmodel = RandomForestClassifier(n_estimators=5000, max_depth=1000, random_state=1)\nmodel.fit(X, y)\n\n####\n\npredictions = model.predict(X)\n\n\nmodel.score(X, y)\n\n0.8170594837261503\n\n\n\n바꾼 게 더 좋은 것 같은데???\n\n- 이것도 제출 결과로 만들어보자.\n\npredictions = model.predict(X_test)\n\n\npd.read_csv(\"./data/test.csv\")[['PassengerId']].assign(Survived = predictions)#\\\n#.to_csv(\"AlexisCook수정_submission.csv\", index = False)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\n\n\n\n\n0\n892\n0\n\n\n1\n893\n0\n\n\n2\n894\n0\n\n\n3\n895\n0\n\n\n4\n896\n0\n\n\n...\n...\n...\n\n\n413\n1305\n0\n\n\n414\n1306\n1\n\n\n415\n1307\n0\n\n\n416\n1308\n0\n\n\n417\n1309\n0\n\n\n\n\n418 rows × 2 columns\n\n\n\n\nindex를 꼭 누락시켜야 한다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#제출결과의-비교",
    "href": "posts/Machine Learning in Practice/Titanic/2. code-by-alexis-cook.html#제출결과의-비교",
    "title": "Kaggle | Alexis Cook의 코드",
    "section": "4. 제출결과의 비교",
    "text": "4. 제출결과의 비교\n\nhyper parameter를 조정해서 train score는 더 높아졌지만, 실제 test score는 더 낮아졌다.\n\n- overfitting된 경우 둘의 차이가 극명하게 난다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/5. asdf.html",
    "href": "posts/Machine Learning in Practice/practice/5. asdf.html",
    "title": "전처리 | 연속형 자료의 범위 조정",
    "section": "",
    "text": "sklearn.preprocessing을 이용하여 자료의 범위를 전처리해보자."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/5. asdf.html#라이브러리-import",
    "href": "posts/Machine Learning in Practice/practice/5. asdf.html#라이브러리-import",
    "title": "전처리 | 연속형 자료의 범위 조정",
    "section": "1. 라이브러리 import",
    "text": "1. 라이브러리 import\n\nimport pandas as pd\nimport numpy as np\nimport sklearn.preprocessing"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/5. asdf.html#minmaxscaler",
    "href": "posts/Machine Learning in Practice/practice/5. asdf.html#minmaxscaler",
    "title": "전처리 | 연속형 자료의 범위 조정",
    "section": "2. MinMaxScaler",
    "text": "2. MinMaxScaler\n\nA. 모티브\n\n- 예제자료 : 학점, 토익 등이 취업에 미치는 정도\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/MP2023/main/posts/employment.csv').loc[:7,['toeic','gpa']]\ndf\n\n\n\n\n\n\n\n\ntoeic\ngpa\n\n\n\n\n0\n135\n0.051535\n\n\n1\n935\n0.355496\n\n\n2\n485\n2.228435\n\n\n3\n65\n1.179701\n\n\n4\n445\n3.962356\n\n\n5\n65\n1.846885\n\n\n6\n290\n0.309928\n\n\n7\n730\n0.336081\n\n\n\n\n\n\n\n- 모형을 돌려보고 해석한 결과… (sklearn.linear_model.Linear_Regression())\nu = X.toeic*0.00571598 + X.gpa*2.46520018 -8.45433334\nv = 1/(1+np.exp(-u))\nv # 확률같은것임\n그래서… * 토익이 중요해? 아니면 학점이 중요해? * 무엇이 얼만큼 중요해?\n- 모티브 : 토익과 gpa 모두 0~1 사이의 척도로 바꾸면 해석이 쉽지 않을까?"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/5. asdf.html#b.-사용방법",
    "href": "posts/Machine Learning in Practice/practice/5. asdf.html#b.-사용방법",
    "title": "전처리 | 연속형 자료의 범위 조정",
    "section": "### B. 사용방법",
    "text": "### B. 사용방법\n\nclass를 이용, object를 생성하는 방법(이전과 유사한 방법)\n\n\nscalr = sklearn.preprocessing.MinMaxScaler()\n\nscalr.fit(df)\n\nscalr.transform(df)  ## 전처리의 경우에는 transform을 사용한다. .impute.SimpleImputer()에서도 그랬잖아?\n\narray([[0.08045977, 0.        ],\n       [1.        , 0.07772319],\n       [0.48275862, 0.55663499],\n       [0.        , 0.28847292],\n       [0.43678161, 1.        ],\n       [0.        , 0.45907256],\n       [0.25862069, 0.06607128],\n       [0.76436782, 0.07275881]])\n\n\n\n역시 한번에 할 수도 있다.\n\n\nscalr.fit_transform(df)  ## 당연히 원래 자료를 훼손하진 않는다.\n\narray([[0.08045977, 0.        ],\n       [1.        , 0.07772319],\n       [0.48275862, 0.55663499],\n       [0.        , 0.28847292],\n       [0.43678161, 1.        ],\n       [0.        , 0.45907256],\n       [0.25862069, 0.06607128],\n       [0.76436782, 0.07275881]])"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/3. 결측치.html",
    "href": "posts/Machine Learning in Practice/practice/3. 결측치.html",
    "title": "결측치의 처리",
    "section": "",
    "text": "결측치를 시각화해보고, 계산해서 대치(impute)해보기도 하자!"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/3. 결측치.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/practice/3. 결측치.html#라이브러리-imports",
    "title": "결측치의 처리",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\n#!pip install missingno # missingno 라이브러리가 설치되어있지 않을 경우\n\nimport pandas as pd\nimport numpy as np\nimport missingno as msno\nimport sklearn.impute"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/3. 결측치.html#missingno의-활용",
    "href": "posts/Machine Learning in Practice/practice/3. 결측치.html#missingno의-활용",
    "title": "결측치의 처리",
    "section": "2. missingno의 활용",
    "text": "2. missingno의 활용\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/MP2023/main/posts/msno.csv\")\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n0\n0.383420\n1.385096\nNaN\n-0.545132\n-0.732395\n\n\n1\n1.084175\n0.080613\n-0.770527\n-0.272143\n-0.749881\n\n\n2\n1.142778\n1.258419\nNaN\n-0.072007\n-0.440757\n\n\n3\n0.307894\n0.521400\n0.446974\n0.329530\n-1.457388\n\n\n4\n0.237787\n0.132401\n-0.516630\n0.177995\n0.416182\n\n\n...\n...\n...\n...\n...\n...\n\n\n995\n0.041092\n-1.308165\n1.085820\n1.136210\nNaN\n\n\n996\n-1.286358\n1.547987\nNaN\n-0.174334\n-0.579486\n\n\n997\n0.710257\n1.764058\nNaN\n-0.353928\nNaN\n\n\n998\n-1.908729\n-0.804691\nNaN\nNaN\n-0.066739\n\n\n999\n0.650026\n2.206549\nNaN\n-0.919945\nNaN\n\n\n\n\n1000 rows × 5 columns\n\n\n\n\n결측치가 딱봐도 엄청 많아보인다. missingno는 그것을 시각화해준다.\n\n\nmsno.matrix(df)\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n우측 노이즈와 같은 그래프에서 0에 있는 것은 해당 행에 데이터가 하나도 없다는 뜻이고, 5에 있는 것은 다섯개의 데이터가 해당 행에 존재한다는 것이다. 데이터셋이 다섯개니까 그 합이 그래프로 표기된다.\n\n\nmsno.heatmap(df)\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nmsno.dendrogram(df)\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n구조가 비슷한 자료들을 엮어놓는다.\n\n그럼 시각화를 했으니까, 이제 결측치를 처리해야겠지?"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/3. 결측치.html#숫자형-자료의-impute결측치를-대체하는-것",
    "href": "posts/Machine Learning in Practice/practice/3. 결측치.html#숫자형-자료의-impute결측치를-대체하는-것",
    "title": "결측치의 처리",
    "section": "3. 숫자형 자료의 impute(결측치를 대체하는 것)",
    "text": "3. 숫자형 자료의 impute(결측치를 대체하는 것)\n- 주어진 자료\n\nA = [2.1, 1.9, 2.2, np.nan, 1.9]\nB = [0, 0, np.nan, 0, 0]\n\n\ndf = pd.DataFrame({'A' : A, 'B' : B})\ndf\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\n2.1\n0.0\n\n\n1\n1.9\n0.0\n\n\n2\n2.2\nNaN\n\n\n3\nNaN\n0.0\n\n\n4\n1.9\n0.0\n\n\n\n\n\n\n\n\n결측치를 무엇으로 채워주면 좋을까?\n\n\n일단 평균으로 해보면 얼추 맞을 것 같다.\n\n\ndf2 = df\ndf2.loc[3, 'A'] = df2.A.mean()  ## mean과 같은 메소드는 결측치를 반영하지 않는다.\ndf2.loc[2, 'B'] = df2.B.mean()\ndf2\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\n2.100\n0.0\n\n\n1\n1.900\n0.0\n\n\n2\n2.200\n0.0\n\n\n3\n2.025\n0.0\n\n\n4\n1.900\n0.0\n\n\n\n\n\n\n\n- 근데 이게 엄청 많으면 언제 다 일일히 하고 있어? &gt; 자동으로 하려면?\n(방법1) | 평균으로 impute\n\nimputr = sklearn.impute.SimpleImputer()  ## SimpleImputer(strategy = 'mean')\nimputr\n\nSimpleImputer()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SimpleImputerSimpleImputer()\n\n\n\npredictr.fit하는 것처럼 결측치가 있는 열에 적합해야 한다.\n\n\nimputr.fit(df)\n\nSimpleImputer()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SimpleImputerSimpleImputer()\n\n\n\npredictr.predict하는 것처럼 인풋시켜야 한다.\n\n\nimputr.transform(df)\n\narray([[2.1  , 0.   ],\n       [1.9  , 0.   ],\n       [2.2  , 0.   ],\n       [2.025, 0.   ],\n       [1.9  , 0.   ]])\n\n\n\n위에서와 똑같은 결과를 산출했다.\n\n해당 과정은 imputr.fit_transform(df)로 한번에 시행할 수 있다.\n- 만약 평균이 아닌 다른 방식으로 결측치를 대체하고 싶다면…\n(방법 2) | median으로 impute\n\nimputr = sklearn.impute.SimpleImputer(strategy = 'median')\nimputr.fit_transform(df)\n\narray([[2.1  , 0.   ],\n       [1.9  , 0.   ],\n       [2.2  , 0.   ],\n       [2.025, 0.   ],\n       [1.9  , 0.   ]])\n\n\n(방법 3) | 최빈값으로 대체\n\nimputr = sklearn.impute.SimpleImputer(strategy = 'most_frequent')\nimputr.fit_transform(df)\n\narray([[2.1  , 0.   ],\n       [1.9  , 0.   ],\n       [2.2  , 0.   ],\n       [2.025, 0.   ],\n       [1.9  , 0.   ]])\n\n\n(방법 4) | 정해진 상수값으로 대체\n\nimputr = sklearn.impute.SimpleImputer(strategy = 'constant', fill_value = 999)\nimputr.fit_transform(df)\n\narray([[2.1  , 0.   ],\n       [1.9  , 0.   ],\n       [2.2  , 0.   ],\n       [2.025, 0.   ],\n       [1.9  , 0.   ]])"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/3. 결측치.html#범주형-자료의-impute",
    "href": "posts/Machine Learning in Practice/practice/3. 결측치.html#범주형-자료의-impute",
    "title": "결측치의 처리",
    "section": "4. 범주형 자료의 impute",
    "text": "4. 범주형 자료의 impute\n\ndf = pd.DataFrame({'A':['Y','N','Y','Y',np.nan], 'B':['stat','math',np.nan,'stat','bio']})\ndf\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\nY\nstat\n\n\n1\nN\nmath\n\n\n2\nY\nNaN\n\n\n3\nY\nstat\n\n\n4\nNaN\nbio\n\n\n\n\n\n\n\n(방법 1) | 최빈값을 이용\n\nimputr = sklearn.impute.SimpleImputer(strategy = 'most_frequent')\nimputr.fit_transform(df)\n\narray([['Y', 'stat'],\n       ['N', 'math'],\n       ['Y', 'stat'],\n       ['Y', 'stat'],\n       ['Y', 'bio']], dtype=object)\n\n\n(방법 2) | 상수(지정값)로 대체함\n\nimputr = sklearn.impute.SimpleImputer(strategy = 'constant', fill_value = 'G')\nA_ = pd.Series(imputr.fit_transform(df[['A']]).reshape(-1))\nimputr = sklearn.impute.SimpleImputer(strategy = 'constant', fill_value = 'economy')\nB_ = pd.Series(imputr.fit_transform(df[['B']]).reshape(-1))\n\n\npd.concat([A_, B_], axis = 1).set_axis(['A','B'], axis = 1)\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\nY\nstat\n\n\n1\nN\nmath\n\n\n2\nY\neconomy\n\n\n3\nY\nstat\n\n\n4\nG\nbio\n\n\n\n\n\n\n\n\n## 또는\nimputr = sklearn.impute.SimpleImputer(strategy = 'constant', fill_value = 'G')\nA_ = imputr.fit_transform(df[['A']])\nimputr = sklearn.impute.SimpleImputer(strategy = 'constant', fill_value = 'economy')\nB_ = imputr.fit_transform(df[['B']])\n\npd.DataFrame(np.concatenate([A_,B_], axis = 1), columns = ['A','B'])\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\nY\nstat\n\n\n1\nN\nmath\n\n\n2\nY\neconomy\n\n\n3\nY\nstat\n\n\n4\nG\nbio\n\n\n\n\n\n\n\n\n일반적으로 연속형ㆍ숫자형 자료에는 평균, 범주형 자료에는 최빈값으로 대체한다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "",
    "text": "sklearn의 linear_mode.LinearRegression()을 사용하여 선형회귀분석을 해보자!"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#라이브러리-imports",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn.linear_model"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#data",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#data",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "2. Data",
    "text": "2. Data\n\n전주시의 기온 자료\n\n\ntemp = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/temp.csv').iloc[:,3].to_numpy()[:100]\ntemp.sort()   ## 자료를 크기 순서대로 정렬, sort_values()와 비슷하달까...\n\n\ntemp\n\narray([-4.1, -3.7, -3. , -1.3, -0.5, -0.3,  0.3,  0.4,  0.4,  0.7,  0.7,\n        0.9,  0.9,  1. ,  1.2,  1.4,  1.4,  1.5,  1.5,  2. ,  2. ,  2. ,\n        2.3,  2.5,  2.5,  2.5,  2.6,  2.6,  2.9,  3.2,  3.5,  3.5,  3.6,\n        3.7,  3.8,  4.2,  4.4,  4.5,  4.5,  4.6,  4.9,  4.9,  4.9,  5. ,\n        5. ,  5.1,  5.6,  5.9,  5.9,  6. ,  6. ,  6.1,  6.1,  6.3,  6.3,\n        6.4,  6.4,  6.5,  6.7,  6.8,  6.8,  7. ,  7. ,  7.1,  7.2,  7.4,\n        7.7,  8. ,  8.1,  8.1,  8.3,  8.4,  8.4,  8.4,  8.5,  8.8,  8.9,\n        9.1,  9.2,  9.3,  9.4,  9.4,  9.5,  9.6,  9.6,  9.7,  9.8,  9.9,\n       10.2, 10.3, 10.6, 10.6, 10.8, 11.2, 12.1, 12.4, 13.4, 14.7, 15. ,\n       15.2])\n\n\n- 아래와 같은 모형을 가정하자. \\[\\textup{아이스크림 판매량}= 20 ＋ \\textup{온도} × 2.5 × \\textup{오차(운)}\\]\n\n더미 모형 생성\n\n\nnp.random.seed(43052)\neps = np.random.randn(100)*3  ## 오차\nicecream_sales = 20 + temp * 2.5 + eps\n\n\nplt.plot(temp, icecream_sales, 'o')\nplt.show()\n\n\n\n\n\n상기 결과를 관측했다고 생각합시다.\n\n\ndf = pd.DataFrame({'temp' : temp, 'sales' : icecream_sales})\ndf\n\n\n\n\n\n\n\n\ntemp\nsales\n\n\n\n\n0\n-4.1\n10.900261\n\n\n1\n-3.7\n14.002524\n\n\n2\n-3.0\n15.928335\n\n\n3\n-1.3\n17.673681\n\n\n4\n-0.5\n19.463362\n\n\n...\n...\n...\n\n\n95\n12.4\n54.926065\n\n\n96\n13.4\n54.716129\n\n\n97\n14.7\n56.194791\n\n\n98\n15.0\n60.666163\n\n\n99\n15.2\n61.561043\n\n\n\n\n100 rows × 2 columns"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#게임세팅",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#게임세팅",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "3. 게임세팅",
    "text": "3. 게임세팅\n- 편의상 아래와 같은 기호를 도입하자.\n\n(df.temp[0], df.temp[1], … , df.temp[99]) = \\((x_1,x_2,\\dots,x_{100})=(-4.1,-3.7,\\dots,15.2)\\)\n(df.sales[0], df.sales[1], … , df.sales[99]) = \\((y_1,y_2,\\dots,y_{100})=(10.90,14.00, \\dots,61.56)\\)\n\n\n이 자료 \\(\\big\\{(x_i,y_i)\\big\\}_{i=1}^{100}\\)를 바탕으로 어떠한 패턴을 발견하여 새로운 \\(x\\)에 대한 예측값을 알고 싶다 : \\(\\hat{y}\\)\n\nA. 질문\n- 기온이 \\(x = -2.0\\)일 때, 아이스크림을 얼마정도 판다고 보는 게 타당할까?\nB. 답 1\n- \\(x = -2.0\\) 근처의 데이터를 살펴보자.\n\ndf[(-4.0 &lt; df.temp) & (0.0 &gt; df.temp)]\n\n\n\n\n\n\n\n\ntemp\nsales\n\n\n\n\n1\n-3.7\n14.002524\n\n\n2\n-3.0\n15.928335\n\n\n3\n-1.3\n17.673681\n\n\n4\n-0.5\n19.463362\n\n\n5\n-0.3\n20.317853\n\n\n\n\n\n\n\n\n\\(-1.3\\)이 제일 가까운데, 대충 \\(17.67\\) 언저리 아닐까…?\n\n\nA. 산점도와 추세선\n\n- 자료를 바탕으로 그림을 그려보자\n\nplt.plot(df.temp, df.sales, 'o')\nplt.plot([-2.0],[17.67],'x')     # 이미 들어가있는 플롯에 점을 하나 찍는다. 마커는 X\n\nplt.show()\n\n\n\n\n\n예상한 것(17.67)보다 못팔 것 같은데…?"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-아이디어",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-아이디어",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "### B. 아이디어",
    "text": "### B. 아이디어\n- 선을 기가 막히게 그어서 추세선을 만들고, 그 추세선 위의 점으로 예측하자!~(사실 모형을 우리가 만들었으니 이미 추세선을 알고 있긴 함)~\n\nplt.plot(df.temp, df.sales, 'o')\nplt.plot(df.temp, 20+df.temp*2.5, '--')  ## 위에서 직접 설정했던 자료의 관계, 절편이 20이고 기울기가 2.5\n\nplt.show()\n\n\n\n\n- 사실 \\(y = 20 + 2.5x\\)라는 추세선을 이미 알고 있었음.\n- 그래서 \\(x = -2\\)라면 \\(y = 20 - 2.5 × 2 = 15\\)라고 보는 게 합리적임(오차를 고려 안하면)\n\n허나, 실제 상황에서 우리는 \\(20, 2.5\\)라는 숫자를 모른다.\n\n- 게임셋팅 * 원래 게임 : 임의의 \\(x\\)에 대하여 합리적인 \\(y\\)를 잘 찾는 게임 * 변형된 게임 : \\(20, 2.5\\)라는 숫자를 잘 찾는 게임. 즉, 데이처를 보고 최대한 \\(y_i \\approx ax_i+b\\)가 되도록 \\(a, b\\)를 잘 선택하는 게임"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#분석",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#분석",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "4. 분석",
    "text": "4. 분석\n\n그렇다면 늘 했던 것처럼 네 단계로 분석을 해보자.\n\n\nA. 데이터\n\n\n# step 1 -- data\ntrain = pd.DataFrame({'temp' : temp, 'sales' : icecream_sales})\n\nX = train[['temp']]\ny = train['sales']\n\n\n데이터를 학습해서 추세선을 적절히 그릴 수 있고, 그려진 추세선으로 예측까지 해줄 수 있는 아이(predictor)를 만들자.~(근데 이정도면 학생이 아니라 노예…)~"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-predictor",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-predictor",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "### B. predictor",
    "text": "### B. predictor\n\n# step 2\npredictr = sklearn.linear_model.LinearRegression()\n\n\nsklearn의 linear_model.LinearRegression()을 사용했다. 이러면 가장 기본적인 선형회귀를 진행한다.(LSE를 쓰는 그거 있잖아…)\n\n\nC. 학습\n\n\n# step 3\npredictr.fit(X, y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n학생이 train을 완료했다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#d.-예측predict",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#d.-예측predict",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "### D. 예측(predict)",
    "text": "### D. 예측(predict)\n- 학생(predictr) : 데이터를 살펴보니 True는 이럴 것 같아요.\n\ny_hat = predictr.predict(X)  ## X값에 해당하는 y_hat값을 예측하여 산출.\n\n\nplt.plot(X, y, 'o', alpha = 0.5)\nplt.plot(X, y_hat, 'o--', alpha = 0.5)\n\nplt.show()\n\n\n\n\n- 그럼 기울기와 절편은 어디에 저장된 걸까?\n- predictr : 여깄음.\n\n(predictr.coef_, predictr.intercept_)\n\n(array([2.51561216]), 19.66713126947925)\n\n\n- 새로운 데이터 \\(x = -2\\)에 대한 예측\n\nfloat(predictr.coef_)*(-2) + float(predictr.intercept_)\n\n14.63590694951262\n\n\n\n해당 결과값을 그래프에 나타내면…\n\n\nX_input = pd.DataFrame({'temp' : [-2.0]})\n\n\nplt.plot(X, y, 'o', alpha = 0.5)\nplt.plot(X, y_hat, '--', alpha = 0.5)\nplt.plot(X_input, predictr.predict(X_input), 'xr')  ## 원래는 리스트나 어레이로 넣어주는 게 정배긴 함\n\nplt.show()\n\n\n\n\n\n예측값이 직선상에 위치함을 알 수 있다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#두-타입의-아이스크림초코-바닐라에-대한-회귀분석",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#두-타입의-아이스크림초코-바닐라에-대한-회귀분석",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "5. 두 타입의 아이스크림(초코 / 바닐라)에 대한 회귀분석",
    "text": "5. 두 타입의 아이스크림(초코 / 바닐라)에 대한 회귀분석\n\n이전의 기온 자료를 바꿔 아래와 같은 모형을 가정해보자.\n\n\nA. Data\n\n\ntemp = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/temp.csv').iloc[:,3].to_numpy()[:100]\ntemp.sort()   ## 자료를 크기 순서대로 정렬\ntemp  ## 전주시의 기온 100개 자료\n\narray([-4.1, -3.7, -3. , -1.3, -0.5, -0.3,  0.3,  0.4,  0.4,  0.7,  0.7,\n        0.9,  0.9,  1. ,  1.2,  1.4,  1.4,  1.5,  1.5,  2. ,  2. ,  2. ,\n        2.3,  2.5,  2.5,  2.5,  2.6,  2.6,  2.9,  3.2,  3.5,  3.5,  3.6,\n        3.7,  3.8,  4.2,  4.4,  4.5,  4.5,  4.6,  4.9,  4.9,  4.9,  5. ,\n        5. ,  5.1,  5.6,  5.9,  5.9,  6. ,  6. ,  6.1,  6.1,  6.3,  6.3,\n        6.4,  6.4,  6.5,  6.7,  6.8,  6.8,  7. ,  7. ,  7.1,  7.2,  7.4,\n        7.7,  8. ,  8.1,  8.1,  8.3,  8.4,  8.4,  8.4,  8.5,  8.8,  8.9,\n        9.1,  9.2,  9.3,  9.4,  9.4,  9.5,  9.6,  9.6,  9.7,  9.8,  9.9,\n       10.2, 10.3, 10.6, 10.6, 10.8, 11.2, 12.1, 12.4, 13.4, 14.7, 15. ,\n       15.2])\n\n\n- 아래와 같은 모형을 가정하자.\n\\[\\textup{초코 아이스크림 판매량} = 20 + \\textup{온도} \\times 2.5 + \\textup{오차(운)}\\]\n\\[\\textup{바닐라 아이스크림 판매량} = 40 + \\textup{온도} \\times 2.5 + \\textup{오차(운)}\\]\n\nnp.random.seed(43052)\nchoco = 20 + temp*2.5 + np.random.randn(100)*3  ## random normal distribution\nvanilla = 40 + temp*2.5 + np.random.randn(100)*3\n\n\nplt.plot(temp, choco, 'o', label = 'choco')\nplt.plot(temp, vanilla, 'o', label = 'vanilla')\nplt.legend()\nplt.show()\n\n\n\n\n\n우리는 위와 같은 정보를 관측했다고 가정하자.\n\n\ndf1 = pd.DataFrame({'temp' : temp, 'type' : ['choco' for i in range(100)], 'sales' : choco})\ndf2 = pd.DataFrame({'temp' : temp, 'type' : ['vanilla' for i in range(100)], 'sales' : vanilla})\n\ndf = pd.concat([df1, df2], axis = 0).reset_index(drop = True)\ndf\n\n\n\n\n\n\n\n\ntemp\ntype\nsales\n\n\n\n\n0\n-4.1\nchoco\n10.900261\n\n\n1\n-3.7\nchoco\n14.002524\n\n\n2\n-3.0\nchoco\n15.928335\n\n\n3\n-1.3\nchoco\n17.673681\n\n\n4\n-0.5\nchoco\n19.463362\n\n\n...\n...\n...\n...\n\n\n195\n12.4\nvanilla\n68.708075\n\n\n196\n13.4\nvanilla\n75.800464\n\n\n197\n14.7\nvanilla\n79.846568\n\n\n198\n15.0\nvanilla\n78.713140\n\n\n199\n15.2\nvanilla\n77.595252\n\n\n\n\n200 rows × 3 columns"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-분석",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-분석",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "### B. 분석",
    "text": "### B. 분석\n- 언제처럼 늘 그랬던 것처럼…\n\n# step 1\n## X = pd.get_dummies(df).drop(['sales'], axis = 1) ## 이게 제일 범용적이긴 함\nX = df.loc[:, ['temp', 'type']].assign(type = (df.type == 'choco')) ## 직관적으로 쓴 코드, 범주형은 인식을 못한다.\ny = df['sales']\n\n# step 2\npredictr = sklearn.linear_model.LinearRegression()\n\n# step 3\npredictr.fit(X, y)\n\n# step 4\ndf = df.assign(sales_hat = predictr.predict(X));df\n\n\n\n\n\n\n\n\ntemp\ntype\nsales\nsales_hat\n\n\n\n\n0\n-4.1\nchoco\n10.900261\n9.286731\n\n\n1\n-3.7\nchoco\n14.002524\n10.295689\n\n\n2\n-3.0\nchoco\n15.928335\n12.061366\n\n\n3\n-1.3\nchoco\n17.673681\n16.349439\n\n\n4\n-0.5\nchoco\n19.463362\n18.367355\n\n\n...\n...\n...\n...\n...\n\n\n195\n12.4\nvanilla\n68.708075\n71.446479\n\n\n196\n13.4\nvanilla\n75.800464\n73.968875\n\n\n197\n14.7\nvanilla\n79.846568\n77.247989\n\n\n198\n15.0\nvanilla\n78.713140\n78.004708\n\n\n199\n15.2\nvanilla\n77.595252\n78.509187\n\n\n\n\n200 rows × 4 columns\n\n\n\n- 가장 중요한 시각화까지…\n\nplt.plot(df.temp, df.sales, 'o')\nplt.plot(df.loc[df.type == 'choco'].temp, df.loc[df.type == 'choco'].sales_hat, '--', color = 'brown', label = 'choco')\nplt.plot(df.loc[df.type == 'vanilla'].temp, df.loc[df.type == 'vanilla'].sales_hat, '--', color = 'yellow', label = 'vanilla')\nplt.legend()\nplt.show()\n\n\n\n\n\n별다른 뜻 없이 (초코, 바닐라)에 (1, 0)을 넣었는데, 어떻게 뭐가 나오긴 했다.\n\n\n어케했음???\n\n\\[\\textup{아이스크림 판매량} = 40 + \\textup{아이스크림종류} \\times (-20) + \\textup{온도} \\times 2.5 + \\textup{오차(운)}\\]\n\npredictr.coef_, predictr.intercept_\n\n(array([  2.52239574, -20.54021854]), 40.16877158069265)\n\n\n\ncoef_(기울기)가 2개지요.\n\n온도와 범주형 자료인 아이스크림 종류에 따라 기울기가 다르다. 온도 1도가 변할때마다 판매량은 2.52239574가 변하고, 아이스크림 종류가 1 변할때마다(0에서 1이니까 바닐라에서 초코로 바뀜) -20.54를 곱한 수를 더하여 수식을 설명하였다.\n예측\n- 온도가 \\(-2\\)이고, type이 vanilla(0)라면 예측값은?\n\nXnew = pd.DataFrame({'temp' : [-2], 'type' : [0]})\n\npredictr.predict(Xnew)\n\narray([35.1239801])\n\n\n\nplt.plot(df.temp, df.sales, 'o')\nplt.plot(df.loc[df.type == 'choco'].temp, df.loc[df.type == 'choco'].sales_hat, '--', color = 'brown', label = 'choco')\nplt.plot(df.loc[df.type == 'vanilla'].temp, df.loc[df.type == 'vanilla'].sales_hat, '--', color = 'yellow', label = 'vanilla')\nplt.plot(Xnew.temp, predictr.predict(Xnew), 'or', label = 'prediction')\nplt.legend()\nplt.show()\n\n\n\n\n\nC. 데이터 전처리\n\n- 아까 pd.get_dummies()를 잠시 본 것 같은데, 이걸 어떻게, 왜 써야 하는 지 알아보자.\n\nX = df[['temp','type']] # 독립변수, 설명변수, 피쳐\ny = df[['sales']] # 종속변수, 반응변수, 타겟 \n\n\nX = pd.get_dummies(X);X\n\n\n\n\n\n\n\n\ntemp\ntype_choco\ntype_vanilla\n\n\n\n\n0\n-4.1\nTrue\nFalse\n\n\n1\n-3.7\nTrue\nFalse\n\n\n2\n-3.0\nTrue\nFalse\n\n\n3\n-1.3\nTrue\nFalse\n\n\n4\n-0.5\nTrue\nFalse\n\n\n...\n...\n...\n...\n\n\n195\n12.4\nFalse\nTrue\n\n\n196\n13.4\nFalse\nTrue\n\n\n197\n14.7\nFalse\nTrue\n\n\n198\n15.0\nFalse\nTrue\n\n\n199\n15.2\nFalse\nTrue\n\n\n\n\n200 rows × 3 columns\n\n\n\n\n원-핫 인코딩 : 표현하고 싶은 단어에는 1을, 그것이 아닌 것에는 0을 부여\n\n- LinearRegression 모델의 경우 범주형 자료를 자동으로 인식하지 못한다. 따라서 구분할 범주형 변수가 많다면, pd.get_dummies()를 통해 범주를 나눠주어야 한다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#d.-모형의-평가",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#d.-모형의-평가",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "### D. 모형의 평가",
    "text": "### D. 모형의 평가\n- 단순선형회귀분석의 경우 모형을 \\(R^2\\)(결정계수)로 평가한다.\n\n다만 이것이 높다고 해서 무조건적으로 좋은 건 아니고, 명확한 기준도 없다. 모형 간 상대적인 좋음을 비교하는 것 뿐이다.\n\n- LogisticRegression에서는 적중률로 딱 떨어지게 점수를 내줄 수 있겠지만, 이건 그렇게 해버리면 0점이 나와버리겠지…"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#설명변수가-많을-때",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#설명변수가-많을-때",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "6. 설명변수가 많을 때",
    "text": "6. 설명변수가 많을 때\n- kaggle에서 “Medical Cose Personal Datasets”을 다운로드\n\nhttps://www.kaggle.com/datasets/mirichoi0218/insurance\n\n\ndf = pd.read_csv(\".\\data\\insurance.csv\")\ndf\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\nmale\n30.970\n3\nno\nnorthwest\n10600.54830\n\n\n1334\n18\nfemale\n31.920\n0\nno\nnortheast\n2205.98080\n\n\n1335\n18\nfemale\n36.850\n0\nno\nsoutheast\n1629.83350\n\n\n1336\n21\nfemale\n25.800\n0\nno\nsouthwest\n2007.94500\n\n\n1337\n61\nfemale\n29.070\n0\nyes\nnorthwest\n29141.36030\n\n\n\n\n1338 rows × 7 columns\n\n\n\n\nA. 분석\n\n\n열 이름을 먼저 알아보자.\n\n\nset(df.columns)\n\n{'age', 'bmi', 'charges', 'children', 'region', 'sex', 'smoker'}\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n\n\n- 대충 여러가지 범주형ㆍ연속형 설명변수들과 보험료의 관계를 요약하고 싶다고 하자.\n\n먼저 범주형 자료(sex, smoker, region)들을 원-핫 인코딩 해주자.\n\n\nX = pd.get_dummies(df.drop(['charges'], axis = 1))\ny = df.charges\n\nX\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsex_female\nsex_male\nsmoker_no\nsmoker_yes\nregion_northeast\nregion_northwest\nregion_southeast\nregion_southwest\n\n\n\n\n0\n19\n27.900\n0\nTrue\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\n\n\n1\n18\n33.770\n1\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n2\n28\n33.000\n3\nFalse\nTrue\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n3\n33\n22.705\n0\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n4\n32\n28.880\n0\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n30.970\n3\nFalse\nTrue\nTrue\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n1334\n18\n31.920\n0\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n1335\n18\n36.850\n0\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n1336\n21\n25.800\n0\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1337\n61\n29.070\n0\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nFalse\n\n\n\n\n1338 rows × 11 columns\n\n\n\n- 그럼 뭐 늘 하던대로…\n\n# 2\npredictr = sklearn.linear_model.LinearRegression()\n\n# 3\npredictr.fit(X, y)\n\n# 4\ndf = df.assign(y_hat = predictr.predict(X))\n\n\ndf\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\ny_hat\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n25293.713028\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n3448.602834\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n6706.988491\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n3754.830163\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n5592.493386\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\nmale\n30.970\n3\nno\nnorthwest\n10600.54830\n12351.323686\n\n\n1334\n18\nfemale\n31.920\n0\nno\nnortheast\n2205.98080\n3511.930809\n\n\n1335\n18\nfemale\n36.850\n0\nno\nsoutheast\n1629.83350\n4149.132486\n\n\n1336\n21\nfemale\n25.800\n0\nno\nsouthwest\n2007.94500\n1246.584939\n\n\n1337\n61\nfemale\n29.070\n0\nyes\nnorthwest\n29141.36030\n37085.623268\n\n\n\n\n1338 rows × 8 columns\n\n\n\n- charge와 y_hat이 잘 안맞는 것 같은데…?"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-평가",
    "href": "posts/Machine Learning in Practice/practice/1. 회귀분석_아이스크림.html#b.-평가",
    "title": "선형회귀분석의 시작 | LinearRegression()",
    "section": "### B. 평가",
    "text": "### B. 평가\n\npredictr.score(X, y)\n\n0.7509130345985205\n\n\n\n\\(R^2 = \\frac{SSR}{SST} = 0.7509130345985205\\)\n0.7 이상이면 망한 모형까진 아니지만…\n\n계수 해석\n- 상수항\n\npredictr.intercept_\n\n-666.9377199366372\n\n\n\n기본적인 보험료(다른 모든 것이 0일 때)는 -666이다.~(딱봐도 이상하죠? 그래서 별로 의미는 없다.)~\n\n- 계수\n\npd.DataFrame({'columns' : X.columns, 'coef' : predictr.coef_})\n\n\n\n\n\n\n\n\ncolumns\ncoef\n\n\n\n\n0\nage\n256.856353\n\n\n1\nbmi\n339.193454\n\n\n2\nchildren\n475.500545\n\n\n3\nsex_female\n65.657180\n\n\n4\nsex_male\n-65.657180\n\n\n5\nsmoker_no\n-11924.267271\n\n\n6\nsmoker_yes\n11924.267271\n\n\n7\nregion_northeast\n587.009235\n\n\n8\nregion_northwest\n234.045336\n\n\n9\nregion_southeast\n-448.012814\n\n\n10\nregion_southwest\n-373.041756\n\n\n\n\n\n\n\n\n연속형 : 나이, bmi, 자녀의 수가 많을수록 보험료는 올라갔다.\n범주형 : 여성, 흡연자의 경우 보험료가 더 비쌌다.\n지역은 잘 모르겠으나, 나머지는 꽤 그럴듯해 보인다.(지역에 대한 정보는 알기 어려움…)"
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html",
    "href": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html",
    "title": "[문제 풀이] 특정 단어를 포함하는 열 선택",
    "section": "",
    "text": "데이터프레임 df의 열이름에 actor라는 단어가 포함된 column만을 선택하는 코드를 작성하라"
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html#사전작업",
    "href": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html#사전작업",
    "title": "[문제 풀이] 특정 단어를 포함하는 열 선택",
    "section": "1. 사전작업",
    "text": "1. 사전작업\n\n라이브러리 설치\n\n\nimport pandas as pd\nimport numpy as np\n\n\n데이터 불러오기 및 확인\n\n\ndf=pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv')\ndf.head()\n\n\n\n\n\n\n\n\ncolor\ndirector_name\nnum_critic_for_reviews\nduration\ndirector_facebook_likes\nactor_3_facebook_likes\nactor_2_name\nactor_1_facebook_likes\ngross\ngenres\n...\nnum_user_for_reviews\nlanguage\ncountry\ncontent_rating\nbudget\ntitle_year\nactor_2_facebook_likes\nimdb_score\naspect_ratio\nmovie_facebook_likes\n\n\n\n\n0\nColor\nJames Cameron\n723.0\n178.0\n0.0\n855.0\nJoel David Moore\n1000.0\n760505847.0\nAction|Adventure|Fantasy|Sci-Fi\n...\n3054.0\nEnglish\nUSA\nPG-13\n237000000.0\n2009.0\n936.0\n7.9\n1.78\n33000\n\n\n1\nColor\nGore Verbinski\n302.0\n169.0\n563.0\n1000.0\nOrlando Bloom\n40000.0\n309404152.0\nAction|Adventure|Fantasy\n...\n1238.0\nEnglish\nUSA\nPG-13\n300000000.0\n2007.0\n5000.0\n7.1\n2.35\n0\n\n\n2\nColor\nSam Mendes\n602.0\n148.0\n0.0\n161.0\nRory Kinnear\n11000.0\n200074175.0\nAction|Adventure|Thriller\n...\n994.0\nEnglish\nUK\nPG-13\n245000000.0\n2015.0\n393.0\n6.8\n2.35\n85000\n\n\n3\nColor\nChristopher Nolan\n813.0\n164.0\n22000.0\n23000.0\nChristian Bale\n27000.0\n448130642.0\nAction|Thriller\n...\n2701.0\nEnglish\nUSA\nPG-13\n250000000.0\n2012.0\n23000.0\n8.5\n2.35\n164000\n\n\n4\nNaN\nDoug Walker\nNaN\nNaN\n131.0\nNaN\nRob Walker\n131.0\nNaN\nDocumentary\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n12.0\n7.1\nNaN\n0\n\n\n\n\n5 rows × 28 columns\n\n\n\n\ndf.columns\n\nIndex(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n      dtype='object')\n\n\n\n열 이름에서 단어의 구분이 모두 '_'로 되어있으므로, 열이름에 split()함수를 적용시킬 수 있을 것 같다."
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html#풀이",
    "href": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html#풀이",
    "title": "[문제 풀이] 특정 단어를 포함하는 열 선택",
    "section": "2. 풀이",
    "text": "2. 풀이\n\nfor 문을 이용하여 풀이해보자.\n\n\n['actor' in i.split('_') for i in df.columns]\n\n[False,\n False,\n False,\n False,\n False,\n True,\n True,\n True,\n False,\n False,\n True,\n False,\n False,\n False,\n True,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n True,\n False,\n False,\n False]"
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html#결과",
    "href": "posts/Data Visualization/Solution Assemble/특정 단어를 포함하는 열 선택.html#결과",
    "title": "[문제 풀이] 특정 단어를 포함하는 열 선택",
    "section": "3. 결과",
    "text": "3. 결과\n\ndf.loc[:, ['actor' in i.split('_') for i in df.columns]]\n\n\n\n\n\n\n\n\nactor_3_facebook_likes\nactor_2_name\nactor_1_facebook_likes\nactor_1_name\nactor_3_name\nactor_2_facebook_likes\n\n\n\n\n0\n855.0\nJoel David Moore\n1000.0\nCCH Pounder\nWes Studi\n936.0\n\n\n1\n1000.0\nOrlando Bloom\n40000.0\nJohnny Depp\nJack Davenport\n5000.0\n\n\n2\n161.0\nRory Kinnear\n11000.0\nChristoph Waltz\nStephanie Sigman\n393.0\n\n\n3\n23000.0\nChristian Bale\n27000.0\nTom Hardy\nJoseph Gordon-Levitt\n23000.0\n\n\n4\nNaN\nRob Walker\n131.0\nDoug Walker\nNaN\n12.0\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n4911\n318.0\nDaphne Zuniga\n637.0\nEric Mabius\nCrystal Lowe\n470.0\n\n\n4912\n319.0\nValorie Curry\n841.0\nNatalie Zea\nSam Underwood\n593.0\n\n\n4913\n0.0\nMaxwell Moody\n0.0\nEva Boehnke\nDavid Chandler\n0.0\n\n\n4914\n489.0\nDaniel Henney\n946.0\nAlan Ruck\nEliza Coupe\n719.0\n\n\n4915\n16.0\nBrian Herzlinger\n86.0\nJohn August\nJon Gunn\n23.0\n\n\n\n\n4916 rows × 6 columns\n\n\n\n완료"
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "",
    "text": "FIFA23 선수 데이터에서 결측치를 처리하고 여러 열을 가공하여 시각화해보자!"
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#라이브러리-import",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#라이브러리-import",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "1. 라이브러리 import",
    "text": "1. 라이브러리 import\n\nimport pandas as pd\nimport numpy as np\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#학습할-코드",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#학습할-코드",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "2. 학습할 코드",
    "text": "2. 학습할 코드\n\nA. dropna()\n\n- 행에서 결측치가 하나라도 있으면 제거한다.\n\ndf = pd.DataFrame({\n    'A': [1,2,3,np.nan,5,6,7],\n    'B': [11,np.nan,33,np.nan,55,66,77], \n    'C': [111,222,333,np.nan,555,666,np.nan]})\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1.0\n11.0\n111.0\n\n\n1\n2.0\nNaN\n222.0\n\n\n2\n3.0\n33.0\n333.0\n\n\n3\nNaN\nNaN\nNaN\n\n\n4\n5.0\n55.0\n555.0\n\n\n5\n6.0\n66.0\n666.0\n\n\n6\n7.0\n77.0\nNaN\n\n\n\n\n\n\n\n\n이러한 데이터가 있다고 할 때…\n\n\ndf.dropna()\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1.0\n11.0\n111.0\n\n\n2\n3.0\n33.0\n333.0\n\n\n4\n5.0\n55.0\n555.0\n\n\n5\n6.0\n66.0\n666.0\n\n\n\n\n\n\n\n\n결측치가 하나라도 있는 행은 모두 드롭된다. (원본 데이터 손상 X)"
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#b.-_",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#b.-_",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "### B. _",
    "text": "### B. _\n- 파이썬에서 가장 최근 콘솔에 띄워진 결과는 _로 불러올 수 있다.\n\na = [1,2,3]\na + [4] \n\n[1, 2, 3, 4]\n\n\n\n_\n\n[1, 2, 3, 4]\n\n\n\n_ + [5]\n\n[1, 2, 3, 4, 5]\n\n\n\n_.pop()  ## 마지막 요소를 리턴하고 그 요소는 삭제\n\n5\n\n\n\n_ + 1\n\n6\n\n\n\n리스트에서 숫자까지… _의 다사다난한 모험"
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#fifa23-시각화-문제",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#fifa23-시각화-문제",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "3. FIFA23 시각화 문제",
    "text": "3. FIFA23 시각화 문제\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2021/master/_notebooks/2021-10-25-FIFA22_official_data.csv')\ndf.head()\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nSlidingTackle\nGKDiving\nGKHandling\nGKKicking\nGKPositioning\nGKReflexes\nBest Position\nBest Overall Rating\nRelease Clause\nDefensiveAwareness\n\n\n\n\n0\n212198\nBruno Fernandes\n26\nhttps://cdn.sofifa.com/players/212/198/22_60.png\nPortugal\nhttps://cdn.sofifa.com/flags/pt.png\n88\n89\nManchester United\nhttps://cdn.sofifa.com/teams/11/30.png\n...\n65.0\n12.0\n14.0\n15.0\n8.0\n14.0\nCAM\n88.0\n€206.9M\n72.0\n\n\n1\n209658\nL. Goretzka\n26\nhttps://cdn.sofifa.com/players/209/658/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.com/teams/21/30.png\n...\n77.0\n13.0\n8.0\n15.0\n11.0\n9.0\nCM\n87.0\n€160.4M\n74.0\n\n\n2\n176580\nL. Suárez\n34\nhttps://cdn.sofifa.com/players/176/580/22_60.png\nUruguay\nhttps://cdn.sofifa.com/flags/uy.png\n88\n88\nAtlético de Madrid\nhttps://cdn.sofifa.com/teams/240/30.png\n...\n38.0\n27.0\n25.0\n31.0\n33.0\n37.0\nST\n88.0\n€91.2M\n42.0\n\n\n3\n192985\nK. De Bruyne\n30\nhttps://cdn.sofifa.com/players/192/985/22_60.png\nBelgium\nhttps://cdn.sofifa.com/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.com/teams/10/30.png\n...\n53.0\n15.0\n13.0\n5.0\n10.0\n13.0\nCM\n91.0\n€232.2M\n68.0\n\n\n4\n224334\nM. Acuña\n29\nhttps://cdn.sofifa.com/players/224/334/22_60.png\nArgentina\nhttps://cdn.sofifa.com/flags/ar.png\n84\n84\nSevilla FC\nhttps://cdn.sofifa.com/teams/481/30.png\n...\n82.0\n8.0\n14.0\n13.0\n13.0\n14.0\nLB\n84.0\n€77.7M\n80.0\n\n\n\n\n5 rows × 65 columns\n\n\n\n포지션별로 선수들의 능력치(ShotPower,SlidingTackle)와 급여(Wage)를 시각화하고 싶다. 아래의 세부지침에 맞추어 포지션별 ShotPower와 SlidingTackle의 산점도를 그려라.\n\ndf.Position\n\n0        &lt;span class=\"pos pos18\"&gt;CAM\n1        &lt;span class=\"pos pos11\"&gt;LDM\n2         &lt;span class=\"pos pos24\"&gt;RS\n3        &lt;span class=\"pos pos13\"&gt;RCM\n4          &lt;span class=\"pos pos7\"&gt;LB\n                    ...             \n16705    &lt;span class=\"pos pos29\"&gt;RES\n16706    &lt;span class=\"pos pos29\"&gt;RES\n16707    &lt;span class=\"pos pos29\"&gt;RES\n16708    &lt;span class=\"pos pos28\"&gt;SUB\n16709    &lt;span class=\"pos pos28\"&gt;SUB\nName: Position, Length: 16710, dtype: object\n\n\n세부지침\nA. Column의 이름에서 공백을 제거하라.\nB. 결측치가 50%이상인 컬럼을 찾고 이를 제거하라. 그 뒤에 .dropna()를 사용하여 결측치가 포함된 행을 제거하라.\nC. position_dict를 이용하여 df.Position을 적절하게 변환하라. 변환된 값을 df.Position에 저장하라.\n\nposition_dict = {\n    'GOALKEEPER':{'GK'},\n    'DEFENDER':{'CB','RCB','LCB','RB','LB','RWB','LWB'},\n    'MIDFIELDER':{'CM','RCM','LCM','CDM','RDM','LDM','CAM','RAM','LAM','RM','LM'},\n    'FORWARD':{'ST','CF','RF','LF','RW','LW','RS','LS'},\n    'SUB':{'SUB'},\n    'RES':{'RES'}\n}\n\nD. df.Wage를 적절하게 변환하라.\nE. Position==“DEFENDER” or Position==“FORWARD”에 해당하는 관측치를 고른 뒤 x축에 ShotPower, y축에 SlidingTackle을 시각화하라. 이때 Position은 color로 구분하고 Wage는 size와 alpha로 구분하라.\n시각화 예시"
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#fifa23-시각화---풀이",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#fifa23-시각화---풀이",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "4. FIFA23 시각화 - 풀이",
    "text": "4. FIFA23 시각화 - 풀이\n\nA. Column의 이름에서 공백을 제거하라.\n\n\ndf.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Jersey Number', 'Joined', 'Loaned From', 'Contract Valid Until',\n       'Height', 'Weight', 'Crossing', 'Finishing', 'HeadingAccuracy',\n       'ShortPassing', 'Volleys', 'Dribbling', 'Curve', 'FKAccuracy',\n       'LongPassing', 'BallControl', 'Acceleration', 'SprintSpeed', 'Agility',\n       'Reactions', 'Balance', 'ShotPower', 'Jumping', 'Stamina', 'Strength',\n       'LongShots', 'Aggression', 'Interceptions', 'Positioning', 'Vision',\n       'Penalties', 'Composure', 'Marking', 'StandingTackle', 'SlidingTackle',\n       'GKDiving', 'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes',\n       'Best Position', 'Best Overall Rating', 'Release Clause',\n       'DefensiveAwareness'],\n      dtype='object')\n\n\n\ndf.columns.str.replace(' ', '')\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'ClubLogo', 'Value', 'Wage', 'Special',\n       'PreferredFoot', 'InternationalReputation', 'WeakFoot', 'SkillMoves',\n       'WorkRate', 'BodyType', 'RealFace', 'Position', 'JerseyNumber',\n       'Joined', 'LoanedFrom', 'ContractValidUntil', 'Height', 'Weight',\n       'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys',\n       'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl',\n       'Acceleration', 'SprintSpeed', 'Agility', 'Reactions', 'Balance',\n       'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots',\n       'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties',\n       'Composure', 'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving',\n       'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes',\n       'BestPosition', 'BestOverallRating', 'ReleaseClause',\n       'DefensiveAwareness'],\n      dtype='object')\n\n\n\ndf.set_axis(df.columns.str.replace(' ', ''), axis = 1).columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'ClubLogo', 'Value', 'Wage', 'Special',\n       'PreferredFoot', 'InternationalReputation', 'WeakFoot', 'SkillMoves',\n       'WorkRate', 'BodyType', 'RealFace', 'Position', 'JerseyNumber',\n       'Joined', 'LoanedFrom', 'ContractValidUntil', 'Height', 'Weight',\n       'Crossing', 'Finishing', 'HeadingAccuracy', 'ShortPassing', 'Volleys',\n       'Dribbling', 'Curve', 'FKAccuracy', 'LongPassing', 'BallControl',\n       'Acceleration', 'SprintSpeed', 'Agility', 'Reactions', 'Balance',\n       'ShotPower', 'Jumping', 'Stamina', 'Strength', 'LongShots',\n       'Aggression', 'Interceptions', 'Positioning', 'Vision', 'Penalties',\n       'Composure', 'Marking', 'StandingTackle', 'SlidingTackle', 'GKDiving',\n       'GKHandling', 'GKKicking', 'GKPositioning', 'GKReflexes',\n       'BestPosition', 'BestOverallRating', 'ReleaseClause',\n       'DefensiveAwareness'],\n      dtype='object')\n\n\n\n공백이 없어진 것을 확인할 수 있다.\n\n\n\nB. 결측치가 50%이상인 컬럼을 찾고 이를 제거하라. 그 뒤에 .dropna()를 사용하여 결측치가 포함된 행을 제거하라.\n\n\ndf_b = df.set_axis(df.columns.str.replace(' ', ''), axis = 1)\n\n\ndf_b.loc[:, df_b.isna().mean() &gt;= 0.5].columns\n\nIndex(['LoanedFrom', 'Marking'], dtype='object')\n\n\n\n위 두 개의 컬럼이 결측치가 50% 이상이다.\n\n\ndf_b.loc[:, df_b.isna().mean() &lt; 0.5].dropna()\n##df_b.loc[:, [s &lt; 0.5 for s in df_b.isna().mean()]].dropna()\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClubLogo\n...\nSlidingTackle\nGKDiving\nGKHandling\nGKKicking\nGKPositioning\nGKReflexes\nBestPosition\nBestOverallRating\nReleaseClause\nDefensiveAwareness\n\n\n\n\n0\n212198\nBruno Fernandes\n26\nhttps://cdn.sofifa.com/players/212/198/22_60.png\nPortugal\nhttps://cdn.sofifa.com/flags/pt.png\n88\n89\nManchester United\nhttps://cdn.sofifa.com/teams/11/30.png\n...\n65.0\n12.0\n14.0\n15.0\n8.0\n14.0\nCAM\n88.0\n€206.9M\n72.0\n\n\n1\n209658\nL. Goretzka\n26\nhttps://cdn.sofifa.com/players/209/658/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.com/teams/21/30.png\n...\n77.0\n13.0\n8.0\n15.0\n11.0\n9.0\nCM\n87.0\n€160.4M\n74.0\n\n\n2\n176580\nL. Suárez\n34\nhttps://cdn.sofifa.com/players/176/580/22_60.png\nUruguay\nhttps://cdn.sofifa.com/flags/uy.png\n88\n88\nAtlético de Madrid\nhttps://cdn.sofifa.com/teams/240/30.png\n...\n38.0\n27.0\n25.0\n31.0\n33.0\n37.0\nST\n88.0\n€91.2M\n42.0\n\n\n3\n192985\nK. De Bruyne\n30\nhttps://cdn.sofifa.com/players/192/985/22_60.png\nBelgium\nhttps://cdn.sofifa.com/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.com/teams/10/30.png\n...\n53.0\n15.0\n13.0\n5.0\n10.0\n13.0\nCM\n91.0\n€232.2M\n68.0\n\n\n4\n224334\nM. Acuña\n29\nhttps://cdn.sofifa.com/players/224/334/22_60.png\nArgentina\nhttps://cdn.sofifa.com/flags/ar.png\n84\n84\nSevilla FC\nhttps://cdn.sofifa.com/teams/481/30.png\n...\n82.0\n8.0\n14.0\n13.0\n13.0\n14.0\nLB\n84.0\n€77.7M\n80.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16703\n259718\nF. Gebhardt\n19\nhttps://cdn.sofifa.com/players/259/718/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n52\n66\nFC Basel 1893\nhttps://cdn.sofifa.com/teams/896/30.png\n...\n10.0\n53.0\n45.0\n47.0\n52.0\n57.0\nGK\n52.0\n€361K\n6.0\n\n\n16704\n251433\nB. Voll\n20\nhttps://cdn.sofifa.com/players/251/433/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n58\n69\nF.C. Hansa Rostock\nhttps://cdn.sofifa.com/teams/27/30.png\n...\n10.0\n59.0\n60.0\n56.0\n55.0\n61.0\nGK\n58.0\n€656K\n5.0\n\n\n16706\n262846\n�. Dobre\n20\nhttps://cdn.sofifa.com/players/262/846/22_60.png\nRomania\nhttps://cdn.sofifa.com/flags/ro.png\n53\n63\nFC Academica Clinceni\nhttps://cdn.sofifa.com/teams/113391/30.png\n...\n12.0\n57.0\n52.0\n53.0\n48.0\n58.0\nGK\n53.0\n€279K\n5.0\n\n\n16707\n241317\n21 Xue Qinghao\n19\nhttps://cdn.sofifa.com/players/241/317/21_60.png\nChina PR\nhttps://cdn.sofifa.com/flags/cn.png\n47\n60\nShanghai Shenhua FC\nhttps://cdn.sofifa.com/teams/110955/30.png\n...\n9.0\n49.0\n48.0\n45.0\n38.0\n52.0\nGK\n47.0\n€223K\n21.0\n\n\n16708\n259646\nA. Shaikh\n18\nhttps://cdn.sofifa.com/players/259/646/22_60.png\nIndia\nhttps://cdn.sofifa.com/flags/in.png\n47\n67\nATK Mohun Bagan FC\nhttps://cdn.sofifa.com/teams/113146/30.png\n...\n13.0\n49.0\n41.0\n39.0\n45.0\n49.0\nGK\n47.0\n€259K\n7.0\n\n\n\n\n14398 rows × 63 columns\n\n\n\n\n따라서 해당 조건에 반대를 슬라이싱하는 방식으로 해당 컬럼을 제거하였다."
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#c.-position_dict를-이용하여-df.position을-적절하게-변환하라.-변환된-값을-df.position에-저장하라.",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#c.-position_dict를-이용하여-df.position을-적절하게-변환하라.-변환된-값을-df.position에-저장하라.",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "### C. position_dict를 이용하여 df.Position을 적절하게 변환하라. 변환된 값을 df.Position에 저장하라.",
    "text": "### C. position_dict를 이용하여 df.Position을 적절하게 변환하라. 변환된 값을 df.Position에 저장하라.\n\nposition_dict\n\n{'GOALKEEPER': {'GK'},\n 'DEFENDER': {'CB', 'LB', 'LCB', 'LWB', 'RB', 'RCB', 'RWB'},\n 'MIDFIELDER': {'CAM',\n  'CDM',\n  'CM',\n  'LAM',\n  'LCM',\n  'LDM',\n  'LM',\n  'RAM',\n  'RCM',\n  'RDM',\n  'RM'},\n 'FORWARD': {'CF', 'LF', 'LS', 'LW', 'RF', 'RS', 'RW', 'ST'},\n 'SUB': {'SUB'},\n 'RES': {'RES'}}\n\n\n\ndf_c = df_b.loc[:, df_b.isna().mean() &lt; 0.5].dropna()\ndf_c.Position\n\n0        &lt;span class=\"pos pos18\"&gt;CAM\n1        &lt;span class=\"pos pos11\"&gt;LDM\n2         &lt;span class=\"pos pos24\"&gt;RS\n3        &lt;span class=\"pos pos13\"&gt;RCM\n4          &lt;span class=\"pos pos7\"&gt;LB\n                    ...             \n16703    &lt;span class=\"pos pos29\"&gt;RES\n16704    &lt;span class=\"pos pos29\"&gt;RES\n16706    &lt;span class=\"pos pos29\"&gt;RES\n16707    &lt;span class=\"pos pos29\"&gt;RES\n16708    &lt;span class=\"pos pos28\"&gt;SUB\nName: Position, Length: 14398, dtype: object\n\n\n\n뒤의 &gt;를 제외한 문자열을 추출해서 바꿔줘야 할 것 같다.\n\n\ndf_c.assign(Position = df_c.Position.str.split('&gt;').str[-1]).Position\n\n0        CAM\n1        LDM\n2         RS\n3        RCM\n4         LB\n        ... \n16703    RES\n16704    RES\n16706    RES\n16707    RES\n16708    SUB\nName: Position, Length: 14398, dtype: object\n\n\n\n뒤의 문자열만 추출\n\n- 무지성으로 쥐어짜내본 아이디어\n\nx = df_c.Position.str.split('&gt;').str[-1][2]\nlst = [i != 0 for i in [key if x in value else 0 for key, value in position_dict.items()]];lst\n\n[False, False, False, True, False, False]\n\n\n\n[i != 0 for i in [key if x in value else 0 for key, value in position_dict.items()]].index(True)\n\n3\n\n\n\nlst = [[key if i in value else np.nan if i == np.nan else 1 for key, value in position_dict.items()] for i in df_c.Position.str.split('&gt;').str[-1]]\n\n\nvalue와 같은 값이면 key, 아니면 1, 결측치면 np.nan을 넣어줘봤음.\n\n\ndef cutting_1(lst):\n    for i in lst:\n        if i != 1:\n            return i\n\nPosition_s = pd.Series(lst).apply(cutting_1); Position_s\n\n0        MIDFIELDER\n1        MIDFIELDER\n2           FORWARD\n3        MIDFIELDER\n4          DEFENDER\n            ...    \n14393           RES\n14394           RES\n14395           RES\n14396           RES\n14397           SUB\nLength: 14398, dtype: object\n\n\n\n잘 된듯~(근데 앞에서 .dropna()를 안해서 쓸데없는 코드까지 작성해버렸다.)~\n\n\nlst_2 = list(map(lambda x : [key for key, value in position_dict.items() if x in value], df_c.Position.str.split('&gt;').str[-1]))\n## [i[0] for i in lst_2] : 왜인지 안됨\n## [i.pop() for i in lst_2] : 이건 뭐 객체 저장인지 뭔지 문제라는데, 다른 변수에 copy()해서 넣어봐도 안됨\n\n\ndf_c.reset_index(drop = True).assign(Position = Position_s).Position\n\n0        MIDFIELDER\n1        MIDFIELDER\n2           FORWARD\n3        MIDFIELDER\n4          DEFENDER\n            ...    \n14393           RES\n14394           RES\n14395           RES\n14396           RES\n14397           SUB\nName: Position, Length: 14398, dtype: object\n\n\n\n잘못된 코드\n\n\ndf_c.assign(Position = Position_s).Position  ## 문제가 있는 코드, reset_index(drop = True)를 안해줘서 인덱스가 꼬임\n\n0        MIDFIELDER\n1        MIDFIELDER\n2           FORWARD\n3        MIDFIELDER\n4          DEFENDER\n            ...    \n16703           NaN\n16704           NaN\n16706           NaN\n16707           NaN\n16708           NaN\nName: Position, Length: 14398, dtype: object\n\n\n\n뭘 잘못했는 지 알겠지? index가 달라서 값이 엮이지가 않잖아…\n\n- 매우 간단한 교수님의 해법\n\ndf.set_axis(df.columns.str.replace(' ',''),axis=1)\\\n.loc[:,lambda _df: _df.isna().mean()&lt;0.5].dropna()\\\n.assign(Position = lambda _df: _df.Position.str.split(\"&gt;\").str[-1].apply(lambda x: [k for k,v in position_dict.items() if x in v].pop()))\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClubLogo\n...\nSlidingTackle\nGKDiving\nGKHandling\nGKKicking\nGKPositioning\nGKReflexes\nBestPosition\nBestOverallRating\nReleaseClause\nDefensiveAwareness\n\n\n\n\n0\n212198\nBruno Fernandes\n26\nhttps://cdn.sofifa.com/players/212/198/22_60.png\nPortugal\nhttps://cdn.sofifa.com/flags/pt.png\n88\n89\nManchester United\nhttps://cdn.sofifa.com/teams/11/30.png\n...\n65.0\n12.0\n14.0\n15.0\n8.0\n14.0\nCAM\n88.0\n€206.9M\n72.0\n\n\n1\n209658\nL. Goretzka\n26\nhttps://cdn.sofifa.com/players/209/658/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.com/teams/21/30.png\n...\n77.0\n13.0\n8.0\n15.0\n11.0\n9.0\nCM\n87.0\n€160.4M\n74.0\n\n\n2\n176580\nL. Suárez\n34\nhttps://cdn.sofifa.com/players/176/580/22_60.png\nUruguay\nhttps://cdn.sofifa.com/flags/uy.png\n88\n88\nAtlético de Madrid\nhttps://cdn.sofifa.com/teams/240/30.png\n...\n38.0\n27.0\n25.0\n31.0\n33.0\n37.0\nST\n88.0\n€91.2M\n42.0\n\n\n3\n192985\nK. De Bruyne\n30\nhttps://cdn.sofifa.com/players/192/985/22_60.png\nBelgium\nhttps://cdn.sofifa.com/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.com/teams/10/30.png\n...\n53.0\n15.0\n13.0\n5.0\n10.0\n13.0\nCM\n91.0\n€232.2M\n68.0\n\n\n4\n224334\nM. Acuña\n29\nhttps://cdn.sofifa.com/players/224/334/22_60.png\nArgentina\nhttps://cdn.sofifa.com/flags/ar.png\n84\n84\nSevilla FC\nhttps://cdn.sofifa.com/teams/481/30.png\n...\n82.0\n8.0\n14.0\n13.0\n13.0\n14.0\nLB\n84.0\n€77.7M\n80.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16703\n259718\nF. Gebhardt\n19\nhttps://cdn.sofifa.com/players/259/718/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n52\n66\nFC Basel 1893\nhttps://cdn.sofifa.com/teams/896/30.png\n...\n10.0\n53.0\n45.0\n47.0\n52.0\n57.0\nGK\n52.0\n€361K\n6.0\n\n\n16704\n251433\nB. Voll\n20\nhttps://cdn.sofifa.com/players/251/433/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n58\n69\nF.C. Hansa Rostock\nhttps://cdn.sofifa.com/teams/27/30.png\n...\n10.0\n59.0\n60.0\n56.0\n55.0\n61.0\nGK\n58.0\n€656K\n5.0\n\n\n16706\n262846\n�. Dobre\n20\nhttps://cdn.sofifa.com/players/262/846/22_60.png\nRomania\nhttps://cdn.sofifa.com/flags/ro.png\n53\n63\nFC Academica Clinceni\nhttps://cdn.sofifa.com/teams/113391/30.png\n...\n12.0\n57.0\n52.0\n53.0\n48.0\n58.0\nGK\n53.0\n€279K\n5.0\n\n\n16707\n241317\n21 Xue Qinghao\n19\nhttps://cdn.sofifa.com/players/241/317/21_60.png\nChina PR\nhttps://cdn.sofifa.com/flags/cn.png\n47\n60\nShanghai Shenhua FC\nhttps://cdn.sofifa.com/teams/110955/30.png\n...\n9.0\n49.0\n48.0\n45.0\n38.0\n52.0\nGK\n47.0\n€223K\n21.0\n\n\n16708\n259646\nA. Shaikh\n18\nhttps://cdn.sofifa.com/players/259/646/22_60.png\nIndia\nhttps://cdn.sofifa.com/flags/in.png\n47\n67\nATK Mohun Bagan FC\nhttps://cdn.sofifa.com/teams/113146/30.png\n...\n13.0\n49.0\n41.0\n39.0\n45.0\n49.0\nGK\n47.0\n€259K\n7.0\n\n\n\n\n14398 rows × 63 columns\n\n\n\n\n아마도 모든 문제의 원흉은 dropna()를 하지 않은 너에게 있었다. (결측치가 있으면 작동이 힘든가봄)\n\n\nD. df.Wage를 적절하게 변환하라.\n\n\ndf.Wage\n\n0        €250K\n1        €140K\n2        €135K\n3        €350K\n4         €45K\n         ...  \n16705      €1K\n16706     €550\n16707     €700\n16708     €500\n16709       €0\nName: Wage, Length: 16710, dtype: object\n\n\n\n시각화 해주려면 숫자형 자료여야 하는데, 범주형으로 들어가있다.\n\n- 앞의 유로를 없애고, K는 1000을 곱해주자.\n\ndf_d = df_c.reset_index(drop = True).assign(Position = Position_s)\n\n\ndf_d.Wage.str.replace('€','').str.replace('K','000')\n##[int(i) if i[-1] != 'K' else int(i.replace('K',''))*1000 for i in df_d.Wage.str.replace('€','')]와 동일\n\n0        250000\n1        140000\n2        135000\n3        350000\n4         45000\n          ...  \n14393       650\n14394       950\n14395       550\n14396       700\n14397       500\nName: Wage, Length: 14398, dtype: object\n\n\n\ndf_d.assign(Wage = df_d.Wage.str.replace('€','').str.replace('K','000').astype(int)).Wage\n\n0        250000\n1        140000\n2        135000\n3        350000\n4         45000\n          ...  \n14393       650\n14394       950\n14395       550\n14396       700\n14397       500\nName: Wage, Length: 14398, dtype: int32\n\n\n\n잘 된 것을 볼 수 있다."
  },
  {
    "objectID": "posts/Data Visualization/Review/8. 실습_FIFA23.html#e.-positiondefender-or-positionforward에-해당하는-관측치를-고른-뒤-x축에-shotpower-y축에-slidingtackle을-시각화하라.-이때-position은-color로-구분하고-wage는-size와-alpha로-구분하라.",
    "href": "posts/Data Visualization/Review/8. 실습_FIFA23.html#e.-positiondefender-or-positionforward에-해당하는-관측치를-고른-뒤-x축에-shotpower-y축에-slidingtackle을-시각화하라.-이때-position은-color로-구분하고-wage는-size와-alpha로-구분하라.",
    "title": "데이터 시각화 실습 : FIFA23 선수 데이터",
    "section": "### E. Position==“DEFENDER” or Position==“FORWARD”에 해당하는 관측치를 고른 뒤 x축에 ShotPower, y축에 SlidingTackle을 시각화하라. 이때 Position은 color로 구분하고 Wage는 size와 alpha로 구분하라.",
    "text": "### E. Position==“DEFENDER” or Position==“FORWARD”에 해당하는 관측치를 고른 뒤 x축에 ShotPower, y축에 SlidingTackle을 시각화하라. 이때 Position은 color로 구분하고 Wage는 size와 alpha로 구분하라.\n\ndf_e = df_d.assign(Wage = df_d.Wage.str.replace('€','').str.replace('K','000').astype(int))\n\n\ndf_e.loc[(df_e.Position == \"DEFENDER\") | (df_e.Position == \"FORWARD\")]\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClubLogo\n...\nSlidingTackle\nGKDiving\nGKHandling\nGKKicking\nGKPositioning\nGKReflexes\nBestPosition\nBestOverallRating\nReleaseClause\nDefensiveAwareness\n\n\n\n\n2\n176580\nL. Suárez\n34\nhttps://cdn.sofifa.com/players/176/580/22_60.png\nUruguay\nhttps://cdn.sofifa.com/flags/uy.png\n88\n88\nAtlético de Madrid\nhttps://cdn.sofifa.com/teams/240/30.png\n...\n38.0\n27.0\n25.0\n31.0\n33.0\n37.0\nST\n88.0\n€91.2M\n42.0\n\n\n4\n224334\nM. Acuña\n29\nhttps://cdn.sofifa.com/players/224/334/22_60.png\nArgentina\nhttps://cdn.sofifa.com/flags/ar.png\n84\n84\nSevilla FC\nhttps://cdn.sofifa.com/teams/481/30.png\n...\n82.0\n8.0\n14.0\n13.0\n13.0\n14.0\nLB\n84.0\n€77.7M\n80.0\n\n\n11\n155862\nSergio Ramos\n35\nhttps://cdn.sofifa.com/players/155/862/22_60.png\nSpain\nhttps://cdn.sofifa.com/flags/es.png\n88\n88\nParis Saint-Germain\nhttps://cdn.sofifa.com/teams/73/30.png\n...\n91.0\n11.0\n8.0\n9.0\n7.0\n11.0\nCB\n88.0\n€44.4M\n84.0\n\n\n12\n197445\nD. Alaba\n29\nhttps://cdn.sofifa.com/players/197/445/22_60.png\nAustria\nhttps://cdn.sofifa.com/flags/at.png\n84\n84\nReal Madrid CF\nhttps://cdn.sofifa.com/teams/243/30.png\n...\n82.0\n5.0\n7.0\n14.0\n15.0\n9.0\nCB\n84.0\n€72.8M\n86.0\n\n\n20\n210514\nJoão Cancelo\n27\nhttps://cdn.sofifa.com/players/210/514/22_60.png\nPortugal\nhttps://cdn.sofifa.com/flags/pt.png\n86\n87\nManchester City\nhttps://cdn.sofifa.com/teams/10/30.png\n...\n80.0\n6.0\n9.0\n15.0\n14.0\n14.0\nRB\n86.0\n€137.6M\n79.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13109\n203430\nG. Ray\n27\nhttps://cdn.sofifa.com/players/203/430/22_60.png\nWales\nhttps://cdn.sofifa.com/flags/gb-wls.png\n59\n60\nExeter City\nhttps://cdn.sofifa.com/teams/143/30.png\n...\n59.0\n13.0\n10.0\n12.0\n9.0\n8.0\nCB\n60.0\n€420K\n58.0\n\n\n13124\n187154\nN. Canavan\n30\nhttps://cdn.sofifa.com/players/187/154/22_60.png\nRepublic of Ireland\nhttps://cdn.sofifa.com/flags/ie.png\n63\n63\nBradford City\nhttps://cdn.sofifa.com/teams/1804/30.png\n...\n62.0\n6.0\n10.0\n11.0\n14.0\n6.0\nCB\n63.0\n€700K\n63.0\n\n\n13183\n263968\nK. Sow\n18\nhttps://cdn.sofifa.com/players/263/968/22_60.png\nSwitzerland\nhttps://cdn.sofifa.com/flags/ch.png\n54\n76\nFC Lausanne-Sport\nhttps://cdn.sofifa.com/teams/1862/30.png\n...\n55.0\n6.0\n9.0\n13.0\n7.0\n14.0\nCB\n56.0\n€796K\n54.0\n\n\n13238\n263022\nM. Rosenfelder\n18\nhttps://cdn.sofifa.com/players/263/022/22_60.png\nGermany\nhttps://cdn.sofifa.com/flags/de.png\n57\n71\nSC Freiburg II\nhttps://cdn.sofifa.com/teams/110691/30.png\n...\n60.0\n10.0\n10.0\n8.0\n10.0\n11.0\nCB\n59.0\n€726K\n58.0\n\n\n13405\n261062\nLee Han Beom\n19\nhttps://cdn.sofifa.com/players/261/062/22_60.png\nKorea Republic\nhttps://cdn.sofifa.com/flags/kr.png\n53\n72\nFC Seoul\nhttps://cdn.sofifa.com/teams/982/30.png\n...\n53.0\n7.0\n14.0\n5.0\n6.0\n15.0\nCB\n55.0\n€431K\n52.0\n\n\n\n\n3298 rows × 63 columns\n\n\n\n\ntidydata = df_e.loc[(df_e.Position == \"DEFENDER\") | (df_e.Position == \"FORWARD\")]\n\n\nfig = ggplot(tidydata)\npoint = geom_point(aes(x = 'ShotPower', y = 'SlidingTackle', color = 'Position', size = 'Wage', alpha = 'Wage'), position = 'jitter')\n\nfig + point\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n해치웠나…?\n\n결론\n\n- 데이터의 결측치를 반드시 먼저 처리하고 하자!(dropna()의 필요성)\n- pop()을 사용하기 전에는 결측치를 반드시 모두 없애자!\n- 데이터를 가공하여 순서가 바뀐 경우 왠만해선 인덱스를 초기화해주자!(reset_index()의 필요성)"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "",
    "text": "열 이름 변경, 열 추가, 리스트 컴프리헨션, 결측치 파악, query, 매핑 등등… 해당 내용은 왠만해선 다 알아두는 게 좋다."
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#import",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#import",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "1. import",
    "text": "1. import\n\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-기본기능",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-기본기능",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "2. Pandas 기본기능",
    "text": "2. Pandas 기본기능\n\nA. 열의 이름 변경\n\n\ndf = pd.DataFrame(np.random.randn(3, 2))\ndf\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n-0.000655\n0.686701\n\n\n1\n0.591774\n0.842045\n\n\n2\n-0.027722\n-0.703161\n\n\n\n\n\n\n\n- 방법1 : df.columns에 대입\n\ndf.columns = ['A', 'B']\ndf\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\n-0.000655\n0.686701\n\n\n1\n0.591774\n0.842045\n\n\n2\n-0.027722\n-0.703161\n\n\n\n\n\n\n\n- 방법2 : df.set_axis() \\(\\star\\star\\star\\)\n\ndf2 = pd.DataFrame(np.random.randn(5,3))\ndf2\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n0.200618\n-0.567175\n-0.249051\n\n\n1\n0.805185\n-0.479624\n0.797904\n\n\n2\n-1.278647\n-0.061503\n1.048704\n\n\n3\n0.308626\n-3.294418\n0.326681\n\n\n4\n1.585979\n-1.200001\n0.386765\n\n\n\n\n\n\n\n\ndf2 = df2.set_axis(['A','B','C'], axis = 1)\ndf2\n\n#df2.set_axis(['a','b','c','d,',e'], axis = 0)으로 하면 인덱스가 바뀐다.\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n0.200618\n-0.567175\n-0.249051\n\n\n1\n0.805185\n-0.479624\n0.797904\n\n\n2\n-1.278647\n-0.061503\n1.048704\n\n\n3\n0.308626\n-3.294418\n0.326681\n\n\n4\n1.585979\n-1.200001\n0.386765\n\n\n\n\n\n\n\n- 방법3 : df.rename()\n\ndf3 = pd.DataFrame(np.random.randn(5,3))\ndf3\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n0.202540\n0.265273\n1.855420\n\n\n1\n-0.422516\n-0.954117\n-0.050532\n\n\n2\n-0.010961\n-1.681503\n-1.613766\n\n\n3\n0.855199\n0.773191\n1.149413\n\n\n4\n0.310184\n-0.063591\n-0.572836\n\n\n\n\n\n\n\n\ndf3.rename({0 : 'A'}, axis = 1) ## dictionary 형태로 지정, 특정 열만 바꿈\n##df3.rename(columns = {0 : 'A'})와 동일\n\n\n\n\n\n\n\n\nA\n1\n2\n\n\n\n\n0\n0.202540\n0.265273\n1.855420\n\n\n1\n-0.422516\n-0.954117\n-0.050532\n\n\n2\n-0.010961\n-1.681503\n-1.613766\n\n\n3\n0.855199\n0.773191\n1.149413\n\n\n4\n0.310184\n-0.063591\n-0.572836"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-행의-이름-변경",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-행의-이름-변경",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### B. 행의 이름 변경",
    "text": "### B. 행의 이름 변경\n- 방법1 : df.index에 대입\n\ndf = pd.DataFrame(np.random.randn(2,3))\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n0.108275\n-0.802206\n-3.011323\n\n\n1\n-1.437775\n-1.868590\n-0.079212\n\n\n\n\n\n\n\n\ndf.index = ['a', 'b']\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\na\n0.108275\n-0.802206\n-3.011323\n\n\nb\n-1.437775\n-1.868590\n-0.079212\n\n\n\n\n\n\n\n- 방법2 : df.set_axis() \\(\\star\\star\\star\\)\n\ndf = pd.DataFrame(np.random.randn(2,3))\ndf\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n-0.179379\n0.684650\n1.678079\n\n\n1\n0.487614\n-1.358992\n-0.661587\n\n\n\n\n\n\n\n\ndf.set_axis(['1','2'], axis = 0)\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n1\n-0.179379\n0.684650\n1.678079\n\n\n2\n0.487614\n-1.358992\n-0.661587\n\n\n\n\n\n\n\n- 방법3 : df.rename()\n\ndf = pd.DataFrame(np.random.randn(2,3))\ndf\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n-0.051285\n1.185885\n0.841335\n\n\n1\n0.118555\n1.527457\n0.544870\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf.rename({0 : 'A'}, axis = 0)    ## default = 0\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n\n\n\n\nA\n-0.051285\n1.185885\n0.841335\n\n\n1\n0.118555\n1.527457\n0.544870\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n- 방법 4 : df.set_index() &gt; 임의의 열을 행이름으로 지정, 이미 있던 열 하나를 인덱스로 잡고 싶을 시 사용\n\ndf = pd.DataFrame({'id':['2020-43052','2021-43053'], 'X1':[1,2],'X2':[2,3]})\ndf\n\n\n\n\n\n\n\n\nid\nX1\nX2\n\n\n\n\n0\n2020-43052\n1\n2\n\n\n1\n2021-43053\n2\n3\n\n\n\n\n\n\n\n\ndf.set_index('id')\n\n\n\n\n\n\n\n\nX1\nX2\n\n\nid\n\n\n\n\n\n\n2020-43052\n1\n2\n\n\n2021-43053\n2\n3\n\n\n\n\n\n\n\n\n# A~B에 대한 연습문제\n\n- 데이터 load\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\ndf.head()\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n0\n209658\nL. Goretzka\n27\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\nNaN\n2026\n189cm\n82kg\n€157M\n8.0\nNaN\n\n\n1\n212198\nBruno Fernandes\n27\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\nNaN\n2026\n179cm\n69kg\n€155M\n8.0\nNaN\n\n\n2\n224334\nM. Acuña\n30\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n...\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\nNaN\n2024\n172cm\n69kg\n€97.7M\n19.0\nNaN\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\nNaN\n2025\n181cm\n70kg\n€198.9M\n17.0\nNaN\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\nNaN\n2026\n172cm\n68kg\n€154.4M\n23.0\nNaN\n\n\n\n\n5 rows × 29 columns\n\n\n\n# 예제1 : 열의 이름을 출력하고, 열의 이름중 공백()이 있을 경우 언더바(_) 로 바꾸자.\n\ndf.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n- 방법1 : df.columns에 직접 대입\n\ndf_ = df\ndf_.columns = [i.replace(' ', '_') for i in df_.columns]\n\n\ndf_.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club_Logo', 'Value', 'Wage', 'Special',\n       'Preferred_Foot', 'International_Reputation', 'Weak_Foot',\n       'Skill_Moves', 'Work_Rate', 'Body_Type', 'Real_Face', 'Position',\n       'Joined', 'Loaned_From', 'Contract_Valid_Until', 'Height', 'Weight',\n       'Release_Clause', 'Kit_Number', 'Best_Overall_Rating'],\n      dtype='object')\n\n\n- 방법2 : set_axis() 이용 \\(\\star\\star\\star\\)\n\ndf_ = df\ndf_.set_axis([col.replace(' ', '_') for col in df_.columns], axis = 1).columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club_Logo', 'Value', 'Wage', 'Special',\n       'Preferred_Foot', 'International_Reputation', 'Weak_Foot',\n       'Skill_Moves', 'Work_Rate', 'Body_Type', 'Real_Face', 'Position',\n       'Joined', 'Loaned_From', 'Contract_Valid_Until', 'Height', 'Weight',\n       'Release_Clause', 'Kit_Number', 'Best_Overall_Rating'],\n      dtype='object')\n\n\n- 방법 3 : rename() 이용(안중요함)\n\ntemp3 = df\n\ndic = {i:i.replace(' ','_') for i in df.columns}\ntemp3.rename(dic, axis = 1).columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club_Logo', 'Value', 'Wage', 'Special',\n       'Preferred_Foot', 'International_Reputation', 'Weak_Foot',\n       'Skill_Moves', 'Work_Rate', 'Body_Type', 'Real_Face', 'Position',\n       'Joined', 'Loaned_From', 'Contract_Valid_Until', 'Height', 'Weight',\n       'Release_Clause', 'Kit_Number', 'Best_Overall_Rating'],\n      dtype='object')\n\n\n# 예제2: ID를 row-index로 지정하라.\n\ndf.ID\n\n0        209658\n1        212198\n2        224334\n3        192985\n4        224232\n          ...  \n17655    269526\n17656    267946\n17657    270567\n17658    256624\n17659    256376\nName: ID, Length: 17660, dtype: int64\n\n\n- 방법1 : 직접지정\n\ndf_ = df\ndf_.index = df.ID\ndf_.index\n\nIndex([209658, 212198, 224334, 192985, 224232, 212622, 197445, 187961, 208333,\n       210514,\n       ...\n       256879, 269546, 267647, 253186, 267461, 269526, 267946, 270567, 256624,\n       256376],\n      dtype='int64', name='ID', length=17660)\n\n\n- 방법2 : set_axis() \\(\\star\\star\\star\\)\n\ndf_ = df\ndf_ = df_.set_axis(df.ID)   ## default : axis = 0, df_.set_axis(df.ID, axis = 0)과 동일\ndf_.index\n\nInt64Index([209658, 212198, 224334, 192985, 224232, 212622, 197445, 187961,\n            208333, 210514,\n            ...\n            256879, 269546, 267647, 253186, 267461, 269526, 267946, 270567,\n            256624, 256376],\n           dtype='int64', name='ID', length=17660)\n\n\n- 방법3 : set_index()\n\n이 경우 해당 열을 나중에 따로 드랍하지 않아도 됨\n\n\ndf_ = df\ndf_ = df_.set_index('ID')\ndf_.index\n\nIndex([209658, 212198, 224334, 192985, 224232, 212622, 197445, 187961, 208333,\n       210514,\n       ...\n       256879, 269546, 267647, 253186, 267461, 269526, 267946, 270567, 256624,\n       256376],\n      dtype='int64', name='ID', length=17660)"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#c.-df.t-데이터프레임을-전치",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#c.-df.t-데이터프레임을-전치",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### C. df.T | 데이터프레임을 전치",
    "text": "### C. df.T | 데이터프레임을 전치\ndf.T를 이용하여 데이터를 살피면 편리함\n- data load\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\ndf.head()\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n0\n209658\nL. Goretzka\n27\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\nNaN\n2026\n189cm\n82kg\n€157M\n8.0\nNaN\n\n\n1\n212198\nBruno Fernandes\n27\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\nNaN\n2026\n179cm\n69kg\n€155M\n8.0\nNaN\n\n\n2\n224334\nM. Acuña\n30\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n...\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\nNaN\n2024\n172cm\n69kg\n€97.7M\n19.0\nNaN\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\nNaN\n2025\n181cm\n70kg\n€198.9M\n17.0\nNaN\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\nNaN\n2026\n172cm\n68kg\n€154.4M\n23.0\nNaN\n\n\n\n\n5 rows × 29 columns\n\n\n\n- df.T : 데이터프레임을 전치(transition)한다.\n\ndf.T.loc[:,:3]\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\nID\n209658\n212198\n224334\n192985\n\n\nName\nL. Goretzka\nBruno Fernandes\nM. Acuña\nK. De Bruyne\n\n\nAge\n27\n27\n30\n31\n\n\nPhoto\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nhttps://cdn.sofifa.net/players/192/985/23_60.png\n\n\nNationality\nGermany\nPortugal\nArgentina\nBelgium\n\n\nFlag\nhttps://cdn.sofifa.net/flags/de.png\nhttps://cdn.sofifa.net/flags/pt.png\nhttps://cdn.sofifa.net/flags/ar.png\nhttps://cdn.sofifa.net/flags/be.png\n\n\nOverall\n87\n86\n85\n91\n\n\nPotential\n88\n87\n85\n91\n\n\nClub\nFC Bayern München\nManchester United\nSevilla FC\nManchester City\n\n\nClub Logo\nhttps://cdn.sofifa.net/teams/21/30.png\nhttps://cdn.sofifa.net/teams/11/30.png\nhttps://cdn.sofifa.net/teams/481/30.png\nhttps://cdn.sofifa.net/teams/10/30.png\n\n\nValue\n€91M\n€78.5M\n€46.5M\n€107.5M\n\n\nWage\n€115K\n€190K\n€46K\n€350K\n\n\nSpecial\n2312\n2305\n2303\n2303\n\n\nPreferred Foot\nRight\nRight\nLeft\nRight\n\n\nInternational Reputation\n4.0\n3.0\n2.0\n4.0\n\n\nWeak Foot\n4.0\n3.0\n3.0\n5.0\n\n\nSkill Moves\n3.0\n4.0\n3.0\n4.0\n\n\nWork Rate\nHigh/ Medium\nHigh/ High\nHigh/ High\nHigh/ High\n\n\nBody Type\nUnique\nUnique\nStocky (170-185)\nUnique\n\n\nReal Face\nYes\nYes\nNo\nYes\n\n\nPosition\n&lt;span class=\"pos pos28\"&gt;SUB\n&lt;span class=\"pos pos15\"&gt;LCM\n&lt;span class=\"pos pos7\"&gt;LB\n&lt;span class=\"pos pos13\"&gt;RCM\n\n\nJoined\nJul 1, 2018\nJan 30, 2020\nSep 14, 2020\nAug 30, 2015\n\n\nLoaned From\nNaN\nNaN\nNaN\nNaN\n\n\nContract Valid Until\n2026\n2026\n2024\n2025\n\n\nHeight\n189cm\n179cm\n172cm\n181cm\n\n\nWeight\n82kg\n69kg\n69kg\n70kg\n\n\nRelease Clause\n€157M\n€155M\n€97.7M\n€198.9M\n\n\nKit Number\n8.0\n8.0\n19.0\n17.0\n\n\nBest Overall Rating\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n- 출력옵션 조정\n\npd.options.display.max_rows = 10\ndisplay(df.T.iloc[:, :3])\npd.reset_option('display.max_rows')   ## 디폴트 옵션으로 변경\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\nID\n209658\n212198\n224334\n\n\nName\nL. Goretzka\nBruno Fernandes\nM. Acuña\n\n\nAge\n27\n27\n30\n\n\nPhoto\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nhttps://cdn.sofifa.net/players/224/334/23_60.png\n\n\nNationality\nGermany\nPortugal\nArgentina\n\n\n...\n...\n...\n...\n\n\nHeight\n189cm\n179cm\n172cm\n\n\nWeight\n82kg\n69kg\n69kg\n\n\nRelease Clause\n€157M\n€155M\n€97.7M\n\n\nKit Number\n8.0\n8.0\n19.0\n\n\nBest Overall Rating\nNaN\nNaN\nNaN\n\n\n\n\n29 rows × 3 columns\n\n\n\n\n여기선 설명을 위해 줄이는 옵션을 사용했지만, 보통은 늘려서 사용함."
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#d.-df.dtypes-sdtype-데이터의-타입-산출",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#d.-df.dtypes-sdtype-데이터의-타입-산출",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### D. df.dtypes, s,dtype | 데이터의 타입 산출",
    "text": "### D. df.dtypes, s,dtype | 데이터의 타입 산출\n- df.dtypes\n\n데이터프레임 각 열에 저장된 데이터들의 타입을 알려준다.\n\n\ndf.dtypes\n\nID                            int64\nName                         object\nAge                           int64\nPhoto                        object\nNationality                  object\nFlag                         object\nOverall                       int64\nPotential                     int64\nClub                         object\nClub Logo                    object\nValue                        object\nWage                         object\nSpecial                       int64\nPreferred Foot               object\nInternational Reputation    float64\nWeak Foot                   float64\nSkill Moves                 float64\nWork Rate                    object\nBody Type                    object\nReal Face                    object\nPosition                     object\nJoined                       object\nLoaned From                  object\nContract Valid Until         object\nHeight                       object\nWeight                       object\nRelease Clause               object\nKit Number                  float64\nBest Overall Rating          object\ndtype: object\n\n\n\nobject : string이라고 생각해도 무방. 범주형 자료.\n\n- s.dtype Series에 붙여 사용\n\ndf.Name.dtype   ## 한 행의 데이터 타입만을 산출\n\ndtype('O')\n\n\n\n다양한 활용이 가능\n\n\ndf.Name.dtype == np.object_\n\nTrue\n\n\n\ndf.Age.dtype == np.int64\n\nTrue\n\n\n\ndf['International Reputation'].dtype == np.float64\n\nTrue\n\n\n\nbool을 산출하니까 컴프리헨션에 조건문 걸어서 해도 되고… 활용의 여지가 넓다.\n\n# 예제: df에서 int64 자료형만 출력\n- 풀이 1 : 표를 보고 직접 뽑음\n\npd.Series(list(df.dtypes))\n\n0       int64\n1      object\n2       int64\n3      object\n4      object\n5      object\n6       int64\n7       int64\n8      object\n9      object\n10     object\n11     object\n12      int64\n13     object\n14    float64\n15    float64\n16    float64\n17     object\n18     object\n19     object\n20     object\n21     object\n22     object\n23     object\n24     object\n25     object\n26     object\n27    float64\n28     object\ndtype: object\n\n\n\ndf.iloc[:, [0,2,6,7,12]]\n\n\n\n\n\n\n\n\nID\nAge\nOverall\nPotential\nSpecial\n\n\n\n\n0\n209658\n27\n87\n88\n2312\n\n\n1\n212198\n27\n86\n87\n2305\n\n\n2\n224334\n30\n85\n85\n2303\n\n\n3\n192985\n31\n91\n91\n2303\n\n\n4\n224232\n25\n86\n89\n2296\n\n\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\n19\n48\n61\n762\n\n\n17656\n267946\n17\n48\n64\n761\n\n\n17657\n270567\n25\n51\n56\n759\n\n\n17658\n256624\n18\n50\n65\n758\n\n\n17659\n256376\n20\n50\n61\n749\n\n\n\n\n17660 rows × 5 columns\n\n\n\n- 풀이 2 : 리스트 컴프리핸션 이용\n\ndf.loc[:, [o == np.int64 for o in df.dtypes]]\n##df.loc[:, [o == 'int64' for o in df.dtypes]]\n\n\n\n\n\n\n\n\nID\nAge\nOverall\nPotential\nSpecial\n\n\n\n\n0\n209658\n27\n87\n88\n2312\n\n\n1\n212198\n27\n86\n87\n2305\n\n\n2\n224334\n30\n85\n85\n2303\n\n\n3\n192985\n31\n91\n91\n2303\n\n\n4\n224232\n25\n86\n89\n2296\n\n\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\n19\n48\n61\n762\n\n\n17656\n267946\n17\n48\n64\n761\n\n\n17657\n270567\n25\n51\n56\n759\n\n\n17658\n256624\n18\n50\n65\n758\n\n\n17659\n256376\n20\n50\n61\n749\n\n\n\n\n17660 rows × 5 columns"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#e.-df.sort_values-데이터들을-정렬",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#e.-df.sort_values-데이터들을-정렬",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### E. df.sort_values() | 데이터들을 정렬",
    "text": "### E. df.sort_values() | 데이터들을 정렬\n- 예시1 : 순서대로 정렬\n\ndf.sort_values('Age')   ## 나이가 어린 순서대로 오름차순 정렬 / 인덱스 개판\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n17636\n263636\n22 D. Oncescu\n15\nhttps://cdn.sofifa.net/players/263/636/22_60.png\nRomania\nhttps://cdn.sofifa.net/flags/ro.png\n50\n72\nFC Dinamo 1948 Bucureşti\nhttps://cdn.sofifa.net/teams/100757/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 1, 2021\nNaN\n2025\n190cm\n77kg\n€306K\n34.0\nNaN\n\n\n13712\n271072\nE. Topcu\n16\nhttps://cdn.sofifa.net/players/271/072/23_60.png\nRepublic of Ireland\nhttps://cdn.sofifa.net/flags/ie.png\n48\n58\nDrogheda United\nhttps://cdn.sofifa.net/teams/1572/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJul 8, 2022\nNaN\n2022\n183cm\n65kg\n€175K\n20.0\nNaN\n\n\n13078\n259442\n22 R. van den Berg\n16\nhttps://cdn.sofifa.net/players/259/442/22_60.png\nNetherlands\nhttps://cdn.sofifa.net/flags/nl.png\n60\n81\nPEC Zwolle\nhttps://cdn.sofifa.net/teams/1914/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nMay 24, 2020\nNaN\n2024\n190cm\n73kg\n€1.8M\n33.0\nNaN\n\n\n11257\n266205\n22 Y. Koré\n16\nhttps://cdn.sofifa.net/players/266/205/22_60.png\nFrance\nhttps://cdn.sofifa.net/flags/fr.png\n59\n74\nParis FC\nhttps://cdn.sofifa.net/teams/111817/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nAug 11, 2022\nNaN\n2025\n187cm\n75kg\n€1.1M\n34.0\nNaN\n\n\n11278\n261873\n21 H. Kumagai\n16\nhttps://cdn.sofifa.net/players/261/873/21_60.png\nJapan\nhttps://cdn.sofifa.net/flags/jp.png\n52\n70\nVegalta Sendai\nhttps://cdn.sofifa.net/teams/112836/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 16, 2021\nNaN\n2023\n174cm\n64kg\n€375K\n48.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16311\n254196\n21 L. Fernández\n42\nhttps://cdn.sofifa.net/players/254/196/21_60.png\nColombia\nhttps://cdn.sofifa.net/flags/co.png\n61\n61\nSociedad Deportiva Aucas\nhttps://cdn.sofifa.net/teams/110987/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nJan 29, 2018\nNaN\n2024\n187cm\n82kg\n€75K\n1.0\nNaN\n\n\n16036\n216692\nS. Torrico\n42\nhttps://cdn.sofifa.net/players/216/692/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n72\n72\nSan Lorenzo de Almagro\nhttps://cdn.sofifa.net/teams/1013/30.png\n...\nNo\n&lt;span class=\"pos pos0\"&gt;GK\nApr 25, 2013\nNaN\n2022\n183cm\n84kg\n€375K\n12.0\nNaN\n\n\n17257\n645\n17 D. Andersson\n43\nhttps://cdn.sofifa.net/players/000/645/17_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n57\n57\nHelsingborgs IF\nhttps://cdn.sofifa.net/teams/432/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nApr 21, 2016\nNaN\n2022\n187cm\n85kg\nNaN\n39.0\nNaN\n\n\n15375\n1179\nG. Buffon\n44\nhttps://cdn.sofifa.net/players/001/179/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n79\n79\nParma\nhttps://cdn.sofifa.net/teams/50/30.png\n...\nYes\n&lt;span class=\"pos pos0\"&gt;GK\nJul 1, 2021\nNaN\n2024\n192cm\n92kg\n€3M\n1.0\nNaN\n\n\n15272\n254704\n22 K. Miura\n54\nhttps://cdn.sofifa.net/players/254/704/22_60.png\nJapan\nhttps://cdn.sofifa.net/flags/jp.png\n56\n56\nYokohama FC\nhttps://cdn.sofifa.net/teams/113197/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJul 1, 2005\nNaN\n2022\n177cm\n72kg\nNaN\n11.0\nNaN\n\n\n\n\n17660 rows × 29 columns\n\n\n\n- 예시 2 : 내림차순으로 정렬\n\ndf.sort_values('Age', ascending = False)  ## default : ascending = True\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n15272\n254704\n22 K. Miura\n54\nhttps://cdn.sofifa.net/players/254/704/22_60.png\nJapan\nhttps://cdn.sofifa.net/flags/jp.png\n56\n56\nYokohama FC\nhttps://cdn.sofifa.net/teams/113197/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJul 1, 2005\nNaN\n2022\n177cm\n72kg\nNaN\n11.0\nNaN\n\n\n15375\n1179\nG. Buffon\n44\nhttps://cdn.sofifa.net/players/001/179/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n79\n79\nParma\nhttps://cdn.sofifa.net/teams/50/30.png\n...\nYes\n&lt;span class=\"pos pos0\"&gt;GK\nJul 1, 2021\nNaN\n2024\n192cm\n92kg\n€3M\n1.0\nNaN\n\n\n17257\n645\n17 D. Andersson\n43\nhttps://cdn.sofifa.net/players/000/645/17_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n57\n57\nHelsingborgs IF\nhttps://cdn.sofifa.net/teams/432/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nApr 21, 2016\nNaN\n2022\n187cm\n85kg\nNaN\n39.0\nNaN\n\n\n16036\n216692\nS. Torrico\n42\nhttps://cdn.sofifa.net/players/216/692/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n72\n72\nSan Lorenzo de Almagro\nhttps://cdn.sofifa.net/teams/1013/30.png\n...\nNo\n&lt;span class=\"pos pos0\"&gt;GK\nApr 25, 2013\nNaN\n2022\n183cm\n84kg\n€375K\n12.0\nNaN\n\n\n16311\n254196\n21 L. Fernández\n42\nhttps://cdn.sofifa.net/players/254/196/21_60.png\nColombia\nhttps://cdn.sofifa.net/flags/co.png\n61\n61\nSociedad Deportiva Aucas\nhttps://cdn.sofifa.net/teams/110987/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nJan 29, 2018\nNaN\n2024\n187cm\n82kg\n€75K\n1.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17360\n261023\n21 H. Broun\n16\nhttps://cdn.sofifa.net/players/261/023/21_60.png\nScotland\nhttps://cdn.sofifa.net/flags/gb-sct.png\n52\n72\nKilmarnock\nhttps://cdn.sofifa.net/teams/82/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nSep 17, 2020\nNaN\n2022\n182cm\n70kg\n€523K\n40.0\nNaN\n\n\n15536\n263639\n22 M. Pavel\n16\nhttps://cdn.sofifa.net/players/263/639/22_60.png\nRomania\nhttps://cdn.sofifa.net/flags/ro.png\n51\n69\nFC Dinamo 1948 Bucureşti\nhttps://cdn.sofifa.net/teams/100757/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJul 1, 2021\nNaN\n2023\n178cm\n66kg\n€277K\n77.0\nNaN\n\n\n11398\n256405\n21 W. Essanoussi\n16\nhttps://cdn.sofifa.net/players/256/405/21_60.png\nNetherlands\nhttps://cdn.sofifa.net/flags/nl.png\n59\n75\nVVV-Venlo\nhttps://cdn.sofifa.net/teams/100651/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJul 1, 2019\nNaN\n2022\n178cm\n70kg\n€1.1M\n24.0\nNaN\n\n\n15030\n270594\nT. Walczak\n16\nhttps://cdn.sofifa.net/players/270/594/23_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n54\n68\nWisła Płock\nhttps://cdn.sofifa.net/teams/1569/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nSep 7, 2021\nNaN\n2023\n191cm\n88kg\n€494K\n99.0\nNaN\n\n\n17636\n263636\n22 D. Oncescu\n15\nhttps://cdn.sofifa.net/players/263/636/22_60.png\nRomania\nhttps://cdn.sofifa.net/flags/ro.png\n50\n72\nFC Dinamo 1948 Bucureşti\nhttps://cdn.sofifa.net/teams/100757/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 1, 2021\nNaN\n2025\n190cm\n77kg\n€306K\n34.0\nNaN\n\n\n\n\n17660 rows × 29 columns\n\n\n\n- 예시 3 : 능력치가 좋은 순서대로 정렬\n\ndf.sort_values(by = 'Overall', ascending = False)    ## 수가 높을수록 위로 가니까, by 생략해도 됨.\n\n\n  \n    \n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n41\n188545\nR. Lewandowski\n33\nhttps://cdn.sofifa.net/players/188/545/23_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n91\n91\nFC Barcelona\nhttps://cdn.sofifa.net/teams/241/30.png\n...\nYes\n&lt;span class=\"pos pos25\"&gt;ST\nJul 18, 2022\nNaN\n2025\n185cm\n81kg\n€172.2M\n9.0\nNaN\n\n\n124\n165153\nK. Benzema\n34\nhttps://cdn.sofifa.net/players/165/153/23_60.png\nFrance\nhttps://cdn.sofifa.net/flags/fr.png\n91\n91\nReal Madrid CF\nhttps://cdn.sofifa.net/teams/243/30.png\n...\nYes\n&lt;span class=\"pos pos21\"&gt;CF\nJul 9, 2009\nNaN\n2023\n185cm\n81kg\n€131.2M\n9.0\nNaN\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\nNaN\n2025\n181cm\n70kg\n€198.9M\n17.0\nNaN\n\n\n56\n158023\nL. Messi\n35\nhttps://cdn.sofifa.net/players/158/023/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n91\n91\nParis Saint-Germain\nhttps://cdn.sofifa.net/teams/73/30.png\n...\nYes\n&lt;span class=\"pos pos23\"&gt;RW\nAug 10, 2021\nNaN\n2023\n169cm\n67kg\n€99.9M\n30.0\nNaN\n\n\n75\n231747\nK. Mbappé\n23\nhttps://cdn.sofifa.net/players/231/747/23_60.png\nFrance\nhttps://cdn.sofifa.net/flags/fr.png\n91\n95\nParis Saint-Germain\nhttps://cdn.sofifa.net/teams/73/30.png\n...\nYes\n&lt;span class=\"pos pos25\"&gt;ST\nJul 1, 2018\nNaN\n2025\n182cm\n73kg\n€366.7M\n7.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n15513\n266751\n22 Jung Ho Yeon\n20\nhttps://cdn.sofifa.net/players/266/751/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n45\n53\nGwangJu FC\nhttps://cdn.sofifa.net/teams/112258/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 20, 2022\nNaN\n2026\n180cm\n73kg\n€145K\n23.0\nNaN\n\n\n16215\n268279\n22 J. Looschen\n24\nhttps://cdn.sofifa.net/players/268/279/22_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n44\n47\nSV Meppen\nhttps://cdn.sofifa.net/teams/110597/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nMar 19, 2022\nNaN\n2026\n178cm\n78kg\n€92K\n42.0\nNaN\n\n\n16042\n255283\n20 Kim Yeong Geun\n22\nhttps://cdn.sofifa.net/players/255/283/20_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n44\n49\nGyeongnam FC\nhttps://cdn.sofifa.net/teams/111588/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 9, 2020\nNaN\n2020\n174cm\n71kg\n€53K\n43.0\nNaN\n\n\n14634\n269038\n22 Zhang Wenxuan\n16\nhttps://cdn.sofifa.net/players/269/038/22_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n44\n59\nGuangzhou FC\nhttps://cdn.sofifa.net/teams/111839/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nMay 1, 2022\nNaN\n2022\n175cm\n70kg\n€239K\n29.0\nNaN\n\n\n17618\n168933\n07 I. Paskov\n33\nhttps://cdn.sofifa.net/players/168/933/07_60.png\nBulgaria\nhttps://cdn.sofifa.net/flags/bg.png\n43\n42\nNaN\nhttps://cdn.sofifa.net/flags/bg.png\n...\nNaN\n&lt;span class=\"pos pos28\"&gt;SUB\nNaN\nNaN\nNaN\n184cm\n79kg\nNaN\n24.0\nNaN\n\n\n\n\n\n17660 rows × 29 columns"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#f.-df.info-행별-information-산출",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#f.-df.info-행별-information-산출",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### F. df.info() | 행별 information 산출",
    "text": "### F. df.info() | 행별 information 산출\n시험에는 절대 안 낼 거지만 매우 중요한 것\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 17660 entries, 0 to 17659\nData columns (total 29 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ID                        17660 non-null  int64  \n 1   Name                      17660 non-null  object \n 2   Age                       17660 non-null  int64  \n 3   Photo                     17660 non-null  object \n 4   Nationality               17660 non-null  object \n 5   Flag                      17660 non-null  object \n 6   Overall                   17660 non-null  int64  \n 7   Potential                 17660 non-null  int64  \n 8   Club                      17449 non-null  object \n 9   Club Logo                 17660 non-null  object \n 10  Value                     17660 non-null  object \n 11  Wage                      17660 non-null  object \n 12  Special                   17660 non-null  int64  \n 13  Preferred Foot            17660 non-null  object \n 14  International Reputation  17660 non-null  float64\n 15  Weak Foot                 17660 non-null  float64\n 16  Skill Moves               17660 non-null  float64\n 17  Work Rate                 17660 non-null  object \n 18  Body Type                 17622 non-null  object \n 19  Real Face                 17622 non-null  object \n 20  Position                  17625 non-null  object \n 21  Joined                    16562 non-null  object \n 22  Loaned From               694 non-null    object \n 23  Contract Valid Until      17299 non-null  object \n 24  Height                    17660 non-null  object \n 25  Weight                    17660 non-null  object \n 26  Release Clause            16509 non-null  object \n 27  Kit Number                17625 non-null  float64\n 28  Best Overall Rating       21 non-null     object \ndtypes: float64(4), int64(5), object(20)\nmemory usage: 3.9+ MB\n\n\n\ndata들의 현황을 한눈에 파악하기 좋다.\n\n\ndf.iloc[:, [28]].sort_values('Best Overall Rating')\n\n\n  \n    \n\n\n\n\n\n\nBest Overall Rating\n\n\n\n\n13299\n&lt;span class=\"bp3-tag p p-54\"&gt;54&lt;/span&gt;\n\n\n14366\n&lt;span class=\"bp3-tag p p-56\"&gt;56&lt;/span&gt;\n\n\n16779\n&lt;span class=\"bp3-tag p p-58\"&gt;58&lt;/span&gt;\n\n\n16968\n&lt;span class=\"bp3-tag p p-58\"&gt;58&lt;/span&gt;\n\n\n16835\n&lt;span class=\"bp3-tag p p-59\"&gt;59&lt;/span&gt;\n\n\n...\n...\n\n\n17655\nNaN\n\n\n17656\nNaN\n\n\n17657\nNaN\n\n\n17658\nNaN\n\n\n17659\nNaN\n\n\n\n\n\n17660 rows × 1 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf.loc[:, ['Best Overall Rating']].isna().sum()\n\nBest Overall Rating    17639\ndtype: int64\n\n\n\n결측치가 매우 많은 것을 볼 수 있다."
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#g.-df.isna-각-원소가-결측치인지-아닌지-산출",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#g.-df.isna-각-원소가-결측치인지-아닌지-산출",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### G. df.isna()| 각 원소가 결측치인지 아닌지 산출",
    "text": "### G. df.isna()| 각 원소가 결측치인지 아닌지 산출\n- 예시 1 : 열별로 결측치 카운트\n\ndf.isna()   ## NaN 값이 있다면 True 산출\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n17656\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n17657\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n17658\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n17659\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n\n\n17660 rows × 29 columns\n\n\n\n\ndf.isna().sum(axis = 0)   ## default : axis = 0\n\nID                              0\nName                            0\nAge                             0\nPhoto                           0\nNationality                     0\nFlag                            0\nOverall                         0\nPotential                       0\nClub                          211\nClub Logo                       0\nValue                           0\nWage                            0\nSpecial                         0\nPreferred Foot                  0\nInternational Reputation        0\nWeak Foot                       0\nSkill Moves                     0\nWork Rate                       0\nBody Type                      38\nReal Face                      38\nPosition                       35\nJoined                       1098\nLoaned From                 16966\nContract Valid Until          361\nHeight                          0\nWeight                          0\nRelease Clause               1151\nKit Number                     35\nBest Overall Rating         17639\ndtype: int64\n\n\n\narr = np.array([(True, False), (True, False), (False, True)])\narr\n\narray([[ True, False],\n       [ True, False],\n       [False,  True]])\n\n\n\narr.shape\n\n(3, 2)\n\n\n\narr.sum(axis = 0) ## 열별로 합\n\narray([2, 1])\n\n\n\narr.sum(axis = 1)   ## 행별로 합\n\narray([1, 1, 1])\n\n\n- 예시2 : 결측치가 50% 이상인 열 출력\n\ntype(df.isna().mean() &gt; 0.5)  ## 이 값 자체가 시리즈이므로 리스트로 넣으면 안된다.\n\npandas.core.series.Series\n\n\n\ndf.loc[:, df.isna().mean() &gt; 0.5]  ## [df.isna().mean() &gt; 0.5]는 에러뜸\n\n\n\n\n\n\n\n\nLoaned From\nBest Overall Rating\n\n\n\n\n0\nNaN\nNaN\n\n\n1\nNaN\nNaN\n\n\n2\nNaN\nNaN\n\n\n3\nNaN\nNaN\n\n\n4\nNaN\nNaN\n\n\n...\n...\n...\n\n\n17655\nNaN\nNaN\n\n\n17656\nNaN\nNaN\n\n\n17657\nNaN\nNaN\n\n\n17658\nNaN\nNaN\n\n\n17659\nNaN\nNaN\n\n\n\n\n17660 rows × 2 columns"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#h.-df.drop-특정-행이나-열을-drop",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#h.-df.drop-특정-행이나-열을-drop",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### H. df.drop() | 특정 행이나 열을 drop",
    "text": "### H. df.drop() | 특정 행이나 열을 drop\n- 예시 1 : [0,1,2,3] 행을 drop\n\ndf.drop([0,1,2,3])\n## df.drop([0,1,2,3], axis = 0)\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\nNaN\n2026\n172cm\n68kg\n€154.4M\n23.0\nNaN\n\n\n5\n212622\nJ. Kimmich\n27\nhttps://cdn.sofifa.net/players/212/622/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n89\n90\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nYes\n&lt;span class=\"pos pos9\"&gt;RDM\nJul 1, 2015\nNaN\n2025\n177cm\n75kg\n€182M\n6.0\nNaN\n\n\n6\n197445\nD. Alaba\n30\nhttps://cdn.sofifa.net/players/197/445/23_60.png\nAustria\nhttps://cdn.sofifa.net/flags/at.png\n86\n86\nReal Madrid CF\nhttps://cdn.sofifa.net/teams/243/30.png\n...\nYes\n&lt;span class=\"pos pos6\"&gt;LCB\nJul 1, 2021\nNaN\n2026\n180cm\n78kg\n€113.8M\n4.0\nNaN\n\n\n7\n187961\n22 Paulinho\n32\nhttps://cdn.sofifa.net/players/187/961/22_60.png\nBrazil\nhttps://cdn.sofifa.net/flags/br.png\n83\n83\nAl Ahli\nhttps://cdn.sofifa.net/teams/112387/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJul 22, 2021\nNaN\n2024\n183cm\n80kg\n€48.5M\n15.0\nNaN\n\n\n8\n208333\nE. Can\n28\nhttps://cdn.sofifa.net/players/208/333/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n82\n82\nBorussia Dortmund\nhttps://cdn.sofifa.net/teams/22/30.png\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nFeb 18, 2020\nNaN\n2024\n186cm\n86kg\n€51.9M\n23.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\nDeng Xiongtao\n19\nhttps://cdn.sofifa.net/players/269/526/23_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n48\n61\nMeizhou Hakka\nhttps://cdn.sofifa.net/teams/114628/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 11, 2022\nNaN\n2027\n190cm\n78kg\n€218K\n35.0\nNaN\n\n\n17656\n267946\n22 Lim Jun Sub\n17\nhttps://cdn.sofifa.net/players/267/946/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n48\n64\nJeju United FC\nhttps://cdn.sofifa.net/teams/1478/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2022\nNaN\n2026\n195cm\n84kg\n€188K\n21.0\nNaN\n\n\n17657\n270567\nA. Demir\n25\nhttps://cdn.sofifa.net/players/270/567/23_60.png\nTurkey\nhttps://cdn.sofifa.net/flags/tr.png\n51\n56\nÜmraniyespor\nhttps://cdn.sofifa.net/teams/113796/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 6, 2021\nNaN\n2023\n190cm\n82kg\n€142K\n12.0\nNaN\n\n\n17658\n256624\n21 S. Czajor\n18\nhttps://cdn.sofifa.net/players/256/624/21_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n50\n65\nFleetwood Town\nhttps://cdn.sofifa.net/teams/112260/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2020\nNaN\n2021\n187cm\n79kg\n€214K\n40.0\nNaN\n\n\n17659\n256376\n21 F. Jakobsson\n20\nhttps://cdn.sofifa.net/players/256/376/21_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n50\n61\nIFK Norrköping\nhttps://cdn.sofifa.net/teams/702/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 8, 2020\nNaN\n2021\n186cm\n78kg\n€131K\n30.0\nNaN\n\n\n\n\n17656 rows × 29 columns\n\n\n\n- 예시 2 : ['Name', 'Age']열을 drop\n\ndf.drop(columns = ['Name', 'Age'])\n## df.drop(['Name', 'Age'], axis = 1)\n\n\n  \n    \n\n\n\n\n\n\nID\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\nValue\nWage\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n0\n209658\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n€91M\n€115K\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\nNaN\n2026\n189cm\n82kg\n€157M\n8.0\nNaN\n\n\n1\n212198\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n€78.5M\n€190K\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\nNaN\n2026\n179cm\n69kg\n€155M\n8.0\nNaN\n\n\n2\n224334\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n€46.5M\n€46K\n...\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\nNaN\n2024\n172cm\n69kg\n€97.7M\n19.0\nNaN\n\n\n3\n192985\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n€107.5M\n€350K\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\nNaN\n2025\n181cm\n70kg\n€198.9M\n17.0\nNaN\n\n\n4\n224232\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n€89.5M\n€110K\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\nNaN\n2026\n172cm\n68kg\n€154.4M\n23.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\nhttps://cdn.sofifa.net/players/269/526/23_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n48\n61\nMeizhou Hakka\nhttps://cdn.sofifa.net/teams/114628/30.png\n€100K\n€500\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 11, 2022\nNaN\n2027\n190cm\n78kg\n€218K\n35.0\nNaN\n\n\n17656\n267946\nhttps://cdn.sofifa.net/players/267/946/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n48\n64\nJeju United FC\nhttps://cdn.sofifa.net/teams/1478/30.png\n€100K\n€500\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2022\nNaN\n2026\n195cm\n84kg\n€188K\n21.0\nNaN\n\n\n17657\n270567\nhttps://cdn.sofifa.net/players/270/567/23_60.png\nTurkey\nhttps://cdn.sofifa.net/flags/tr.png\n51\n56\nÜmraniyespor\nhttps://cdn.sofifa.net/teams/113796/30.png\n€70K\n€2K\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 6, 2021\nNaN\n2023\n190cm\n82kg\n€142K\n12.0\nNaN\n\n\n17658\n256624\nhttps://cdn.sofifa.net/players/256/624/21_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n50\n65\nFleetwood Town\nhttps://cdn.sofifa.net/teams/112260/30.png\n€90K\n€500\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2020\nNaN\n2021\n187cm\n79kg\n€214K\n40.0\nNaN\n\n\n17659\n256376\nhttps://cdn.sofifa.net/players/256/376/21_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n50\n61\nIFK Norrköping\nhttps://cdn.sofifa.net/teams/702/30.png\n€90K\n€500\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 8, 2020\nNaN\n2021\n186cm\n78kg\n€131K\n30.0\nNaN\n\n\n\n\n\n17660 rows × 27 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n결국에 axis 옵션만 기억하면 다른 parameter를 기억하지 않아도 된다.\n\n\n# G~H 에 대한 연습문제\n# 예제: 결측치가 50퍼 이상인 열을 제외하라.\n- 풀이 1 : 무지성 직접 제외\n\ndf.isna().mean()  ## := df.isna().sum() / len(df). Series\n\nID                          0.000000\nName                        0.000000\nAge                         0.000000\nPhoto                       0.000000\nNationality                 0.000000\nFlag                        0.000000\nOverall                     0.000000\nPotential                   0.000000\nClub                        0.011948\nClub Logo                   0.000000\nValue                       0.000000\nWage                        0.000000\nSpecial                     0.000000\nPreferred Foot              0.000000\nInternational Reputation    0.000000\nWeak Foot                   0.000000\nSkill Moves                 0.000000\nWork Rate                   0.000000\nBody Type                   0.002152\nReal Face                   0.002152\nPosition                    0.001982\nJoined                      0.062174\nLoaned From                 0.960702\nContract Valid Until        0.020442\nHeight                      0.000000\nWeight                      0.000000\nRelease Clause              0.065176\nKit Number                  0.001982\nBest Overall Rating         0.998811\ndtype: float64\n\n\n\ndf.drop(columns=['Loaned From','Best Overall Rating'])\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nWork Rate\nBody Type\nReal Face\nPosition\nJoined\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\n\n\n\n\n0\n209658\nL. Goretzka\n27\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nHigh/ Medium\nUnique\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\n2026\n189cm\n82kg\n€157M\n8.0\n\n\n1\n212198\nBruno Fernandes\n27\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n...\nHigh/ High\nUnique\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\n2026\n179cm\n69kg\n€155M\n8.0\n\n\n2\n224334\nM. Acuña\n30\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n...\nHigh/ High\nStocky (170-185)\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\n2024\n172cm\n69kg\n€97.7M\n19.0\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nHigh/ High\nUnique\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\n2025\n181cm\n70kg\n€198.9M\n17.0\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nHigh/ High\nNormal (170-)\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\n2026\n172cm\n68kg\n€154.4M\n23.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\nDeng Xiongtao\n19\nhttps://cdn.sofifa.net/players/269/526/23_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n48\n61\nMeizhou Hakka\nhttps://cdn.sofifa.net/teams/114628/30.png\n...\nMedium/ Medium\nNormal (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 11, 2022\n2027\n190cm\n78kg\n€218K\n35.0\n\n\n17656\n267946\n22 Lim Jun Sub\n17\nhttps://cdn.sofifa.net/players/267/946/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n48\n64\nJeju United FC\nhttps://cdn.sofifa.net/teams/1478/30.png\n...\nMedium/ Medium\nLean (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2022\n2026\n195cm\n84kg\n€188K\n21.0\n\n\n17657\n270567\nA. Demir\n25\nhttps://cdn.sofifa.net/players/270/567/23_60.png\nTurkey\nhttps://cdn.sofifa.net/flags/tr.png\n51\n56\nÜmraniyespor\nhttps://cdn.sofifa.net/teams/113796/30.png\n...\nMedium/ Medium\nLean (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 6, 2021\n2023\n190cm\n82kg\n€142K\n12.0\n\n\n17658\n256624\n21 S. Czajor\n18\nhttps://cdn.sofifa.net/players/256/624/21_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n50\n65\nFleetwood Town\nhttps://cdn.sofifa.net/teams/112260/30.png\n...\nMedium/ Medium\nNormal (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2020\n2021\n187cm\n79kg\n€214K\n40.0\n\n\n17659\n256376\n21 F. Jakobsson\n20\nhttps://cdn.sofifa.net/players/256/376/21_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n50\n61\nIFK Norrköping\nhttps://cdn.sofifa.net/teams/702/30.png\n...\nMedium/ Medium\nNormal (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 8, 2020\n2021\n186cm\n78kg\n€131K\n30.0\n\n\n\n\n17660 rows × 27 columns\n\n\n\n- 풀이 2 : 이성적인 풀이\n\ndf.loc[:, df.isna().mean() &lt; 0.5]  ## 시리즈니까 리스트로 묶지 말것!!\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nWork Rate\nBody Type\nReal Face\nPosition\nJoined\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\n\n\n\n\n0\n209658\nL. Goretzka\n27\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nHigh/ Medium\nUnique\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\n2026\n189cm\n82kg\n€157M\n8.0\n\n\n1\n212198\nBruno Fernandes\n27\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n...\nHigh/ High\nUnique\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\n2026\n179cm\n69kg\n€155M\n8.0\n\n\n2\n224334\nM. Acuña\n30\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n...\nHigh/ High\nStocky (170-185)\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\n2024\n172cm\n69kg\n€97.7M\n19.0\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nHigh/ High\nUnique\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\n2025\n181cm\n70kg\n€198.9M\n17.0\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nHigh/ High\nNormal (170-)\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\n2026\n172cm\n68kg\n€154.4M\n23.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\nDeng Xiongtao\n19\nhttps://cdn.sofifa.net/players/269/526/23_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n48\n61\nMeizhou Hakka\nhttps://cdn.sofifa.net/teams/114628/30.png\n...\nMedium/ Medium\nNormal (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 11, 2022\n2027\n190cm\n78kg\n€218K\n35.0\n\n\n17656\n267946\n22 Lim Jun Sub\n17\nhttps://cdn.sofifa.net/players/267/946/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n48\n64\nJeju United FC\nhttps://cdn.sofifa.net/teams/1478/30.png\n...\nMedium/ Medium\nLean (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2022\n2026\n195cm\n84kg\n€188K\n21.0\n\n\n17657\n270567\nA. Demir\n25\nhttps://cdn.sofifa.net/players/270/567/23_60.png\nTurkey\nhttps://cdn.sofifa.net/flags/tr.png\n51\n56\nÜmraniyespor\nhttps://cdn.sofifa.net/teams/113796/30.png\n...\nMedium/ Medium\nLean (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 6, 2021\n2023\n190cm\n82kg\n€142K\n12.0\n\n\n17658\n256624\n21 S. Czajor\n18\nhttps://cdn.sofifa.net/players/256/624/21_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n50\n65\nFleetwood Town\nhttps://cdn.sofifa.net/teams/112260/30.png\n...\nMedium/ Medium\nNormal (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2020\n2021\n187cm\n79kg\n€214K\n40.0\n\n\n17659\n256376\n21 F. Jakobsson\n20\nhttps://cdn.sofifa.net/players/256/376/21_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n50\n61\nIFK Norrköping\nhttps://cdn.sofifa.net/teams/702/30.png\n...\nMedium/ Medium\nNormal (185+)\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 8, 2020\n2021\n186cm\n78kg\n€131K\n30.0\n\n\n\n\n17660 rows × 27 columns"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-missing",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-missing",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "3. Pandas : missing",
    "text": "3. Pandas : missing"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-numpy",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-numpy",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### A. Numpy",
    "text": "### A. Numpy\n- 발생 : np.nan\n\nnp.nan\n\nnan\n\n\n\narr = np.array([1,2,3,np.nan])\narr\n\narray([ 1.,  2.,  3., nan])\n\n\n\narr.mean()\n\nnan\n\n\n\nprint(type(np.nan))  ## np.nan 자체는 일종의 float로 취급된다.\nprint(type(arr[0]))\n\n&lt;class 'float'&gt;\n&lt;class 'numpy.float64'&gt;"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-pandas",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-pandas",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### B. Pandas",
    "text": "### B. Pandas\n- 발생 : np.nan, pd.NA\n\npd.Series([np.nan,1,2,3])\n\n0    NaN\n1    1.0\n2    2.0\n3    3.0\ndtype: float64\n\n\n\npd.Series([pd.NA, 1, 2, 3])\n\n0    &lt;NA&gt;\n1       1\n2       2\n3       3\ndtype: object\n\n\n\n위 두 개의 코드는 동일하다고 봐도 무방하다.\n\n- pd.Serise에 NaN 또는 &lt;NA&gt;가 있다면 연산할 때 제외함\n\nprint(f'np.nan을 넣은 시리즈의 평균 : {pd.Series([np.nan,1,2,3]).mean()} = pd.NA를 넣은 시리즈의 평균 : {pd.Series([pd.NA,1,2,3]).mean()}')\n\nnp.nan을 넣은 시리즈의 평균 : 2.0 = pd.NA를 넣은 시리즈의 평균 : 2.0\n\n\n\ns1 = pd.Series([np.nan,1,2,3])\ntype(s1[0])\n\nnumpy.float64\n\n\n\ns2 = pd.Series([pd.NA, 1,2,3])\ntype(s2[0])\n\npandas._libs.missing.NAType\n\n\n\nmissing은 그냥 NaN이라고 보자.\n\n- 검출(\\(\\star\\))(중요한가?)\n\ns1.isna()\n\n0     True\n1    False\n2    False\n3    False\ndtype: bool\n\n\n\ns2.isna()\n\n0     True\n1    False\n2    False\n3    False\ndtype: bool\n\n\n\npd.isna(s1[0]), pd.isnull(s1[0])  ## 결측치가 있느냐?\n\n(True, True)\n\n\n\npd.isna(s2[0]), pd.isnull(s2[0])  ## 결측치가 있느냐?\n\n(True, True)\n\n\n\nid(pd.isna), id(pd.isnull) # 같은함수\n\n(135146401797248, 135146401797248)\n\n\n\nid를 찍었을 때 같다면 같은 함수이다."
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-query",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-query",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "5. Pandas : query",
    "text": "5. Pandas : query\n\n개 간단하고 쉽지만 고점은 낮은 데이터 처리방식\n\n\nts = pd.DataFrame(np.random.normal(size=(20,4)),columns=list('ABCD'),index=pd.date_range('20221226',periods=20)).assign(E=['A']*10+['B']*10)\nts\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-26\n-1.027712\n-0.590487\n1.580671\n-0.315109\nA\n\n\n2022-12-27\n0.640362\n-0.520975\n-0.607376\n-0.560362\nA\n\n\n2022-12-28\n0.625888\n-1.711870\n0.573349\n0.040879\nA\n\n\n2022-12-29\n-1.494778\n-0.333769\n0.028889\n0.984416\nA\n\n\n2022-12-30\n2.573588\n-0.005872\n0.868897\n0.932830\nA\n\n\n2022-12-31\n0.146699\n-0.306216\n1.241642\n-1.008297\nA\n\n\n2023-01-01\n1.105096\n-0.492485\n0.865509\n-0.383760\nA\n\n\n2023-01-02\n-1.136712\n0.595607\n-1.938775\n0.201931\nA\n\n\n2023-01-03\n0.118754\n0.119941\n-0.828199\n-1.356401\nA\n\n\n2023-01-04\n0.673908\n1.199221\n1.454181\n-0.370048\nA\n\n\n2023-01-05\n0.621326\n0.150997\n-0.479691\n0.810434\nB\n\n\n2023-01-06\n-0.095612\n-0.692796\n0.456627\n-0.395918\nB\n\n\n2023-01-07\n1.117905\n0.431402\n-0.235017\n0.897339\nB\n\n\n2023-01-08\n-0.939328\n0.745621\n0.632724\n0.032088\nB\n\n\n2023-01-09\n1.158532\n-2.312485\n-1.292257\n-1.325453\nB\n\n\n2023-01-10\n-0.339565\n-0.460976\n0.320097\n0.482333\nB\n\n\n2023-01-11\n-0.117493\n-1.964531\n-1.867120\n2.325713\nB\n\n\n2023-01-12\n0.574654\n0.984037\n0.641058\n0.264561\nB\n\n\n2023-01-13\n-0.252865\n0.519606\n0.373864\n0.520175\nB\n\n\n2023-01-14\n-1.069801\n-0.659982\n-0.368828\n1.286645\nB"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-기본-query",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-기본-query",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### A. 기본 query",
    "text": "### A. 기본 query\n- 예시1: A&gt;0 and B&lt;0\n\nts.query('A&gt;0 and B&lt;0')\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-27\n0.640362\n-0.520975\n-0.607376\n-0.560362\nA\n\n\n2022-12-28\n0.625888\n-1.711870\n0.573349\n0.040879\nA\n\n\n2022-12-30\n2.573588\n-0.005872\n0.868897\n0.932830\nA\n\n\n2022-12-31\n0.146699\n-0.306216\n1.241642\n-1.008297\nA\n\n\n2023-01-01\n1.105096\n-0.492485\n0.865509\n-0.383760\nA\n\n\n2023-01-09\n1.158532\n-2.312485\n-1.292257\n-1.325453\nB\n\n\n\n\n\n\n\n- 예시2: A&lt;B&lt;C\n\nts.query('A&lt;B&lt;C')\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-26\n-1.027712\n-0.590487\n1.580671\n-0.315109\nA\n\n\n2022-12-29\n-1.494778\n-0.333769\n0.028889\n0.984416\nA\n\n\n2023-01-04\n0.673908\n1.199221\n1.454181\n-0.370048\nA\n\n\n2023-01-14\n-1.069801\n-0.659982\n-0.368828\n1.286645\nB\n\n\n\n\n\n\n\n- 예시3: (A+B/2) &gt; 0\n\nts.query('(A+B)/2 &gt; 0')\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-27\n0.640362\n-0.520975\n-0.607376\n-0.560362\nA\n\n\n2022-12-30\n2.573588\n-0.005872\n0.868897\n0.932830\nA\n\n\n2023-01-01\n1.105096\n-0.492485\n0.865509\n-0.383760\nA\n\n\n2023-01-03\n0.118754\n0.119941\n-0.828199\n-1.356401\nA\n\n\n2023-01-04\n0.673908\n1.199221\n1.454181\n-0.370048\nA\n\n\n2023-01-05\n0.621326\n0.150997\n-0.479691\n0.810434\nB\n\n\n2023-01-07\n1.117905\n0.431402\n-0.235017\n0.897339\nB\n\n\n2023-01-12\n0.574654\n0.984037\n0.641058\n0.264561\nB\n\n\n2023-01-13\n-0.252865\n0.519606\n0.373864\n0.520175\nB\n\n\n\n\n\n\n\n- 예시4: (A+B/2) &gt; 0 and E=='A'\n\nts.query('(A+B)/2 &gt; 0 and E == \"A\"')   ## string 조건을 넣어주고 싶으면 다른 따옴표로 구분하면 된다.\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-27\n0.640362\n-0.520975\n-0.607376\n-0.560362\nA\n\n\n2022-12-30\n2.573588\n-0.005872\n0.868897\n0.932830\nA\n\n\n2023-01-01\n1.105096\n-0.492485\n0.865509\n-0.383760\nA\n\n\n2023-01-03\n0.118754\n0.119941\n-0.828199\n-1.356401\nA\n\n\n2023-01-04\n0.673908\n1.199221\n1.454181\n-0.370048\nA\n\n\n\n\n\n\n\n\n그냥 스트링으로 된 것들 중에는 생각헀던 건 왠만해선 다 된다."
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-외부변수를-이용",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-외부변수를-이용",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### B. 외부변수를 이용",
    "text": "### B. 외부변수를 이용\n- 예시1: A &gt; mean(A)\n\nmean = ts.A.mean()\nmean\n\n0.14414224086779243\n\n\n\n#ts.query('A &gt; np.mean(A)')   ## 이건 안됨\n#ts.query('A &gt; A.mean()')      ## 이건 되긴 함\n\n#ts.query('A &gt; mean')    ## column 중 하나인지 뭔지 헷갈림, 그래서 안됨\n\nts.query('A &gt; @mean')\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-27\n0.640362\n-0.520975\n-0.607376\n-0.560362\nA\n\n\n2022-12-28\n0.625888\n-1.711870\n0.573349\n0.040879\nA\n\n\n2022-12-30\n2.573588\n-0.005872\n0.868897\n0.932830\nA\n\n\n2022-12-31\n0.146699\n-0.306216\n1.241642\n-1.008297\nA\n\n\n2023-01-01\n1.105096\n-0.492485\n0.865509\n-0.383760\nA\n\n\n2023-01-04\n0.673908\n1.199221\n1.454181\n-0.370048\nA\n\n\n2023-01-05\n0.621326\n0.150997\n-0.479691\n0.810434\nB\n\n\n2023-01-07\n1.117905\n0.431402\n-0.235017\n0.897339\nB\n\n\n2023-01-09\n1.158532\n-2.312485\n-1.292257\n-1.325453\nB\n\n\n2023-01-12\n0.574654\n0.984037\n0.641058\n0.264561\nB\n\n\n\n\n\n\n\n\nA.mean()보다 작은 값들을 산출했다.\n\n\nvalue = np.percentile(ts.B, 77)  ## ts.B에서 77백분위수에 해당하는 숫자\nts.query('B &gt; @value')\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2023-01-02\n-1.136712\n0.595607\n-1.938775\n0.201931\nA\n\n\n2023-01-04\n0.673908\n1.199221\n1.454181\n-0.370048\nA\n\n\n2023-01-08\n-0.939328\n0.745621\n0.632724\n0.032088\nB\n\n\n2023-01-12\n0.574654\n0.984037\n0.641058\n0.264561\nB\n\n\n2023-01-13\n-0.252865\n0.519606\n0.373864\n0.520175\nB"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#c.-index로-query",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#c.-index로-query",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### C. Index로 query",
    "text": "### C. Index로 query\n- 예시: (2022년 12월30일 보다 이전 날짜) \\(\\cup\\) (2023년 1월10일)\n\nts.query('index &lt; \"2022-12-30\" or index == \"2023-01-10\"')\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\n2022-12-26\n-1.027712\n-0.590487\n1.580671\n-0.315109\nA\n\n\n2022-12-27\n0.640362\n-0.520975\n-0.607376\n-0.560362\nA\n\n\n2022-12-28\n0.625888\n-1.711870\n0.573349\n0.040879\nA\n\n\n2022-12-29\n-1.494778\n-0.333769\n0.028889\n0.984416\nA\n\n\n2023-01-10\n-0.339565\n-0.460976\n0.320097\n0.482333\nB"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#d.-열의-이름에-공백이-있을-경우",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#d.-열의-이름에-공백이-있을-경우",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### D. 열의 이름에 공백이 있을 경우",
    "text": "### D. 열의 이름에 공백이 있을 경우\n열의 이름에 공백이 있으면 백틱을 이용하면 된다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\ndf.columns\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'Club Logo', 'Value', 'Wage', 'Special',\n       'Preferred Foot', 'International Reputation', 'Weak Foot',\n       'Skill Moves', 'Work Rate', 'Body Type', 'Real Face', 'Position',\n       'Joined', 'Loaned From', 'Contract Valid Until', 'Height', 'Weight',\n       'Release Clause', 'Kit Number', 'Best Overall Rating'],\n      dtype='object')\n\n\n\ndf.query('`Skill Moves` &gt; 4')  ## `를 사용\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n19\n193082\nJ. Cuadrado\n34\nhttps://cdn.sofifa.net/players/193/082/23_60.png\nColombia\nhttps://cdn.sofifa.net/flags/co.png\n83\n83\nJuventus\nhttps://cdn.sofifa.net/teams/45/30.png\n...\nYes\n&lt;span class=\"pos pos3\"&gt;RB\nJul 1, 2017\nNaN\n2023\n179cm\n72kg\n€23M\n11.0\nNaN\n\n\n27\n189509\nThiago\n31\nhttps://cdn.sofifa.net/players/189/509/23_60.png\nSpain\nhttps://cdn.sofifa.net/flags/es.png\n86\n86\nLiverpool\nhttps://cdn.sofifa.net/teams/9/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nSep 18, 2020\nNaN\n2024\n174cm\n70kg\n€102.7M\n6.0\nNaN\n\n\n44\n232411\nC. Nkunku\n24\nhttps://cdn.sofifa.net/players/232/411/23_60.png\nFrance\nhttps://cdn.sofifa.net/flags/fr.png\n86\n89\nRB Leipzig\nhttps://cdn.sofifa.net/teams/112172/30.png\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nNaN\nNaN\nNaN\n175cm\n73kg\n€166.9M\n12.0\nNaN\n\n\n62\n233927\nLucas Paquetá\n24\nhttps://cdn.sofifa.net/players/233/927/23_60.png\nBrazil\nhttps://cdn.sofifa.net/flags/br.png\n82\n87\nOlympique Lyonnais\nhttps://cdn.sofifa.net/teams/66/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nOct 1, 2020\nNaN\n2025\n180cm\n72kg\n€90.9M\n10.0\nNaN\n\n\n75\n231747\nK. Mbappé\n23\nhttps://cdn.sofifa.net/players/231/747/23_60.png\nFrance\nhttps://cdn.sofifa.net/flags/fr.png\n91\n95\nParis Saint-Germain\nhttps://cdn.sofifa.net/teams/73/30.png\n...\nYes\n&lt;span class=\"pos pos25\"&gt;ST\nJul 1, 2018\nNaN\n2025\n182cm\n73kg\n€366.7M\n7.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4516\n253755\nTalles Magno\n20\nhttps://cdn.sofifa.net/players/253/755/23_60.png\nBrazil\nhttps://cdn.sofifa.net/flags/br.png\n71\n83\nNew York City FC\nhttps://cdn.sofifa.net/teams/112828/30.png\n...\nNo\n&lt;span class=\"pos pos16\"&gt;LM\nMay 18, 2021\nNaN\n2026\n186cm\n70kg\n€7.7M\n43.0\nNaN\n\n\n4643\n246548\nO. Sahraoui\n21\nhttps://cdn.sofifa.net/players/246/548/23_60.png\nNorway\nhttps://cdn.sofifa.net/flags/no.png\n67\n78\nVålerenga Fotball\nhttps://cdn.sofifa.net/teams/920/30.png\n...\nNo\n&lt;span class=\"pos pos27\"&gt;LW\nMay 15, 2019\nNaN\n2023\n170cm\n65kg\n€3.3M\n10.0\nNaN\n\n\n4872\n251570\nR. Cherki\n18\nhttps://cdn.sofifa.net/players/251/570/23_60.png\nFrance\nhttps://cdn.sofifa.net/flags/fr.png\n73\n88\nOlympique Lyonnais\nhttps://cdn.sofifa.net/teams/66/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 7, 2019\nNaN\n2023\n176cm\n71kg\n€17.7M\n18.0\nNaN\n\n\n5361\n225712\nD. Bahamboula\n27\nhttps://cdn.sofifa.net/players/225/712/23_60.png\nCongo\nhttps://cdn.sofifa.net/flags/cg.png\n63\n63\nLivingston FC\nhttps://cdn.sofifa.net/teams/621/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 9, 2022\nNaN\n2024\n185cm\n70kg\n€875K\n7.0\nNaN\n\n\n10452\n212455\n17 H. Mastour\n18\nhttps://cdn.sofifa.net/players/212/455/17_60.png\nMorocco\nhttps://cdn.sofifa.net/flags/ma.png\n65\n76\nPEC Zwolle\nhttps://cdn.sofifa.net/teams/1914/30.png\n...\nNo\n&lt;span class=\"pos pos28\"&gt;SUB\nNaN\n&lt;a href=\"/team/47/ac-milan/\"&gt;AC Milan&lt;/a&gt;\nJun 30, 2017\n175cm\n63kg\nNaN\n98.0\nNaN\n\n\n\n\n65 rows × 29 columns"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-할당",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-할당",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "5. Pandas : 할당",
    "text": "5. Pandas : 할당\n아래와 같은 자료를 조건에 맞게 가공해서 새로운 열을 추가해보자.\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\ndf = pd.DataFrame({'att':att,'rep':rep,'mid':mid,'fin':fin})\ndf\n\n\n\n\n\n\n\n\natt\nrep\nmid\nfin\n\n\n\n\n0\n65\n55\n50\n40\n\n\n1\n95\n100\n50\n80\n\n\n2\n65\n90\n60\n30\n\n\n3\n55\n80\n75\n80\n\n\n4\n80\n30\n30\n100\n\n\n5\n75\n40\n100\n15\n\n\n6\n65\n45\n45\n90\n\n\n7\n60\n60\n25\n0\n\n\n8\n95\n65\n20\n10\n\n\n9\n90\n80\n80\n20\n\n\n10\n55\n75\n35\n25\n\n\n11\n95\n95\n45\n0\n\n\n12\n95\n55\n15\n35\n\n\n13\n50\n80\n40\n30\n\n\n14\n50\n55\n15\n85\n\n\n15\n95\n30\n30\n95\n\n\n16\n50\n50\n45\n10\n\n\n17\n65\n55\n15\n45\n\n\n18\n70\n70\n40\n35\n\n\n19\n90\n90\n80\n90"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-df.assign",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-df.assign",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### A. df.assign()",
    "text": "### A. df.assign()\n- 예시: total = att*0.1 + rep*0.2 + mid*0.35 + fin*0.35 를 계산하여 할당\n\ndf.assign(total = df.att*0.1 + df.rep*0.2 + df.mid*0.35 + df.fin*0.35)\n## 원래 데이터 손상시키지 않음\n\ndf_total = df.assign(total = df.att*0.1 + df.rep*0.2 + df.mid*0.35 + df.fin*0.35)\ndf_total\n\n\n\n\n\n\n\n\natt\nrep\nmid\nfin\ntotal\n\n\n\n\n0\n65\n55\n50\n40\n49.00\n\n\n1\n95\n100\n50\n80\n75.00\n\n\n2\n65\n90\n60\n30\n56.00\n\n\n3\n55\n80\n75\n80\n75.75\n\n\n4\n80\n30\n30\n100\n59.50\n\n\n5\n75\n40\n100\n15\n55.75\n\n\n6\n65\n45\n45\n90\n62.75\n\n\n7\n60\n60\n25\n0\n26.75\n\n\n8\n95\n65\n20\n10\n33.00\n\n\n9\n90\n80\n80\n20\n60.00\n\n\n10\n55\n75\n35\n25\n41.50\n\n\n11\n95\n95\n45\n0\n44.25\n\n\n12\n95\n55\n15\n35\n38.00\n\n\n13\n50\n80\n40\n30\n45.50\n\n\n14\n50\n55\n15\n85\n51.00\n\n\n15\n95\n30\n30\n95\n59.25\n\n\n16\n50\n50\n45\n10\n34.25\n\n\n17\n65\n55\n15\n45\n38.50\n\n\n18\n70\n70\n40\n35\n47.25\n\n\n19\n90\n90\n80\n90\n86.50"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-df.eval",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-df.eval",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### B. df.eval()",
    "text": "### B. df.eval()\n- A에서와 동일한 할당\n\ndf.eval('total = att*0.1 + rep*0.2 + mid*0.3 + fin*0.4')    ## query를 쓰는 것처럼, 원본 데이터를 변화시키지 않음\n\n\n\n\n\n\n\n\natt\nrep\nmid\nfin\ntotal\n\n\n\n\n0\n65\n55\n50\n40\n48.5\n\n\n1\n95\n100\n50\n80\n76.5\n\n\n2\n65\n90\n60\n30\n54.5\n\n\n3\n55\n80\n75\n80\n76.0\n\n\n4\n80\n30\n30\n100\n63.0\n\n\n5\n75\n40\n100\n15\n51.5\n\n\n6\n65\n45\n45\n90\n65.0\n\n\n7\n60\n60\n25\n0\n25.5\n\n\n8\n95\n65\n20\n10\n32.5\n\n\n9\n90\n80\n80\n20\n57.0\n\n\n10\n55\n75\n35\n25\n41.0\n\n\n11\n95\n95\n45\n0\n42.0\n\n\n12\n95\n55\n15\n35\n39.0\n\n\n13\n50\n80\n40\n30\n45.0\n\n\n14\n50\n55\n15\n85\n54.5\n\n\n15\n95\n30\n30\n95\n62.5\n\n\n16\n50\n50\n45\n10\n32.5\n\n\n17\n65\n55\n15\n45\n40.0\n\n\n18\n70\n70\n40\n35\n47.0\n\n\n19\n90\n90\n80\n90\n87.0\n\n\n\n\n\n\n\n\nbut, 사칙연산과 같은 기초연산 수준에서만 잘 작동한다."
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#c.-dfcolname-xxx",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#c.-dfcolname-xxx",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### C. df[colname] = xxx",
    "text": "### C. df[colname] = xxx\n\n별로 안쓰는 방법\n\n\ndf['total'] = df.att*0.1 + df.rep*0.2 + df.mid*0.3 + df.fin*0.4   ## 원래의 데이터프레임을 손상시킨다.\ndf\n\n\n\n\n\n\n\n\natt\nrep\nmid\nfin\ntotal\n\n\n\n\n0\n65\n55\n50\n40\n48.5\n\n\n1\n95\n100\n50\n80\n76.5\n\n\n2\n65\n90\n60\n30\n54.5\n\n\n3\n55\n80\n75\n80\n76.0\n\n\n4\n80\n30\n30\n100\n63.0\n\n\n5\n75\n40\n100\n15\n51.5\n\n\n6\n65\n45\n45\n90\n65.0\n\n\n7\n60\n60\n25\n0\n25.5\n\n\n8\n95\n65\n20\n10\n32.5\n\n\n9\n90\n80\n80\n20\n57.0\n\n\n10\n55\n75\n35\n25\n41.0\n\n\n11\n95\n95\n45\n0\n42.0\n\n\n12\n95\n55\n15\n35\n39.0\n\n\n13\n50\n80\n40\n30\n45.0\n\n\n14\n50\n55\n15\n85\n54.5\n\n\n15\n95\n30\n30\n95\n62.5\n\n\n16\n50\n50\n45\n10\n32.5\n\n\n17\n65\n55\n15\n45\n40.0\n\n\n18\n70\n70\n40\n35\n47.0\n\n\n19\n90\n90\n80\n90\n87.0"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-transform-columnstarstarstar",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#pandas-transform-columnstarstarstar",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "6. Pandas : transform column(\\(\\star\\star\\star\\))",
    "text": "6. Pandas : transform column(\\(\\star\\star\\star\\))"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-lambda",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#a.-lambda",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### A. lambda",
    "text": "### A. lambda\n- 예시1: \\(x \\to x+2\\)\n\n\"\"\"\ndef f(x) :\n  return x + 2\n\n해당 코드와 동일하다.\n\"\"\"\n\nf = lambda x: x+2\nprint(f(3))\n\nprint((lambda x : x+2)(3))    ## (lambda x : x+2) 자체가 함수이므로, 뒤에 변수만 지정해주면 된다.\n\n5\n5\n\n\n- 예시2: \\(x,y \\to x+y\\)\n\n(lambda x,y : x+y)(1,3)\n\n4\n\n\n- 예시3: ‘2023-09’ \\(\\to\\) 9 (format : int)\n\n(lambda x : int(x[-2:]))('2023-09')   ## -1번째(뒤에서 두번째 원소까지 추출)\n\n9\n\n\n- 예시4: ‘2023-09’ \\(\\to\\) (2023, 9) (format : tuple)\n\n(lambda x : (int(x[:4]), int(x[-2:])))('2023-09')\n\n(2023, 9)\n\n\n- 예시5: 문자열이 ‘cat’이면 1 ’dog’ 이면 0 // ’cat이면 1 ’cat’이 아니면 0\n\n(lambda x : 1 if x == 'cat' else 0)('cat')\n## (lambda x : pd.Series(x == 'cat').sum())('cat') ## 이것도 된다.\n\n1"
  },
  {
    "objectID": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-map",
    "href": "posts/Data Visualization/Review/6. Pandas, 데이터프레임 핸들링.html#b.-map",
    "title": "Pandas 기본기 | 데이터프레임 핸들링",
    "section": "### B. map",
    "text": "### B. map\n\n함수의 output들을 엮는다. 매핑하는 거\n\n:- 개념: map(f,[x1,x2,...xn])=[f(x1),f(x2),...,f(xn)]\n- 예시1: x-&gt;x+1을 [1,2,3]에 적용\n\nf = lambda x: x+1\nlist(map(f,[1,2,3]))\n\n[2, 3, 4]\n\n\n\nlist(map(lambda x : x + 1, [1,2,3]))\n\n[2, 3, 4]\n\n\n\n매핑하는 것 자체는 수나 리스트가 아니기 때문에 리스트로 엮어줘야 값을 알 수 있다.\n\n- 예시2 df.Height열 변환하기 (xxxcm 라고 적혀있는 것을 cm 없애고 키만 뽑기)\ns.str.replace('cm', '')\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\ns = df.Height[:5]\ns\n\n0    189cm\n1    179cm\n2    172cm\n3    181cm\n4    172cm\nName: Height, dtype: object\n\n\n\nlist(map(lambda x : int(x[:-2]), s))\n\n[189, 179, 172, 181, 172]\n\n\n- 풀이 1 : map 이용\n\ndf.assign(Height = list(map(lambda x: int(x.replace('cm','')), df.Height)))\n\n\n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n0\n209658\nL. Goretzka\n27\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\nNaN\n2026\n189\n82kg\n€157M\n8.0\nNaN\n\n\n1\n212198\nBruno Fernandes\n27\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\nNaN\n2026\n179\n69kg\n€155M\n8.0\nNaN\n\n\n2\n224334\nM. Acuña\n30\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n...\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\nNaN\n2024\n172\n69kg\n€97.7M\n19.0\nNaN\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\nNaN\n2025\n181\n70kg\n€198.9M\n17.0\nNaN\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\nNaN\n2026\n172\n68kg\n€154.4M\n23.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\nDeng Xiongtao\n19\nhttps://cdn.sofifa.net/players/269/526/23_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n48\n61\nMeizhou Hakka\nhttps://cdn.sofifa.net/teams/114628/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 11, 2022\nNaN\n2027\n190\n78kg\n€218K\n35.0\nNaN\n\n\n17656\n267946\n22 Lim Jun Sub\n17\nhttps://cdn.sofifa.net/players/267/946/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n48\n64\nJeju United FC\nhttps://cdn.sofifa.net/teams/1478/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2022\nNaN\n2026\n195\n84kg\n€188K\n21.0\nNaN\n\n\n17657\n270567\nA. Demir\n25\nhttps://cdn.sofifa.net/players/270/567/23_60.png\nTurkey\nhttps://cdn.sofifa.net/flags/tr.png\n51\n56\nÜmraniyespor\nhttps://cdn.sofifa.net/teams/113796/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 6, 2021\nNaN\n2023\n190\n82kg\n€142K\n12.0\nNaN\n\n\n17658\n256624\n21 S. Czajor\n18\nhttps://cdn.sofifa.net/players/256/624/21_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n50\n65\nFleetwood Town\nhttps://cdn.sofifa.net/teams/112260/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2020\nNaN\n2021\n187\n79kg\n€214K\n40.0\nNaN\n\n\n17659\n256376\n21 F. Jakobsson\n20\nhttps://cdn.sofifa.net/players/256/376/21_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n50\n61\nIFK Norrköping\nhttps://cdn.sofifa.net/teams/702/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 8, 2020\nNaN\n2021\n186\n78kg\n€131K\n30.0\nNaN\n\n\n\n\n17660 rows × 29 columns\n\n\n\n- 풀이 2 : 사실 수틀리면 컴프리헨션 쓰면 된다.\n\ndf.assign(Height = [int(s.replace('cm', '')) for s in df.Height])\n\n\n  \n    \n\n\n\n\n\n\nID\nName\nAge\nPhoto\nNationality\nFlag\nOverall\nPotential\nClub\nClub Logo\n...\nReal Face\nPosition\nJoined\nLoaned From\nContract Valid Until\nHeight\nWeight\nRelease Clause\nKit Number\nBest Overall Rating\n\n\n\n\n0\n209658\nL. Goretzka\n27\nhttps://cdn.sofifa.net/players/209/658/23_60.png\nGermany\nhttps://cdn.sofifa.net/flags/de.png\n87\n88\nFC Bayern München\nhttps://cdn.sofifa.net/teams/21/30.png\n...\nYes\n&lt;span class=\"pos pos28\"&gt;SUB\nJul 1, 2018\nNaN\n2026\n189\n82kg\n€157M\n8.0\nNaN\n\n\n1\n212198\nBruno Fernandes\n27\nhttps://cdn.sofifa.net/players/212/198/23_60.png\nPortugal\nhttps://cdn.sofifa.net/flags/pt.png\n86\n87\nManchester United\nhttps://cdn.sofifa.net/teams/11/30.png\n...\nYes\n&lt;span class=\"pos pos15\"&gt;LCM\nJan 30, 2020\nNaN\n2026\n179\n69kg\n€155M\n8.0\nNaN\n\n\n2\n224334\nM. Acuña\n30\nhttps://cdn.sofifa.net/players/224/334/23_60.png\nArgentina\nhttps://cdn.sofifa.net/flags/ar.png\n85\n85\nSevilla FC\nhttps://cdn.sofifa.net/teams/481/30.png\n...\nNo\n&lt;span class=\"pos pos7\"&gt;LB\nSep 14, 2020\nNaN\n2024\n172\n69kg\n€97.7M\n19.0\nNaN\n\n\n3\n192985\nK. De Bruyne\n31\nhttps://cdn.sofifa.net/players/192/985/23_60.png\nBelgium\nhttps://cdn.sofifa.net/flags/be.png\n91\n91\nManchester City\nhttps://cdn.sofifa.net/teams/10/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nAug 30, 2015\nNaN\n2025\n181\n70kg\n€198.9M\n17.0\nNaN\n\n\n4\n224232\nN. Barella\n25\nhttps://cdn.sofifa.net/players/224/232/23_60.png\nItaly\nhttps://cdn.sofifa.net/flags/it.png\n86\n89\nInter\nhttps://cdn.sofifa.net/teams/44/30.png\n...\nYes\n&lt;span class=\"pos pos13\"&gt;RCM\nSep 1, 2020\nNaN\n2026\n172\n68kg\n€154.4M\n23.0\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n17655\n269526\nDeng Xiongtao\n19\nhttps://cdn.sofifa.net/players/269/526/23_60.png\nChina PR\nhttps://cdn.sofifa.net/flags/cn.png\n48\n61\nMeizhou Hakka\nhttps://cdn.sofifa.net/teams/114628/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nApr 11, 2022\nNaN\n2027\n190\n78kg\n€218K\n35.0\nNaN\n\n\n17656\n267946\n22 Lim Jun Sub\n17\nhttps://cdn.sofifa.net/players/267/946/22_60.png\nKorea Republic\nhttps://cdn.sofifa.net/flags/kr.png\n48\n64\nJeju United FC\nhttps://cdn.sofifa.net/teams/1478/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2022\nNaN\n2026\n195\n84kg\n€188K\n21.0\nNaN\n\n\n17657\n270567\nA. Demir\n25\nhttps://cdn.sofifa.net/players/270/567/23_60.png\nTurkey\nhttps://cdn.sofifa.net/flags/tr.png\n51\n56\nÜmraniyespor\nhttps://cdn.sofifa.net/teams/113796/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJun 6, 2021\nNaN\n2023\n190\n82kg\n€142K\n12.0\nNaN\n\n\n17658\n256624\n21 S. Czajor\n18\nhttps://cdn.sofifa.net/players/256/624/21_60.png\nPoland\nhttps://cdn.sofifa.net/flags/pl.png\n50\n65\nFleetwood Town\nhttps://cdn.sofifa.net/teams/112260/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 1, 2020\nNaN\n2021\n187\n79kg\n€214K\n40.0\nNaN\n\n\n17659\n256376\n21 F. Jakobsson\n20\nhttps://cdn.sofifa.net/players/256/376/21_60.png\nSweden\nhttps://cdn.sofifa.net/flags/se.png\n50\n61\nIFK Norrköping\nhttps://cdn.sofifa.net/teams/702/30.png\n...\nNo\n&lt;span class=\"pos pos29\"&gt;RES\nJan 8, 2020\nNaN\n2021\n186\n78kg\n€131K\n30.0\nNaN\n\n\n\n\n\n17660 rows × 29 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n# 예시4 – df.Position 열에 아래와 같은 변환을 수행하고, 변환된 열을 할당하라.\n\n\n\nbefore\nafter\n\n\n\n\n&lt;span class=\"pos pos28\"&gt;SUB\nSUB\n\n\n&lt;span class=\"pos pos15\"&gt;LCM\nLCM\n\n\n&lt;span class=\"pos pos7\"&gt;LB\nLB\n\n\n&lt;span class=\"pos pos13\"&gt;RCM\nRCM\n\n\n&lt;span class=\"pos pos13\"&gt;RCM\nRCM\n\n\n\n- 풀이 1\n\n데이터를 불러와서…\n\n\nlist(map(lambda x : x.str.split('&gt;')[-1] if x.isna() == False else pd.NA, df.Position))\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\n\n\n저장된 꼬라지를 보면…\n\n\nx = df.Position[0]\nx\n\n'&lt;span class=\"pos pos28\"&gt;SUB'\n\n\n\n게다가 결측치까지 있네???\n\n\ndf.Position.isna().sum()\n\n35\n\n\n\n결측치 처리 + 데이터 변환\n\n\ndf.assign(Position = list(map(lambda x : x.split('&gt;')[-1] if not pd.isna(x) else pd.NA, df.Position))).Position\n\n0        SUB\n1        LCM\n2         LB\n3        RCM\n4        RCM\n        ... \n17655    RES\n17656    RES\n17657    RES\n17658    RES\n17659    RES\nName: Position, Length: 17660, dtype: object\n\n\n- (풀이2) – 수틀리면 리스트컴프리헨션\n\nf = lambda x: x.split(\"&gt;\")[-1] if not pd.isna(x) else pd.NA\n\n\ndf.assign(Position = [f(s) for s in df.Position]).Position\n\n0        SUB\n1        LCM\n2         LB\n3        RCM\n4        RCM\n        ... \n17655    RES\n17656    RES\n17657    RES\n17658    RES\n17659    RES\nName: Position, Length: 17660, dtype: object\n\n\n\nmapping하는 게 조금 더 자연스럽고 한번에 쓸 수 있다. ~(어차피 이미 람다로 함수 만들었잖아?)~"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html",
    "href": "posts/Data Visualization/Review/4. Plotnine.html",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "",
    "text": "plotnine : R에서의 문법을 이용하여 그래프를 그려보자!"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#라이브러리-import",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#라이브러리-import",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "1. 라이브러리 import",
    "text": "1. 라이브러리 import\n\n##!pip install plotnine   ## plotnine이 구축되지 않은 경우 설치해야 한다.\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom plotnine import *\n\n\nimport plotnine\n\n\nplotnine.options.dpi= 150\nplotnine.options.figure_size = (6, 5)\n\n\n간단한 그래프 설정이다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#mpg-data",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#mpg-data",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "2. mpg data",
    "text": "2. mpg data\n\nA. read data\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/mpg.csv')\ndf\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n229\nvolkswagen\npassat\n2.0\n2008\n4\nauto(s6)\nf\n19\n28\np\nmidsize\n\n\n230\nvolkswagen\npassat\n2.0\n2008\n4\nmanual(m6)\nf\n21\n29\np\nmidsize\n\n\n231\nvolkswagen\npassat\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\nmidsize\n\n\n232\nvolkswagen\npassat\n2.8\n1999\n6\nmanual(m5)\nf\n18\n26\np\nmidsize\n\n\n233\nvolkswagen\npassat\n3.6\n2008\n6\nauto(s6)\nf\n17\n26\np\nmidsize\n\n\n\n\n234 rows × 11 columns"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#b.-descriptions",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#b.-descriptions",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### B. descriptions",
    "text": "### B. descriptions\n\ndf.columns\n\nIndex(['manufacturer', 'model', 'displ', 'year', 'cyl', 'trans', 'drv', 'cty',\n       'hwy', 'fl', 'class'],\n      dtype='object')\n\n\n- 각 행들이 어떤 의미를 가지는 지 Chat GPT에게 분석을 요청해봤다.\n\n- 그렇단다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#mpg의-시각화-2차원",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#mpg의-시각화-2차원",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "3. mpg의 시각화 : 2차원",
    "text": "3. mpg의 시각화 : 2차원\n\nA. x=displ, y=hwy\n\n- 예시 1 : 정직하게 메뉴얼대로…\n\n파라미터를 직접 지정해주는 경우\n\n\nggplot(data = df) + geom_point(mapping = aes(x = 'displ', y = 'hwy')) ## aes : dictionary와 유사하다고 생각하면 된다.\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n파라미터 생략\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy'))\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#b.-rpy2-코랩-아닌-경우-실습-금지",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#b.-rpy2-코랩-아닌-경우-실습-금지",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### B. rpy2 : 코랩 아닌 경우 실습 금지",
    "text": "### B. rpy2 : 코랩 아닌 경우 실습 금지\n- R에서도 거의 똑같은 문법으로 그릴 수 있음\n\n#import rpy2\n#%load_ext rpy2.ipython\n\n\n#%%R\n#library(tidyverse)\n#df = mpg\n#ggplot(df)+geom_point(aes(x=displ,y=hwy))"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#mpg의-시각화-3차원",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#mpg의-시각화-3차원",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "4. mpg의 시각화 : 3차원",
    "text": "4. mpg의 시각화 : 3차원\n\nA. x=displ, y=hwy, shape=class\n\n\nset(df['class'])  ## 중복되지 않은 값이 어느 것이 있는 지 산출\n## df['class'].unique() : 이건 array로 산출된다. 동일한 코드\n\n{'2seater', 'compact', 'midsize', 'minivan', 'pickup', 'subcompact', 'suv'}\n\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy', shape = 'class'))   ## class를 shape로 구분 &gt; 불편함\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#b.-xdispl-yhwy-colorclass",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#b.-xdispl-yhwy-colorclass",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### B. x=displ, y=hwy, color=class",
    "text": "### B. x=displ, y=hwy, color=class\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy', color = 'class'))\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n모양까지 class별로 달랐으면 좋겠다.\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy', color = 'class', shape = 'class'))\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n전체적으로 포인트의 사이즈를 키우고 싶다.\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy', color = 'class', shape = 'class'), size = 5)  ## 외부 파라미터\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n너무 커서 겹치니까 투명도 조정\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy', color = 'class', shape = 'class'), size = 5, alpha = 0.5)\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\ngeom_point()에서 내부 aes()에 넣은 값들은 값들을 구분하도록 되며, 외부에 입력된 값은 전체 개체들을 바꿔버린다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#mpg의-시각화-4차원-5차원",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#mpg의-시각화-4차원-5차원",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "5. mpg의 시각화 : 4차원, 5차원",
    "text": "5. mpg의 시각화 : 4차원, 5차원\n\nset(df['drv'])  ## 4륜구동, 전륜구동(front), 후륜구동(r)\n\n{'4', 'f', 'r'}\n\n\n\nA. drive metiod에 더 중점\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy', color = 'drv', shape = 'class'), size = 4, alpha = 0.5)\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n4륜구동이 연비가 낮은 걸 확인할 수 있다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#b.-5차원-시각화",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#b.-5차원-시각화",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### B. 5차원 시각화",
    "text": "### B. 5차원 시각화\n\nset(df['cyl'])  ## 실린더 수, 4,5,6,8\n\n{4, 5, 6, 8}\n\n\n\nggplot(df) + geom_point(aes(x='displ',y='hwy',color='drv',shape='class', size = 'cyl'), alpha = 0.5)  ## 외부 파라미터에 size는 제거\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n여기까지가 기본적인 사용 방법이다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#객체지향적-시각화",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#객체지향적-시각화",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "6. 객체지향적 시각화",
    "text": "6. 객체지향적 시각화\n- ggplot의 정체는 뭐지?\n\ntype(ggplot)\n\ntype\n\n\n\nclass. 어떤 물체를 만들어내는 함수와 비슷. matplotlib에서의 plt.figure()와 유사하다고 보면 된다.\n\n- 그럼 geom_point는 정체가 뭐지?\n\ntype(geom_point)  ## class, 생성함수.\n\nplotnine.utils.Registry\n\n\n\ngeom은 그림, 그래프라고 보면 된다. ’fig.add_axes()후 추가된ax`에 그래프를 그리는 것과 유사"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#a.-fig-geom_point-geom_smooth",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#a.-fig-geom_point-geom_smooth",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### A. fig + geom_point + geom_smooth",
    "text": "### A. fig + geom_point + geom_smooth\n\nfig  = ggplot(df)\npoint = geom_point(aes(x = 'displ', y = 'hwy'))\n\n\npoint ## 아무것도 나오지 않음\n\n&lt;plotnine.geoms.geom_point.geom_point at 0x121c8015390&gt;\n\n\n\nfig + point\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n두 개체를 합치니 피규어에 그래프가 들어가버린 형태가 되었다.\n\n\ngeom_smooth() | 산점도가 아닌 직선 그래프를 그려준다.\n\n\nsmooth = geom_smooth(aes(x = 'displ', y = 'hwy'))\n\n\nfig + smooth  ## ggplot(df) + geom_smooth(aes(x = 'displ', y = 'hwy')), 추세선 산출\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n그럼 셋을 합쳐보면…\n\n\nfig + point + smooth\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\nggplot(df) + geom_point(aes(x = 'displ', y = 'hwy')) + geom_smooth(aes(x = 'displ', y = 'hwy'))과 동일하다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#b.-시각화-개선",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#b.-시각화-개선",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### B. 시각화 개선",
    "text": "### B. 시각화 개선\n\ngeom_point()를 개선\n\n\npoint_better = geom_point(aes(x='displ',y='hwy',color='drv',size='cyl'),alpha=0.5)  ## 색상과 크기로 구분\n\n\nfig + point_better\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\ngeom_smooth() 개선\n\n\nsmooth_better = geom_smooth(aes(x = 'displ',  y = 'hwy', color = 'drv'), linetype = 'dashed')  ## 차종별로 추세선\n\n\nfig + smooth_better\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\nassemble\n\n\nfig + smooth_better + smooth\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#c.-다양한-조합",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#c.-다양한-조합",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### C. 다양한 조합",
    "text": "### C. 다양한 조합\n\nfig + point + smooth\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\nfig + smooth_better + point_better\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n전체 추세선 추가\n\n\nfig + smooth_better + point_better + geom_smooth(aes(x = 'displ', y = 'hwy'), color = 'white', linetype = 'dashed', size = 3)\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#아이스크림을-많이-먹으면-걸리는-병---인과관계와-상관관계",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#아이스크림을-많이-먹으면-걸리는-병---인과관계와-상관관계",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "7. 아이스크림을 많이 먹으면 걸리는 병 - 인과관계와 상관관계",
    "text": "7. 아이스크림을 많이 먹으면 걸리는 병 - 인과관계와 상관관계"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#a.-교회의-수와-범죄-아이스크림과-소아마비",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#a.-교회의-수와-범죄-아이스크림과-소아마비",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### A. 교회의 수와 범죄, 아이스크림과 소아마비",
    "text": "### A. 교회의 수와 범죄, 아이스크림과 소아마비\n\n\n\n\n교회의 개수\n범죄건수\n\n\n\n\n전주\n100\n20\n\n\n부산\n1000\n200\n\n\n서울\n5000\n1000\n\n\n\n\n결론(?) : 교회가 많을 수록 범죄도 많아진다???\n\n\n배경없이 숫자만 비교할 경우, 상관관계를 인과관계로 착각할 수도 있다.\n인구에 대한 인과를 착각\n\n- 내용요약\n\n여름 → 수영장 → 소아마비\n여름 → 아이스크림\n아이스크림과 소아마비는 상관관계가 높다. 따라서 아이스크림 성분 중에서 소아마비를 유발하는 유해물질이 있을 것이다(?)\n\n\n다른 변인을 통제하고(인구가 동일한 지역), 비교하려는 대상만 차이를 부여해야 한다."
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#b.-기상자료",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#b.-기상자료",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### B. 기상자료",
    "text": "### B. 기상자료\n- 기상자료 다운로드\n\ntemp=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/temp.csv').iloc[:,3].to_numpy()\n## 판다스 데이터의 4번째 열만 가져와 numpy.array로 만든다.\n\n\nplt.plot(temp)    ## 이럴 때는 ggplot보다 matplotlib가 훨씬 편하다.\nplt.show()"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#c.-숨은-진짜-상황-1-온도---아이스크림-판매량",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#c.-숨은-진짜-상황-1-온도---아이스크림-판매량",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### C. 숨은 진짜 상황 1 : 온도 -> 아이스크림 판매량",
    "text": "### C. 숨은 진짜 상황 1 : 온도 -&gt; 아이스크림 판매량\n-아래와 같은 관계를 가정하자. \\[\\text{아이스크림 판매량} = 20 + 2 \\times \\text{온도} + \\text{오차}\\]\n\nnp.random.seed(1)   ## 결과가 같도록 시드 설정\nicecream = 20 + 2 * temp + np.random.randn(len(temp))*10  ## N(0, 10^2)\nplt.plot(temp, icecream, 'o', alpha = 0.5)\nplt.show()"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#d.-숨은-진짜-상황-2-온도---소아마비-반응수치",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#d.-숨은-진짜-상황-2-온도---소아마비-반응수치",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### D. 숨은 진짜 상황 2 : 온도 -> 소아마비 반응수치",
    "text": "### D. 숨은 진짜 상황 2 : 온도 -&gt; 소아마비 반응수치\n- 아래와 같은 관계를 가정하자. \\[\\text{소아마비 반응수치} = 30 + 0.5 \\times \\text{온도} + \\text{오차}\\]\n\nnp.random.seed(2)\n\ndisease = 30 + 0.5 * temp + np.random.randn(len(temp))*1  ## N(0,1)\nplt.plot(temp, disease, 'o', alpha = 0.5)\nplt.show()"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#e.-우리가-관측한-상황온도는-은닉되어-있음",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#e.-우리가-관측한-상황온도는-은닉되어-있음",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### E. 우리가 관측한 상황(온도는 은닉되어 있음)",
    "text": "### E. 우리가 관측한 상황(온도는 은닉되어 있음)\n\nplt.plot(icecream, disease, 'o', alpha=0.3)\nplt.show()\n\n\n\n\n\nnp.corrcoef(icecream,disease)\n\narray([[1.        , 0.86298975],\n       [0.86298975, 1.        ]])\n\n\n여름만 뽑아서 플랏한다면?\n\nplt.plot(icecream,disease,'o',alpha=0.3)\nplt.plot(icecream[temp&gt;25], disease[temp&gt;25],'o') ## 기온이 25도 이상, 즉, 여름(아마도)\nplt.show()"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#f.-ggplot으로-온도구간을-세분화하여-시각화하자.",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#f.-ggplot으로-온도구간을-세분화하여-시각화하자.",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "### F. ggplot으로 온도구간을 세분화하여 시각화하자.",
    "text": "### F. ggplot으로 온도구간을 세분화하여 시각화하자.\n- 데이터를 데이터프레임으로\n\ndf = pd.DataFrame({'temp' : temp, 'ice' : icecream, 'dis' : disease})\ndf\n\n\n\n\n\n\n\n\ntemp\nice\ndis\n\n\n\n\n0\n-0.5\n35.243454\n29.333242\n\n\n1\n1.4\n16.682436\n30.643733\n\n\n2\n2.6\n19.918282\n29.163804\n\n\n3\n2.0\n13.270314\n32.640271\n\n\n4\n2.5\n33.654076\n29.456564\n\n\n...\n...\n...\n...\n\n\n651\n19.9\n68.839992\n39.633906\n\n\n652\n20.4\n76.554679\n38.920443\n\n\n653\n18.3\n68.666079\n39.882650\n\n\n654\n12.8\n42.771364\n36.613159\n\n\n655\n6.7\n30.736731\n34.902513\n\n\n\n\n656 rows × 3 columns\n\n\n\n- 구간별로 나눈 변수를 추가 : pd.cut(df, bins = int)\n\ndf.assign(temp_cut = pd.cut(df.temp, bins = 5))   ## 온도를 4구간으로 분할한다\n\n\n\n\n\n\n\n\ntemp\nice\ndis\ntemp_cut\n\n\n\n\n0\n-0.5\n35.243454\n29.333242\n(-3.92, 4.56]\n\n\n1\n1.4\n16.682436\n30.643733\n(-3.92, 4.56]\n\n\n2\n2.6\n19.918282\n29.163804\n(-3.92, 4.56]\n\n\n3\n2.0\n13.270314\n32.640271\n(-3.92, 4.56]\n\n\n4\n2.5\n33.654076\n29.456564\n(-3.92, 4.56]\n\n\n...\n...\n...\n...\n...\n\n\n651\n19.9\n68.839992\n39.633906\n(13.04, 21.52]\n\n\n652\n20.4\n76.554679\n38.920443\n(13.04, 21.52]\n\n\n653\n18.3\n68.666079\n39.882650\n(13.04, 21.52]\n\n\n654\n12.8\n42.771364\n36.613159\n(4.56, 13.04]\n\n\n655\n6.7\n30.736731\n34.902513\n(4.56, 13.04]\n\n\n\n\n656 rows × 4 columns\n\n\n\n\ncut_df = df.assign(temp_cut = pd.cut(df.temp, bins = 7))\n\nfig = ggplot(cut_df)\npoint = geom_point(aes(x = 'ice', y = 'dis', color = 'temp_cut'), alpha = 0.2)\nsmooth = geom_smooth(aes(x = 'ice', y = 'dis', color = 'temp_cut'), linetype = 'dashed')\n\nfig + point + smooth\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n실제로 보니 상관관계가 없어보인다.\n\n\n진짜 아이스크림을 먹고 배탈이 났다면?\n\nnp.random.seed(1)\nicecream_sales = 30 + 2 * temp + np.random.randn(len(temp))*10\n\n\nnp.random.seed(2)\ndisease = 30 + 0 * temp + 0.15 * icecream + np.random.randn(len(temp))*1  ## temp, 온도가 미치는 영향을 제로로\n\n\ndf2 = pd.DataFrame({'temp' : temp, 'ice' : icecream_sales, 'dis' : disease})\ndf2.assign(temp_cut = pd.cut(df2.temp, bins = 7))\n\n\n\n\n\n\n\n\ntemp\nice\ndis\ntemp_cut\n\n\n\n\n0\n-0.5\n45.243454\n34.869760\n(-6.343, -0.286]\n\n\n1\n1.4\n26.682436\n32.446099\n(-0.286, 5.771]\n\n\n2\n2.6\n29.918282\n30.851546\n(-0.286, 5.771]\n\n\n3\n2.0\n23.270314\n33.630818\n(-0.286, 5.771]\n\n\n4\n2.5\n43.654076\n33.254676\n(-0.286, 5.771]\n\n\n...\n...\n...\n...\n...\n\n\n651\n19.9\n78.839992\n40.009905\n(17.886, 23.943]\n\n\n652\n20.4\n86.554679\n40.203645\n(17.886, 23.943]\n\n\n653\n18.3\n78.666079\n41.032562\n(17.886, 23.943]\n\n\n654\n12.8\n52.771364\n36.628863\n(11.829, 17.886]\n\n\n655\n6.7\n40.736731\n36.163023\n(5.771, 11.829]\n\n\n\n\n656 rows × 4 columns\n\n\n\n\nfig = ggplot(df2.assign(temp_cut = pd.cut(df2.temp,bins=7)))\npoint = geom_point(aes(x='ice',y='dis',color='temp_cut'),alpha=0.2)\nsmooth = geom_smooth(aes(x='ice',y='dis',color='temp_cut'),linetype='dashed')\nfig + point + smooth\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\plotnine\\stats\\smoothers.py:330: PlotnineWarning: Confidence intervals are not yet implemented for lowess smoothings.\n\n\n\n\n\n&lt;Figure Size: (900 x 750)&gt;\n\n\n\n무친 인과관계"
  },
  {
    "objectID": "posts/Data Visualization/Review/4. Plotnine.html#결론",
    "href": "posts/Data Visualization/Review/4. Plotnine.html#결론",
    "title": "Plotnine : R에서 비롯한 패키지",
    "section": "8. 결론",
    "text": "8. 결론\n\n아이스크림 먹어도 소아마비 안걸려!\n\n\n온도라는 흑막(은닉변수)을 잘 찾았고, 결과적으로 온도 -&gt; 아이스크림 판매량 & 소아마비라는 합리적인 진리를 얻을 수 있었다.\n\n\n고려할 흑막이 온도뿐이라는 보장이 있나?\n\n\n이론적으로는 모든 은닉변수들을 통제하였을 경우에도 corr(X,Y)의 절댓값이 1에 가깝다면 그때는 인과성이 있음이라고 주장할 수 있다.(이 경우에도 둘 중 어느것이 원인인지 파악하는 것은 불가)\n즉, 모든 은닉변수를 제거하면 상관성 = 인과성이다.\n\n\n모든 흑막을 제거하는 건 사실상 불가능하지 않나?\n\n\n실험계획을 잘 하면 흑막을 제거한 효과가 있음(무작위 추출 등)\n인과추론 : 실험계획이 사실상 불가능한 경우가 있음 -&gt; 모인 데이터에서 최대한 흑막2ㆍ3ㆍ4ㆍㆍㆍ등이 비슷한 그룹끼리 “매칭”을 시킨 뒤, 그룹간 corr을 구하여 규명한다!\n\n\n데이터의 수가 방대해지면서 가능해졌다."
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "",
    "text": "matplotlib를 이용하여 그래프를 그려보자!"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#사전작업",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#사전작업",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "1. 사전작업",
    "text": "1. 사전작업\n\n라이브러리 import\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (3, 2)\nmatplotlib.rcParams['figure.dpi'] = 150"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#간단한-꺾은선-그래프",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#간단한-꺾은선-그래프",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "2. 간단한 꺾은선 그래프",
    "text": "2. 간단한 꺾은선 그래프\nplt.plot()을 사용하여 간단하게 그래프를 그릴 수 있다.\n\ny값만 지정한 경우\n\n\nplt.plot([1,2,4,3])\nplt.show()\n\n\n\n\n\nx값과 y값 같이 지정한 경우\n\n\nplt.plot([1,2,3,4],[1,2,4,3])\nplt.show()\n\n\n\n\n\nx값과 y값에 변수를 지정하여 넣어주는 경우\n\n\nx = [1,2,3,4]\ny = [1,2,4,3]\n\nplt.plot(x,y)\nplt.show()\n\n\n\n\n- 이외에도 다양한 옵션을 사용하여 그래프를 다채롭게 그릴 수 있는데, 지금부터 그것들을 알아보도록 하자.\n\nplt.plot의 옵션\nplt.plot()에서 괄호 안에 문자열을 넣음으로서 세 가지 옵션을 간단하게 적용할 수 있다.\nplt.plot(x,y,'--')  ## 파선 그래프\nplt.plot(x,y,':')   ## 점선 그래프\nplt.plot(x,y,'r')   ## 선의 색상이 빨간색\nplt.plot(x,y,'r--') ## 빨간색의 파선 그래프\n...\n- 게다가 세 옵션을 순서 상관없이 집어넣어 적용 가능하다!\n\nLine StylesColorsMarkers\n\n\n\n\n\ncharacter\ndescription\n\n\n\n\n‘-’\nsolid line style\n\n\n‘–’\ndashed line style\n\n\n‘-.’\ndash-dot line style\n\n\n‘:’\ndotted line style\n\n\n\n\n\n\n\n\ncharacter\ncolor\n\n\n\n\n‘b’\nblue\n\n\n‘g’\ngreen\n\n\n‘r’\nred\n\n\n‘c’\ncyan\n\n\n‘m’\nmagenta\n\n\n‘y’\nyellow\n\n\n‘k’\nblack\n\n\n‘w’\nwhite\n\n\n\n\n\n\n\n\ncharacter\ndescription\n\n\n\n\n‘.’\npoint marker\n\n\n‘,’\npixel marker\n\n\n‘o’\ncircle marker\n\n\n‘v’\ntriangle_down marker\n\n\n‘^’\ntriangle_up marker\n\n\n‘&lt;’\ntriangle_left marker\n\n\n‘&gt;’\ntriangle_right marker\n\n\n‘1’\ntri_down marker\n\n\n‘2’\ntri_up marker\n\n\n‘3’\ntri_left marker\n\n\n‘4’\ntri_right marker\n\n\n‘8’\noctagon marker\n\n\n‘s’\nsquare marker\n\n\n‘p’\npentagon marker\n\n\n‘P’\nplus (filled) marker\n\n\n’*’\nstar marker\n\n\n‘h’\nhexagon1 marker\n\n\n‘H’\nhexagon2 marker\n\n\n‘+’\nplus marker\n\n\n‘x’\nx marker\n\n\n‘X’\nx (filled) marker\n\n\n‘D’\ndiamond marker\n\n\n‘d’\nthin_diamond marker\n\n\n‘|’\nvline marker\n\n\n’_’\nhline marker\n\n\n\n\n\n\n그 외에 다른 옵션을 보고 싶다면 아래를 참조하라.\n\nother options or colors\nhttps://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\nhttps://matplotlib.org/2.0.2/examples/color/named_colors.html\nhex code\nhttps://htmlcolorcodes.com/\nother linestyles\nhttps://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html\n\n- preset에 있는 색상 외 다른 색상을 적용\n\nplt.plot(x,y,'--',color = 'lime')\n\n\n\n\n\nusing color name\n\n\nplt.plot(x,y,color = '#751F9B')\n\n\n\n\n\nusing hex code\n\n- 선의 형태를 다양하게 변경\n\nplt.plot(x,y,linestyle = 'dashed')\nplt.show()\n\n\n\n\n\n문자열로 직접 지정\n\n\nplt.plot(x,y,linestyle = (0, (1,1)))\n\n\n\n\n\n파선의 길이를 직접 지정\n\n\n\nplt.plot()에서 scatter plot을 생성\nmarker 옵션을 변경하여 scatter plot을 손쉽게 그릴 수도 있다.\n\nplt.plot(x,y,'db')  ## diamonds, blue\n\n\n\n\n\n\ndot connected plot\n\nplt.plot(x,y,':or')  ## dotline(:), circle(o), red\n\n\n\n\n\n\npile up\nplt.show()를 입력하기 전 계속해서 그래프를 그리면 중첩된다.\n\nplt.plot([1,2,3,2], '--o', color = 'orange')\nplt.plot([2,3,1,4], '--o', color = 'skyblue')\n\nplt.show()\n\nplt.plot([4,4,2,1], '--o', color = 'cyan')\n\nplt.show()\n\n\n\n\n\n\n\n\nplt.plot([1,2,3,2], '--o', color = 'C1')\nplt.plot([2,3,1,4], '--o', color = 'C0')\n\nplt.show()\n\n\n\n\n\n위와 같은 경우에는 color를 지정하지 않을 경우 먼저 입력한 그래프에 C0가 지정된다.\n\n\n\n응용 : scatter plot and line plot\n- 유사 단순선형회귀\n설명변수와 오차, 반응변수를 지정해주자.\n\nx = np.arange(-5,5,0.1)\neps = np.random.randn(100)\ny = 2*x + eps ## 벗어나도록 겹치게\n\n\nplt.plot(x,y,'.b')     ## 실제 데이터\nplt.plot(x,2*x,'--r')  ## 회귀선\nplt.show()\n\n\n\n\n\n\n적합한 그래프를 그릴 때\n- summary: boxplot, histogram, lineplot, scatterplot\n\n라인플랏: 추세\n☆★☆ 스캐터플랏: 두 변수의 관계\n박스플랏: 분포(일상용어)의 비교, 이상치\n히스토그램: 분포(통계용어)파악\n바플랏: 크기비교"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#객체지향적-시각화",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#객체지향적-시각화",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "3. 객체지향적 시각화",
    "text": "3. 객체지향적 시각화\n\nA. 배경지식\n- 그림을 저장해둔 뒤 나중에 꺼내보고 싶다면? | plt.gcf() : Get Current Figure.\n\nplt.plot([1, 2, 3, 2],'--o')\nfig = plt.gcf() ## plt.show()를 하기 전, 현재 표기되는 figure를 얻는다.\n\n\n\n\n\nfig\n\n\n\n\n\n위와 같이 변수에 저장된 것을 알 수 있다.\n\n\n\nB. fig의 해체\nfig\nfig.axes\n\nax = fig.axes[0]\nax.yaxis\nax.xaxis\n\nlines = ax.get_lines()[0]\nlines[0]\n\nfig &gt; 그래프 그 자체\naxes &gt; 그래프의 구역\naxis &gt; x축, y축\nline &gt; 직선형 그래프\n\n등등등…\n아무튼 여러 개체가 나뉘어있다.\n\n개념(비유) : * Figure(fig) : 도화지 * Axes(ax) : 도화지에 존재하는 그림틀 * Axis, Lines : 그림틀 위에 올려지는 물체(object)\n\n\n\nC. plt.plot()없이 그래프 그리기\n\nplt.plot([1,2,4,3], '--o')\nplt.show()\n\n\n\n\n위와 같은 그래프를 plt.plot()없이 만들어보자!\n- 아래의 코드를 하나하나 뜯어보자.\n\nfig = plt.Figure()\n\nax = fig.add_axes([0.125,0.11,0.775,0.77])\nax.set_xlim([-0.15, 3.15])  # setting x axis limit\nax.set_ylim([0.9, 3.1])     # setting y axis limit\nline = matplotlib.lines.Line2D(\n    xdata = [0,1,2,3],\n    ydata = [1,2,3,2],\n    linestyle = '--',\n    marker = 'o'\n)\nax.add_line(line)\n\nfig\n\n\n\n\n1. 최상위 하이라이트(figure) 생성\n\nfig = plt.figure(); fig   ## 최상위 하이라이트인 그림만 만들어냄.\n\n&lt;Figure size 450x300 with 0 Axes&gt;\n\n\n&lt;Figure size 450x300 with 0 Axes&gt;\n\n\n2. 그래프가 들어갈 공간(axes) 생성\n\nax = fig.add_axes([0.125,0.11,0.775,0.77]); fig  ## 가로시작, 세로시작, 종횡비\n\n\n\n\n3. 직선을 지정 후 추가\n\nline = matplotlib.lines.Line2D(\n    xdata = [0,1,2,3],\n    ydata = [1,2,3,2],\n    linestyle = '--',\n    marker = 'o'\n)\n\n\nmatplotlib에서 라인을 만드는 함수가 따로 있었다.\n\n\nax.add_line(line)\n\n&lt;matplotlib.lines.Line2D at 0x1c3c591e380&gt;\n\n\n\nfig\n\n\n\n\n4. 직선이 제대로 표기되지 않는 것 같으니 x축과 y축의 한계를 설정\n\nax.set_xlim([-0.15, 3.15])\nax.set_ylim([0.9, 3.1])\n\nfig\n\n\n\n\n\n\nD. 또 코드의 대체\n1. line2D 오브젝트를 쓰지 않는 방법\n\n## genarally\nfig = plt.Figure()\nax = fig.add_axes([0.125, 0.11, 0.775, 0.77])\nax.plot([1,2,3,2], '--o')\nfig\n\n\n\n\n\nax.plot()을 사용\n\n2. add_axes()를 쓰지 않는 방법(중요!)\n\nfig = plt.Figure()\nax = fig.subplots(1)\nax.plot([1,2,3,2], '--o')\nfig\n\n\n\n\n\nax = fig.subplots()을 사용\n\n3. fig와 ax들을 한번에 지정(중요!)\n\nfig, ax = plt.subplots(1) ## 중요함\nax.plot([1,2,3,2], '--o')\nplt.show()\n\n\n\n\n\n\nE. 정리 (\\(\\star\\star\\star\\))\n아래의 코드는 모두 같은 애들이었다.\n\nplt.plot([1,2,3,2], '--o')\n\n\nfig, ax = plt.subplots()\nax.plot([1,2,3,2], '--o')\n\n\nfig = plt.Figure()\nax = fig.subplots()\nax.plot([1,2,3,2], '--o')\nfig\n\n\nfig = plt.Figure()\nax = fig.add_axes([0.125, 0.11, 0.775, 0.77])\nax.plot([1,2,3,2], '--o')\nfig\n\nplt.subplots()과 ax.plot()의 경우 상당히 유용한 코드이니 꼭 숙지할 것!"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#미니맵과-서브플롯",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#미니맵과-서브플롯",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "4. 미니맵과 서브플롯",
    "text": "4. 미니맵과 서브플롯\n\nA. 미니맵\nfig.add_axes()를 사용한다.\n\nfig = plt.Figure()\nax = fig.add_axes([0,0,2,2]); fig\n\n\n\n\n\nax_mini = fig.add_axes([1.4,0.2,0.5,0.5])  ## 가로 세로 위치(중심위치), 종횡비\nax.plot([1,5,3,4], '--o')\nax_mini.plot([1,2,3,1], '--or')\n\nfig\n\n\n\n\n\n생성된 fig에 axes를 하나 더 추가하여 만들어냈다.\n\n\n\nB. 서브플롯\nplt.subplots(), fig.subplots()을 이용해보자.\n\nfig, axs = plt.subplots(2)  ## 2행\n\n\n\n\n\naxs\n\narray([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object)\n\n\n\naxs에 ax들이 array형태로 저장되어 있다.\n\n\naxs[0].plot([1,2,3,2], '--r')\naxs[1].plot([1,2,4,3], '--o')\n\nfig\n\n\n\n\n\n뭔가 레이아웃이 가려져있고 이상하다.\n\n\nfig.tight_layout(); fig\n\n\n\n\n\n왠만해선 fig.tight_layout()을 해주도록 하자.\n\n\n차피 axs가 array 형태로 저장되므로 그것을 따로 지정해주고 싶다면 아래와 같이 사용하는 것을 권장한다.\n\n\nfig, (ax1, ax2) = plt.subplots(2)\nax1.plot([1,2,3,2], '--r')\nax2.plot([1,2,4,3], '--o')\nfig.tight_layout()\n\n\n\n\n\n\nC. 서브플롯 스케일 조정 및 다중화\n- 스케일 변경\n\nfig, (ax1, ax2) = plt.subplots(2, figsize = (3,3))  ## 종횡비\nax1.plot([1,2,3,2], '--r')\nax2.plot([1,2,4,3], '--o')\nfig.tight_layout()\n\n\n\n\n\n미리 설정해줬던 dpi에 의거하여 종횡비가 배수로 적용된다.\n\n- 더 많은 서브플롯 생성\n\nfig, ((ax1, ax2),(ax3,ax4)) = plt.subplots(2,2, figsize = (3,3))\nax1.plot([1,2,4,3], 'o', color = 'C0')\nax2.plot([1,2,4,3], 'o', color = 'C1')\nax3.plot([1,2,4,3], 'o', color = 'C2')\nax4.plot([1,2,4,3], 'o', color = 'C3')\nfig.tight_layout()\n\n\n\n\n- 사용자 정의 서브플롯 생성\nplt.subplot() ## s가 없는 subplot(), 즉, 하나만 만들어진다.\n\nplt.figure(figsize=(3,3))\nplt.subplot(2,2,1)  ## 2×2의 1\nplt.plot([1,2,4,3],'o', color='C0')\nplt.subplot(1,2,2)\nplt.plot([1,2,4,3],'o', color='C1')\nplt.subplot(2,2,3)\nplt.plot([1,2,4,3],'o', color='C2')\nplt.tight_layout()\n\nfig = plt.gcf()\n\n\n\n\n\n이미 생성된 figure의 크기를 조정\n\n\nfig.set_size_inches(2,2); fig"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#title",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#title",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "5. title",
    "text": "5. title\n\ntitle을 만드는 함수는 어떤 오브젝트에 소속되는 게 좋을까? 1. plt -&gt; subplot의 제목을 설정 가능 2. fig -&gt; 전체제목(super title)을 설정할 수 있음 3. ax -&gt; subplot들의 제목을 설정할 수 있음\n\n\nA. plt.title()\nfigure를 생성하지 않은 기본적인 환경에서 타이틀을 달아준다.\n\n## 가장 평범한 플롯\nplt.plot([1,2,3,2])\nplt.title('asdf')\nplt.show()\n\n\n\n\n\n\nB. ax.set_title()\nfigure와 axes를 생성했을 경우, 각 ax마다 타이틀을 달아줄 수 있다.\n\n## title이 axes에 존재\nfig, ax = plt.subplots()\nax.set_title('asdf')\nax.plot([1,2,3,2])\n\nplt.show()\n\n\n\n\n\n\nC. fig.suptitle() | 권장하지 않는 방법\n원래 figure 자체에 타이틀을 붙이는 것은 불가능하다.\n\n##--------fig : 원래는 불가능--------\nplt.plot([1,2,3,2])\nfig = plt.gcf()\nfig.suptitle('asdf')\n\nplt.show()\n\n\n\n\n\n\nD. 응용\n\nplt.subplots()과 set_title()을 이용\n\n\nfig, (ax1, ax2) = plt.subplots(1,2, figsize = (4,2))\nax1.set_title('asdf')\nax2.set_title('1234')\nax1.plot([1,2,3,2])\nax2.plot([1,2,3,2])\nfig.tight_layout()\n\n\n\n\n\nfigure를 생성하지 않고 plt.subplot()과 plt.title()을 이용하여 손수 지정\n\n\nplt.subplot(1,2,1)\nplt.plot([1,2,3])\nplt.title('asdf')\nplt.subplot(1,2,2)\nplt.plot([1,2,3])\nplt.title('1234')\nplt.tight_layout()\n\n\n\n\n\nfig.suptitle()을 이용한 방법\n\n\nfig, (ax1, ax2) = plt.subplots(1,2)\nax1.set_title('asdf')\nax2.set_title('1234')\nfig.suptitle('asdf1234')\nfig.tight_layout()\n\n\n\n\n\n\nE. plt.gca()\nplt.gca()를 통해 ax개체를 다룰 수도 있다.\n\nplt.plot([1,2,3,2])\nax = plt.gca()\nax.set_title('asdf')  ## 현재의 axis에 바로 타이틀을 설정해준다.\n\nText(0.5, 1.0, 'asdf')"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#산점도의-응용-표본상관계수",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#산점도의-응용-표본상관계수",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "6. 산점도의 응용 | 표본상관계수",
    "text": "6. 산점도의 응용 | 표본상관계수\n\nA. 산점도와 표본상관계수\n아래처럼 두 연속형 자료가 주어질 경우 산점도로 나타낼 수 있다.\n\nweight = [44,48,49,58,62,68,69,70,76,79]\nheight = [159,160,162,165,167,162,165,175,165,172]\n\nplt.plot(weight,height,'.')  ## option : '.' marker가 .인 산점도 산출\nplt.show()\n\n\n\n\n아래 표본상관계수의 정의에 따라 데이터에서의 표본상관계수를 구해보자.\n- (표본)상관계수의 정의\n\\[r=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\sum_{i=1}^{n}(y_i-\\bar{y})^2 }}=\\sum_{i=1}^{n}\\tilde{x}_i\\tilde{y}_i \\]\n\\[단,~\\tilde{x}_i=\\frac{(x_i-\\bar{x})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}},~ \\tilde{y}_i=\\frac{(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\]\n\n위 식에서 \\(\\tilde{x}_i\\)와 \\(\\tilde{y}_i\\)는 \\(x_i\\)와 \\(y_i\\)를 표준화한 것이다.\n\n(데이터를 불러오자)\n\nx=[44,48,49,58,62,68,69,70,76,79]\ny=[159,160,162,165,167,162,165,175,165,172]\n\n(평균을 0으로)\n\nxx = x - np.mean(x); print(xx)\nyy = y - np.mean(y); print(yy)\n\n[-18.3 -14.3 -13.3  -4.3  -0.3   5.7   6.7   7.7  13.7  16.7]\n[-6.2 -5.2 -3.2 -0.2  1.8 -3.2 -0.2  9.8 -0.2  6.8]\n\n\n(퍼진 정도를 표준화)\n\nx_standard = xx/np.sqrt(np.sum(xx**2))\ny_standard = yy/np.sqrt(np.sum(yy**2))\n\n(표본상관계수 산출)\n\nnp.sum(x_standard*y_standard)\n\n0.7138620583559141\n\n\n\n이미 정의된 코드를 통해 해당 결과가 맞는지 확인해보자.\n\n\nnp.corrcoef(x,y)\n\narray([[1.        , 0.71386206],\n       [0.71386206, 1.        ]])"
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#b.-산점도를-보고-상관계수의-부호를-해석",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#b.-산점도를-보고-상관계수의-부호를-해석",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "### B. 산점도를 보고 상관계수의 부호를 해석",
    "text": "### B. 산점도를 보고 상관계수의 부호를 해석\n- 아래의 그림은 상관계수 r의 값이 양수인가 음수인가?\n\nx=[44,48,49,58,62,68,69,70,76,79]\ny=[159,160,162,165,167,162,165,175,165,172]\n\nplt.plot(x, y, 'o')\nplt.show()\n\n\n\n\n\nxx = x-np.mean(x)\nyy = y-np.mean(y) \nxxx = xx/np.sqrt(np.sum(xx**2))\nyyy = yy/np.sqrt(np.sum(yy**2))\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (10,3))\nax1.plot(x,y, 'o')\nax1.set_title(r'$(x_i,y_i)$')\nax2.plot(xx,yy,'o') ## mean to 0\nax2.set_title(r'$(x_i-\\bar{x}, y_i-\\bar{y})$')\nax3.plot(xxx,yyy,'o') ## standarized\nax3.set_title(r'$(\\tilde{x}_i,\\tilde{y}_i)$')\n\nplt.show()\n\n\n\n\n\n마지막 \\(\\tilde{x}_i\\), \\(\\tilde{y}_i\\)를 곱한 값이 양수인 것과 음수인 것을 체크해보자.\n\n\n1,3사분면에 점들이 많으므로 상관계수의 부호는 양수일 것이다."
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#d.-산점도를-보고-상관계수의-절대값을-해석",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#d.-산점도를-보고-상관계수의-절대값을-해석",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "### D. 산점도를 보고 상관계수의 절대값을 해석",
    "text": "### D. 산점도를 보고 상관계수의 절대값을 해석\n- 기울기가 동일하지만 직선 근처의 퍼짐이 다른 두 개의 자료\n\nx=np.arange(0,10,0.1)\ny1=x+np.random.normal(loc=0,scale=1.0,size=len(x))  ## N(0,1)\ny2=x+np.random.normal(loc=0,scale=7.0,size=len(x))  ## N(0,7)\n\nplt.plot(x,y1,'.')\nplt.plot(x,y2,'x')\nplt.show()\n\n\n\n\n\n표준화하는 함수 tilde() 정의\n\n\ndef tilde(x):\n    xx = x-np.mean(x)\n    xxx = xx / np.sqrt(np.sum(xx**2))\n    return xxx\n\n\nfig, (ax1, ax2) = plt.subplots(1,2, figsize = (4,2))\nax1.plot(x,y1,'.'); ax1.plot(x,y2,'x'); ax1.set_title(r'$(x_i,y_i)$')\nax2.plot(tilde(x), tilde(y1),'.'); ax2.plot(tilde(x), tilde(y2), 'x'); ax2.set_title(r'$(\\tilde{x}_i,\\tilde{y}_i)$')\nfig.tight_layout()\n\n\n\n\n- 직선 근처의 퍼짐은 동일하지만, 직선의 기울기가 다른 경우\n\nx=np.arange(0,10,0.1)\ny1=x+np.random.normal(loc=0,scale=1.0,size=len(x))  ## 기울기가 1\ny2=0.2*x+np.random.normal(loc=0,scale=1.0,size=len(x))  ## 기울기가 0.2\n\nplt.plot(x,y1,'.')\nplt.plot(x,y2,'x')\n\nplt.show()\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(4,2))\nax1.plot(x,y1,'.'); ax1.plot(x,y2,'x'); ax1.set_title(r'$(x_i,y_i)$')\nax2.plot(tilde(x),tilde(y1),'.'); ax2.plot(tilde(x),tilde(y2),'x'); ax2.set_title(r'$(\\tilde{x}_i,\\tilde{y}_i)$')\nfig.tight_layout()\n\n\n\n\n기울기가 클수록, 퍼짐 정도가 작을수록 상관계수의 절댓값이 높다."
  },
  {
    "objectID": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#산점도-응용예제2---앤스콤의-4분할",
    "href": "posts/Data Visualization/Review/2. 꺾은선, 산점도, 객체지향화.html#산점도-응용예제2---앤스콤의-4분할",
    "title": "Plot | 꺾은선, 산점도, 객체지향화",
    "section": "7. 산점도 응용예제2 - 앤스콤의 4분할",
    "text": "7. 산점도 응용예제2 - 앤스콤의 4분할\n- 표본상관계수가 모두 동일한 네 자료를 보라.\n\nx1 = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\ny1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n\nx2 = x1\ny2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\n\nx3 = x1\ny3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\n\nx4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\ny4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n\nnp.corrcoef(x1,y1),np.corrcoef(x2,y2),np.corrcoef(x3,y3),np.corrcoef(x4,y4)\n\n(array([[1.        , 0.81642052],\n        [0.81642052, 1.        ]]),\n array([[1.        , 0.81623651],\n        [0.81623651, 1.        ]]),\n array([[1.        , 0.81628674],\n        [0.81628674, 1.        ]]),\n array([[1.        , 0.81652144],\n        [0.81652144, 1.        ]]))\n\n\n\n음, 다 비슷한 자료겠구나… 양의 상관관계를 띄겠네?\n\n라고 속단하긴 이르다.\n\nfig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(6,4))\nax1.plot(x1,y1,'o'); ax1.set_title(f'corrcoef = {np.corrcoef(x1,y1)[0,1] : .6f}')\nax2.plot(x2,y2,'o'); ax2.set_title(f'corrcoef = {np.corrcoef(x2,y2)[0,1] : .6f}')\nax3.plot(x3,y3,'o'); ax3.set_title(f'corrcoef = {np.corrcoef(x3,y3)[0,1] : .6f}')\nax4.plot(x4,y4,'o'); ax4.set_title(f'corrcoef = {np.corrcoef(x4,y4)[0,1] : .6f}')\nfig.tight_layout()\n\n\n\n\n4개의 그림은 모두 같은 상관계수를 가지나, 그 느낌이 전혀 다르다.\n- 앤스콤플랏의 4개의 그림은 모두 같은 상관계수를 가진다. 하지만, 4개의 그림은 느낌이 전혀 다르다.\n- 같은 표본상관계수를 가진다고 하여 같은 관계성을 가지는 것은 아니다. 표본상관계수는 x,y의 비례정도를 측정하는데 그 값이 1에 가깝다고 하여 꼭 정비례의 관계가 있음을 의미하는 건 아니다.\n\\((x_i,y_i)\\)의 산점도가 선형성을 보일 때만 “표본상관계수가 1에 가까우므로 정비례의 관계에 있다”라는 논리전개가 성립한다.\n\n앤스콤의 첫번째 플랏 : 산점도가 선형 -&gt; 표본상관계수가 0.816 = 정비례의 관계가 0.816 정도\n앤스콤의 두번째 플랏 : 산점도가 선형이 아님 -&gt; 표본상관계수가 크게 의미없음.\n앤스콤의 세번째 플랏 : 산점도가 선형인듯 보이나 하나의 이상치가 있음 -&gt; 하나의 이상치가 표본상관계수의 값을 무너뜨릴 수 있으므로 표본상관계수 값을 신뢰할 수 없음.\n앤스콤의 네번째 플랏 : 산점도를 그려보니 이상한 그림 -&gt; 표본상관계수를 계산할 수는 있으나, 그게 무슨 의미가 있을까?\n\n산점도가 선형성을 보일 때만 표본상관계수가 1에 가까우므로 정비례의 관계에 있다라는 논리전개가 성립한다.\n\n1번만 의미가 있음. 3번의 경우 이상치가 존재하여 신뢰할 수 없음.\n\n\n교훈\n상관계수를 해석하기에 앞서서 산점도가 선형성을 보이는 지 체크할 것! 항상 통계량은 적절한 가정하에서만 말이 된다는 사실을 기억할 것!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RiverFlow",
    "section": "",
    "text": "Python을 이용한 문제 풀이, Kaggle competition, R 프로그래밍 연습 등 학습 내역과 작업물들을 기록합니다.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n강신성(202014107).html\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n전처리 | 연속형 자료의 범위 조정\n\n\n\n\n\n\n\npython\n\n\nScaler\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nsklearn.linear_model의 작동원리\n\n\n\n\n\n\n\npython\n\n\nLogistic\n\n\nLinear\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nKaggle | 결측치의 처리\n\n\n\n\n\n\n\npython\n\n\ntitanic\n\n\nimpute\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n선형회귀분석의 시작 | LinearRegression()\n\n\n\n\n\n\n\npython\n\n\nLinear\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n범주형 반응변수의 예측 | LogisticRegression()\n\n\n\n\n\n\n\npython\n\n\nLogistic\n\n\nkaggle\n\n\ntitanic\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n결측치의 처리\n\n\n\n\n\n\n\npython\n\n\nimpute\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nKaggle | Autogluon\n\n\n\n\n\n\n\npython\n\n\nkaggle\n\n\ntitanic\n\n\nautogluon\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n집단 간 비교 : 심슨의 역설\n\n\n\n\n\n\n\npython\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n데이터 시각화 실습 : FIFA23 선수 데이터\n\n\n\n\n\n\n\npython\n\n\npractice\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nPandas 사용 팁\n\n\n\n\n\n\n\npython\n\n\npandas\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nPandas 기본기 | 데이터프레임 핸들링\n\n\n\n\n\n\n\npython\n\n\npandas\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nPandas 기본기 | 행과 열의 선택\n\n\n\n\n\n\n\npython\n\n\npandas\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nPlotnine : R에서 비롯한 패키지\n\n\n\n\n\n\n\npython\n\n\nplotnine\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nSeaborn | 데이터프레임 친화적 패키지\n\n\n\n\n\n\n\npython\n\n\nseaborn\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nPlot | 꺾은선, 산점도, 객체지향화\n\n\n\n\n\n\n\npython\n\n\nmatplotlib\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction | 그래프, 이미지 이퀼라이징\n\n\n\n\n\n\n\npython\n\n\nimage\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n[문제 풀이] while을 이용한 간단한 문제풀이\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n[문제 풀이] 데이터프레임 : 특정 열의 재가공\n\n\n\n\n\n\n\npython\n\n\ndata visualization\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\n[문제 풀이] 특정 단어를 포함하는 열 선택\n\n\n\n\n\n\n\npython\n\n\ndata visualization\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nKaggle | Alexis Cook의 코드\n\n\n\n\n\n\n\npython\n\n\nkaggle\n\n\ntitanic\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\n강신성\n\n\n\n\n\n\n  \n\n\n\n\nKaggle | 1st practice\n\n\n\n\n\n\n\npython\n\n\nkaggle\n\n\ntitanic\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2023\n\n\n강신성\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\nR과 Python, 그 외 공부하는 데 필요했던 자료들이나 대회, 공모전, 연습했던 것들을 올립니다."
  },
  {
    "objectID": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html",
    "href": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html",
    "title": "Introduction | 그래프, 이미지 이퀼라이징",
    "section": "",
    "text": "파이썬을 이용하여 간단한 그래프를 그려보고, 이미지를 이퀼라이징하는 방법을 알아보도록 하자."
  },
  {
    "objectID": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html#사전작업",
    "href": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html#사전작업",
    "title": "Introduction | 그래프, 이미지 이퀼라이징",
    "section": "1. 사전작업",
    "text": "1. 사전작업\n\n라이브러리 import\n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n##--------이퀼라이징을 위한 라이브러리--------\n#!pip install opencv-python\nimport cv2\n\n##--------parameter 설정--------\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (3,2)\nmatplotlib.rcParams['figure.dpi'] = 150 ## 450 : 300\n\n\n오늘 알아볼 함수들\n\nplt.boxplot()      ## 박스플롯 생성\nnp.random.randn()  ## 정규분포 하 확률변수 추출(default : 표준정규분포에서 1개 추출)\nnp.random.seed()   ## 시드 생성\nplt.hist()         ## 히스토그램 생성\ncv2.imread()       ## 이미지를 행렬로 읽어들임\nplt.imshow()       ## 행렬로 저장된 이미지를 시각화\ncv2.equalizeHist() ## 히스토그램 이퀼라이징\n\n!wget link         ## 파일 다운로드(리눅스)"
  },
  {
    "objectID": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html#플롯",
    "href": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html#플롯",
    "title": "Introduction | 그래프, 이미지 이퀼라이징",
    "section": "2. 플롯",
    "text": "2. 플롯\n\nA. Boxplot\n전북고등학교에는 10명의 학생이 있는 두 개의 학급이 있고, 각 학생들이 받은 점수는 아래와 같다.\n\ny1 = [75,75,76,76,77,77,78,79,79,98]\ny2 = [76,76,77,77,78,78,79,80,80,81]\n\n\ny1_frame = pd.DataFrame(y1)\ny1_frame.describe()\n\n\n  \n    \n\n\n\n\n\n\n0\n\n\n\n\ncount\n10.000000\n\n\nmean\n79.000000\n\n\nstd\n6.831301\n\n\nmin\n75.000000\n\n\n25%\n76.000000\n\n\n50%\n77.000000\n\n\n75%\n78.750000\n\n\nmax\n98.000000\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n- 1반의 평균은 \\(79\\)\n\ny2_frame = pd.DataFrame(y2)\ny2_frame.describe()\n\n\n\n\n\n\n\n\n0\n\n\n\n\ncount\n10.00000\n\n\nmean\n78.20000\n\n\nstd\n1.75119\n\n\nmin\n76.00000\n\n\n25%\n77.00000\n\n\n50%\n78.00000\n\n\n75%\n79.75000\n\n\nmax\n81.00000\n\n\n\n\n\n\n\n- 2반의 평균은 \\(78.2\\)이다.\n그렇다면 1반(y1)과 2반(y2), 두 반을 지도하는 선생님 중 어떤 선생님이 우수할까?\n\n아마도… : 평균을 중심으로 분석할 시 y1이 더 잘 지도했다고 판단할 수 있다.\n반론 : 평균은 A반이 더 높으나, 편차또한 더 크다. 고득점을 받는 한 학생(outlier)을 제외하면 전체적으로 B반 학생들이 시험을 더 잘 보았다고 해석할 수 있다.\n\n단순한 평균비교보다 학생들이 받은 점수의 분포를 비교하는 것이 중요.\n따라서 그 분포를 알아보기 위해 Boxplot을 그려보자.\n\n\nmatplotlib로 boxplot 그리기\n\nplt.boxplot(y1);  ## 세미콜론을 붙이면 결과값만 출력한다.\n\n\n\n\n\nplt.boxplot(y2);\n\n\n\n\n\nplt.boxplot([y1,y2]); ## 2차원의 리스트를 넣어 여러 개를 동시에 출력시킬 수도 있다.\n\n##np.array([y1, y2]).shape ## &gt; (2, 10)\n\n\n\n\n위처럼 하나의 outlier를 배제한다면, 나머지의 분포는 2반이 더 높게 위치함을 알 수 있다.\n\n박스플롯의 장점 : 단순히 평균만 제공하는 것보다 데이터를 파악하고 직관을 얻기에 유용하다.\n박스플롯이 이용되는 범위 : 초기 자료 분포를 파악하기 용이, 두 개 이상의 방법을 비교\n\n\n\nB. Histogram\n- 중심경향치(평균, 중앙값)만 가지고 집단을 비교할 순 없다.\n이전의 자료도 결과론적으로 중앙값이 더 타당해 보이나, 이것을 근거로 B반이 공부를 더 잘했다는 주장도 비합리적이다.\n\n단순 평균비교로 이러한 질문에 답을 하기 어려움.\n박스플롯으로 전체분포를 파악해도 어떤 반이 공부를 더 잘한다는 기준을 잡기 애매함.\n\nBut!\n특수한 경우에는 두 반 중에 누가 더 공부를 잘하냐는 질문에 명확히 대답할 수 있다.\n정규분포 전북고등학교 : 평균은 좋은 측정값인가?\n\nnp.random.seed(43052)\ny1 = np.random.randn(10000)   ## random.randn, standard normal distribution\ny2 = np.random.randn(10000) + 0.5\n\n- 두 반의 성적은 모두 표준정규분포를 따르는데, 2반의 성적이 일괄적으로 0.5가 높은 상황\n\nnp.mean(y1), np.mean(y2)\n\n(-0.011790879905079434, 0.4979147460611458)\n\n\n\nplt.boxplot([y1,y2]);\n\n\n\n\n\n분포의 모양이 거의 비슷한데, 중앙값(평균)이 2반이 더 높으므로 성적이 더 높다고 말할 수 있다. &gt; 게다가 평균적으로 0.5점 정도 더 공부를 잘한다고 대답할 수 있다!\n\n근데, 위와 같은 경우는 정규분포에서 뽑힌 랜덤샘플이라 분포의 모양이 같다고 하긴 했는데… 실제 데이터를 확인할 때는 박스플롯으로 하긴 어려워보인다.\n따라서!\n히스토그램을 그려 확인해보자\nplt.hist(array, bins = int, range = list)\n\nplt.hist([y1, y2], bins = 100);\n\n\n\n\n\n둘의 분포는 비슷하지만, 2반(주황색)이 조금 더 높은 수준에서 자리함을 알 수 있다."
  },
  {
    "objectID": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html#equalization",
    "href": "posts/Data Visualization/Review/1. Introduction(그래프, 이미지 이퀼라이징).html#equalization",
    "title": "Introduction | 그래프, 이미지 이퀼라이징",
    "section": "3. Equalization",
    "text": "3. Equalization\n히스토그램이나 이미지를 눈으로 보기 쉽도록 이퀼라이징해보자!\n이미지 자료 다운로드\n\n#!pip install wget\nimport wget\n\nwget.download(\"https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\")\nimg = cv2.imread(\"Unequalized_Hawkes_Bay_NZ.jpg\")\n\n##--------리눅스 환경 충족 시--------\n##!wget https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg\n##img = cv2.imread('https://upload.wikimedia.org/wikipedia/commons/0/08/Unequalized_Hawkes_Bay_NZ.jpg')\n##!rm Unequalized_Hawkes_Bay_NZ.jpg\n\n## 파일을 들여오고 인식한 뒤 삭제하는 코드이다.\n\nRequirement already satisfied: wget in c:\\users\\hollyriver\\anaconda3\\envs\\ssk\\lib\\site-packages (3.2)\n100% [............................................................................] 110895 / 110895\n\n\n\nplt.imshow(img) ## image show\n\n&lt;matplotlib.image.AxesImage at 0x184b83fab00&gt;\n\n\n\n\n\n\nplt.imshow()를 통해서 이미지를 가져왔다!\n\n근데, img는 어떤 값으로 저장된 걸까?\n\nA. 사실 이미지는 숫자열이었다!\n\n_img1 = np.array([0,30,90,120,150,180,210,240,255]).reshape(3,-1)  ## 3행 3열로 변경\n_img1\n\narray([[  0,  30,  90],\n       [120, 150, 180],\n       [210, 240, 255]])\n\n\n\nplt.imshow(_img1, cmap = 'gray')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n_img2 = np.array([0,20,40,60,80,100,120,140,160]).reshape(3,3)\n_img2\n\narray([[  0,  20,  40],\n       [ 60,  80, 100],\n       [120, 140, 160]])\n\n\n\nplt.imshow(_img2, cmap = 'gray', vmin = 0, vmax = 255)  ## vmin, vmax를 설정해주지 않으면 가장 큰 값이 max(white)가 된다\nplt.colorbar()\nplt.show()\n\n\n\n\n255에 가까울 수록 하얀색, 0에 가까울 수록 검정색인 이미지로 변환된 것을 볼 수 있다. 숫자만으로 이뤄진 행렬이 이미지가 된 것이다!\n크게, 더 크게 해보자!\n\n_img3 = np.concatenate([_img1,_img2], axis = 1)  ## 열로 병합, default는 행으로 병합\n_img3\n\narray([[  0,  30,  90,   0,  20,  40],\n       [120, 150, 180,  60,  80, 100],\n       [210, 240, 255, 120, 140, 160]])\n\n\n\nplt.imshow(_img3, cmap = 'gray')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\nB. RGB값을 더한 그림 그리기\n\n먼저, RGB값에 해당하는 수를 각각 array로 지정해주자.\n\n\nr = np.array(\n    [[255, 255, 255,  0,   0],\n     [255, 255, 255,  0,   0],\n     [255, 255, 255,  0,   0],\n     [  0,   0,   0,  0,   0],\n     [  0,   0,   0,  0,   0]]\n)\ng = np.array(\n    [[  0,   0, 255, 255, 255],\n     [  0,   0, 255, 255, 255],\n     [  0,   0, 255, 255, 255],\n     [  0,   0,   0,   0,   0],\n     [  0,   0,   0,   0,   0]]\n)\nb = np.array(\n    [[  0,   0,   0,   0,   0],\n     [  0,   0,   0,   0,   0],\n     [255, 255, 255, 255, 255],\n     [255, 255, 255, 255, 255],\n     [255, 255, 255, 255, 255]]\n)\nz = np.array(\n    [[ 0,  0,  0,  0,  0],\n     [ 0,  0,  0,  0,  0],\n     [ 0,  0,  0,  0,  0],\n     [ 0,  0,  0,  0,  0],\n     [ 0,  0,  0,  0,  0]]\n)\n\n\n그리고 합쳐서 RGB값을 할당해준다.\n\n\nred = np.stack([r,z,z], axis = -1)\ngreen = np.stack([z,g,z], axis = -1)\nblue = np.stack([z,z,b], axis = -1)\n\n\ntemp = np.stack([r,g,b], axis = -1);temp\n\narray([[[255,   0,   0],\n        [255,   0,   0],\n        [255, 255,   0],\n        [  0, 255,   0],\n        [  0, 255,   0]],\n\n       [[255,   0,   0],\n        [255,   0,   0],\n        [255, 255,   0],\n        [  0, 255,   0],\n        [  0, 255,   0]],\n\n       [[255,   0, 255],\n        [255,   0, 255],\n        [255, 255, 255],\n        [  0, 255, 255],\n        [  0, 255, 255]],\n\n       [[  0,   0, 255],\n        [  0,   0, 255],\n        [  0,   0, 255],\n        [  0,   0, 255],\n        [  0,   0, 255]],\n\n       [[  0,   0, 255],\n        [  0,   0, 255],\n        [  0,   0, 255],\n        [  0,   0, 255],\n        [  0,   0, 255]]])\n\n\n\n원소 하나 당 3개의 값이 할당된 것을 알 수 있다.\n\n\nnp.stack([], axis = -1) 크기가 동일한 행렬들의 각 원소들을 리스트화 하여 원소로 저장한다.\n\n\nplt.imshow(red+green+blue)\nplt.show()\n\n\n\n\nR, G, B를 같은 비율로 섞으면 다시 흑백이미지가 된다.\n\narr2 = np.array([[10, 40], [80, 60]])\narr2\n\narray([[10, 40],\n       [80, 60]])\n\n\n\narr3 = np.stack([arr2, arr2, arr2], axis = -1)  ## rgb값이 각각 동일\nplt.imshow(arr3)\nplt.show()\n\n\n\n\n\nimg.shape ## 원소의 리스트 수가 3이라는 것으로 rgb가 포함되어 있음을 추측할 수 있음.\n\n(683, 1024, 3)\n\n\n\n\nC. 히스토그램 이퀼라이징\n그래서 이퀼라이징은 뭐냐고!\n\nimg에서 추출해온 행렬로 아래와 같은 히스토그램을 만들어보자.\n\n\nr = img[:, :, 0]  ## 첫 번째 원소\ng = img[:, :, 1]  ## 두 번째 원소\nb = img[:, :, 2]  ## 세 번째 원소\n\n\nplt.hist(r.reshape(-1),bins=255, range=[0,255])\nplt.show()\n\n\n\n\n\n120~200 사이에 값이 몰려있음\n120~200의 분포된 모양은 그대로 유지하면서 range를 0~255까지 늘린다면?\n\n\nrr = cv2.equalizeHist(r)\ngg = cv2.equalizeHist(g)\nbb = cv2.equalizeHist(b)\n\n\ncv2 라이브러리의 equalizeHist() 사용하면 행렬의 모든 원소들의 분포 정도를 고르게(0~255) 바꾼다.\n\n\nplt.hist(r.reshape(-1),bins=255, range=[0,255],label='befor');\nplt.hist(rr.reshape(-1),bins=255,range=[0,255],label='after');  ## cv2.equalizeHist() 사용\nplt.legend()\nplt.show()\n\n\n\n\n그렇다면 이것을 응용하여 위에서의 이미지를 이퀼라이징하면?\n- 이퀼라이징된 각 원소들을 다시 이어붙여 하나의 이미지로 만들어본다.\n\nimg2 = np.stack([rr,gg,bb], axis = -1)  ## axis = -1 &gt; z축(원소 내에서 확장)으로 추가\nimg2.shape\n\n(683, 1024, 3)\n\n\n\nplt.imshow(img2)\nplt.show()\n\n\n\n\n\nplt.imshow(np.concatenate([img,img2], axis = 1))\nplt.show()\n\n\n\n\n\n이렇게, 이미지를 조금 더 구별하기 쉽도록 바꿀 수 있다."
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html",
    "href": "posts/Data Visualization/Review/3. Seaborn.html",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "",
    "text": "seaborn을 이용하여 그래프를 그려보자!"
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html#라이브러리-import",
    "href": "posts/Data Visualization/Review/3. Seaborn.html#라이브러리-import",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "1. 라이브러리 import",
    "text": "1. 라이브러리 import\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html#seaborn과-matplotlib",
    "href": "posts/Data Visualization/Review/3. Seaborn.html#seaborn과-matplotlib",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "2. Seaborn과 Matplotlib",
    "text": "2. Seaborn과 Matplotlib\n\nmatplotlib : 벡터 친화적\nseaborn : 데이터프레임 친화적\n\n\n분석할 데이터가 태뷸러데이터 형식인 경우가 많다.\nmatplotlib는 여전히 강력하지만, seaborn등 데이터프레임 친화적인 패키지가 우수한 경우가 많다.\n\n\nA. scatter plot\n\n\n## titanic data\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2023/main/posts/titanic.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nlogFare\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n1.981001\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n4.266662\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n2.070022\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n3.972177\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n2.085672\n\n\n\n\n\n\n\n\nsns.scatterplot(\n    df,\n    x = 'logFare',  ## 요금에 로그를 취한 값(너무 변동이 크니까)\n    y = 'Age',\n    hue = 'Sex',    ## 색상, 색조. 변수 별 색상을 나눠 표기한다.\n    style = 'Survived', style_order = [1,0],  ## Survived 여부로 마커 표시, style_order의 디폴트 값이 [0 =&gt; O,1 =&gt; X]이므로 그 순서를 변경\n    alpha = 0.6     ## 투명도 조절\n)\n\n&lt;Axes: xlabel='logFare', ylabel='Age'&gt;\n\n\n\n\n\n\nplt.hist(df.Age)\nplt.hist(df.Age[df.Survived == 1])  ## 그냥 그리면 겹쳐짐\n\nplt.show()\n\n\n\n\n- seaborn은 데이터과학에서 거의 표준적인 패키지. * 안하는 이유 * 간단한 시각화는 matplotlib가 유리 * seaborn에 대한 고급기능은 matplotlib에 대한 통찰이 있어야 가능 * plotline이 더 우수함(ggplot2) * plotly가 모든 면에서 seaborn을 압도하는 추세임\n\n\nB. seaborn의 고급기능 이해\n\nsns.scatterplot(\n    df,\n    x = 'logFare',\n    y = 'Age',\n    hue = 'Sex',\n    style = 'Survived', style_order = [1,0],\n    alpha = 0.8\n)\n\nfig = plt.gcf()\nax = plt.gca()\nax.set_title('Scattor Plot')\n\nfig.add_axes([0.6,0.2,0.25,0.25])\nax_mini = plt.gca()\n## ax_mini = fig.add_axes([0.6,0.2,0.25,0.25])과 동일\n\nax_mini.hist(df.Age)\nax_mini.hist(df.Age[df.Survived == 1])\nax_mini.set_title('Histogram')\nfig.suptitle('TITANIC')\n\nplt.show()\n\n\n\n\n\ntype(fig) ## seaborn으로 제작하였음에도 Figure의 형식을 지닌다.\n\nmatplotlib.figure.Figure"
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html#훌륭한-시각화",
    "href": "posts/Data Visualization/Review/3. Seaborn.html#훌륭한-시각화",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "3. 훌륭한 시각화",
    "text": "3. 훌륭한 시각화"
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html#애드워드-터프티",
    "href": "posts/Data Visualization/Review/3. Seaborn.html#애드워드-터프티",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "### 애드워드 터프티",
    "text": "### 애드워드 터프티\n- 데이터 시각화계의 거장\n\n엄격한 미니멀리즘\n최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다.\n\n\n너무 구시대적인 사고일 수도 있음. 적합할 수도 있고."
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html#찰스미나드의-도표",
    "href": "posts/Data Visualization/Review/3. Seaborn.html#찰스미나드의-도표",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "### 찰스미나드의 도표",
    "text": "### 찰스미나드의 도표\n\n\n터프티도 극찬하고 ~중국이 놀라고, 일본이 경악하고…~\n\n\n군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스크바에서 퇴각하는 동안의 여러 날짜와 그 시점에서의 온도 -&gt; 6차원의 변수를 한 평면상에 표현\n\n미나드는 여러 그림을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함."
  },
  {
    "objectID": "posts/Data Visualization/Review/3. Seaborn.html#미나드처럼-그리는-게-왜-어려운가",
    "href": "posts/Data Visualization/Review/3. Seaborn.html#미나드처럼-그리는-게-왜-어려운가",
    "title": "Seaborn | 데이터프레임 친화적 패키지",
    "section": "4. 미나드처럼 그리는 게 왜 어려운가?",
    "text": "4. 미나드처럼 그리는 게 왜 어려운가?\n- 몸무게, 키, 성별, 국적을 나타내는 자료\n\ndf1=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male1.csv')   ## 남성의 키\ndf2=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/male2.csv')   ## 남성의 몸무게\ndf3=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/female.csv')  ## 여성의 키와 몸무게\ndf4=pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/foreign.csv') ## 외국인의 키와 몸무게, 성별, 국적\n\n\n_df = pd.concat([pd.concat([df1,df2],axis=1)\\\n                 .assign(g='m'),df3.assign(g='f')])\ndf = pd.concat([_df.assign(g2='korea'),df4.assign(g2='foreign')])\\\n.reset_index(drop=True)\ndf\n\n\n  \n    \n\n\n\n\n\n\nw\nh\ng\ng2\n\n\n\n\n0\n72.788217\n183.486773\nm\nkorea\n\n\n1\n66.606430\n173.599877\nm\nkorea\n\n\n2\n69.806324\n173.237903\nm\nkorea\n\n\n3\n67.449439\n173.223805\nm\nkorea\n\n\n4\n70.463183\n174.931946\nm\nkorea\n\n\n...\n...\n...\n...\n...\n\n\n1525\n78.154632\n188.324350\nm\nforeign\n\n\n1526\n74.754308\n183.017979\nf\nforeign\n\n\n1527\n91.196208\n190.100456\nm\nforeign\n\n\n1528\n87.770394\n187.987255\nm\nforeign\n\n\n1529\n88.021995\n193.456798\nm\nforeign\n\n\n\n\n\n1530 rows × 4 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nsns.scatterplot(\n    data=df,\n    x='w',\n    y='h',\n    hue='g',    ## group 1 : gender\n    style='g2',  ## group 2 : region\n    alpha=0.6\n)\n\n&lt;Axes: xlabel='w', ylabel='h'&gt;\n\n\n\n\n\n\n그래프를 이해하기 어려운 것은 아니지만, 아무래도 난잡한 것은 사실이다.\n\n-어려운 점 :\n\n센스 부족 : 센스가 없어서 그룹 구분할 생각을 못함\n개념 부족 : 타이디데이터( =tidy dataframe, long form dataframe) 형태로 데이터를 정리할 생각을 못함.\n코딩 못함 : 타이디테이터로 데이터를 변형하는 코드를 모름."
  },
  {
    "objectID": "posts/Data Visualization/Review/5. Pandas의 기본.html",
    "href": "posts/Data Visualization/Review/5. Pandas의 기본.html",
    "title": "Pandas 기본기 | 행과 열의 선택",
    "section": "",
    "text": "pandas에서 행과 열을 선택하는 기술에 대해서 알아보도록 하자!"
  },
  {
    "objectID": "posts/Data Visualization/Review/5. Pandas의 기본.html#라이브러리-import",
    "href": "posts/Data Visualization/Review/5. Pandas의 기본.html#라이브러리-import",
    "title": "Pandas 기본기 | 행과 열의 선택",
    "section": "1. 라이브러리 import",
    "text": "1. 라이브러리 import\n\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/Data Visualization/Review/5. Pandas의 기본.html#pandas-행과-열의-선택",
    "href": "posts/Data Visualization/Review/5. Pandas의 기본.html#pandas-행과-열의-선택",
    "title": "Pandas 기본기 | 행과 열의 선택",
    "section": "2. pandas : 행과 열의 선택",
    "text": "2. pandas : 행과 열의 선택\n- 같은 자료, 다른 두 형태의 데이터프레임\n\ndf = pd.DataFrame({'date': ['12/30','12/31','01/01','01/02','01/03'], 'X1': [65,95,65,55,80], 'X2': [55,100,90,80,30], 'X3': [50,50,60,75,30], 'X4': [40,80,30,80,100]})\ndf\n\n\n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n2\n01/01\n65\n90\n60\n30\n\n\n3\n01/02\n55\n80\n75\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n\n\n얘는 인덱스는 그저 숫자의 의미이고\n\n\nts = pd.DataFrame({'X1': [65,95,65,55,80], 'X2': [55,100,90,80,30], 'X3': [50,50,60,75,30], 'X4': [40,80,30,80,100]}, index=['12/30','12/31','01/01','01/02','01/03'])\nts  ## 중요한 코드는 아님, 근데 그냥 index 지정해주는 거잖아\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\n\n\n\n\n12/30\n65\n55\n50\n40\n\n\n12/31\n95\n100\n50\n80\n\n\n01/01\n65\n90\n60\n30\n\n\n01/02\n55\n80\n75\n80\n\n\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n\n\n얘는 인덱스에 시계열적 표현이 있다.\n\n\nts.reset_index()  ## 결국 이렇게 하는 게 다루기 편하다.\n\n\n  \n    \n\n\n\n\n\n\nindex\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n2\n01/01\n65\n90\n60\n30\n\n\n3\n01/02\n55\n80\n75\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n안바꾸고 냅두는 경우, index가 time seat를 의미하는 경우에는 안바꾸기도 한다. ~근데 위는 왜 다시 바꾼거~\n\n\nA. 열의 선택\n\n1번째 방법 : df.ㆍ\n! 치명적인 단점 : 변수 이름에 공백 등이 있으면 불러올 수 없음.\n\n\ndf.X1   ## df 또한 하나의 object이므로\n\n0    65\n1    95\n2    65\n3    55\n4    80\nName: X1, dtype: int64\n\n\n\n2번째 방법 : df['ㆍ'], df[['ㆍ']]\n\n\ndf['X1']  ## df를 일종의 딕셔너리처럼 취급하는 방법\n\n0    65\n1    95\n2    65\n3    55\n4    80\nName: X1, dtype: int64\n\n\n\nSeries로 불러온다.\n\ndictionary?\n\ndct = dict({'date': ['12/30','12/31','01/01','01/02','01/03'], 'X1': [65,95,65,55,80], 'X2': [55,100,90,80,30], 'X3': [50,50,60,75,30], 'X4': [40,80,30,80,100]})\ndct['X1']\n\n[65, 95, 65, 55, 80]\n\n\n\ndf.keys()\n\nIndex(['date', 'X1', 'X2', 'X3', 'X4'], dtype='object')\n\n\n\ndct.keys()\n\ndict_keys(['date', 'X1', 'X2', 'X3', 'X4'])\n\n\n\nkey와 value가 있는 것처럼 column의 한 값(key)에 대한 데이터(value)가 있는 모습이다.\n\n\ndf[['X1']]  ## 프레임으로 산출\n\n\n  \n    \n\n\n\n\n\n\nX1\n\n\n\n\n0\n65\n\n\n1\n95\n\n\n2\n65\n\n\n3\n55\n\n\n4\n80\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf[['X1', 'X2']]  ## 2개 이상 산출 가능\n\n\n  \n    \n\n\n\n\n\n\nX1\nX2\n\n\n\n\n0\n65\n55\n\n\n1\n95\n100\n\n\n2\n65\n90\n\n\n3\n55\n80\n\n\n4\n80\n30\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n3번째 방법 : df.iloc[:, ㆍ] &gt; 통째로 np.array와 같다고 보면 된다.\n\n\ndf.iloc[:, 0] ## numpy에서 행렬을 다루는 것과 완전히 같게 사용 가능.\n\n0    12/30\n1    12/31\n2    01/01\n3    01/02\n4    01/03\nName: date, dtype: object\n\n\n\n#df.iloc[:,0] ## int - 0번째 행 | [0]이면 데이터프레임으로\n#df.iloc[:,-2:] # int:int, -2번째 행부터 -1번째 행까지(뒤에서 두 개)\n#df.iloc[:,1::2] # int:int:int - 스트라이딩, 1번째(두번째) 행부터 2개 단위로 추출\n#df.iloc[:,[0,2]] # [int,int] - 특정 행(0, 2번째)을 데이터프레임의 형태로 반환\n#df.iloc[:,[True,True,False,False,False]] # bool의 list\n#df.iloc[:,range(2)] # range, 앞에서 2개\n\n\n4번째 방법 : df.loc[:, ㆍ] &gt; 완전히 새로운 방법\n\n\n#df.loc[:,'X1'] # str - 시리즈 | ['X1']이면 데이터프레임으로\n#df.loc[:,'X1':'X3'] # 'str':'str' -- 칼럼이름으로 슬라이싱 **\n#df.loc[:,'X1'::2] # 'str'::int -- 칼럼이름으로 스트라이딩 **\n#df.loc[:,['X1','X4']] # [str,str] - 특정 행만 데이터프레임으로\n#df.loc[:,[True,False,False,True,False]] # bool의 list\n\n\"\"\"\n그냥 왠만해선 다 됨\n\"\"\"\n\n- 'date'행 부터\n\ndf.loc[:, 'date':]\n\n\n  \n    \n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n2\n01/01\n65\n90\n60\n30\n\n\n3\n01/02\n55\n80\n75\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n- True가 입력된 행만\n\ndf.loc[:, [True, False, True, False, True]]   ## columns의 이름에 어떤 조건을 걸어서 True에 해당하는 열만 산출 가능\n\n\n  \n    \n\n\n\n\n\n\ndate\nX2\nX4\n\n\n\n\n0\n12/30\n55\n40\n\n\n1\n12/31\n100\n80\n\n\n2\n01/01\n90\n30\n\n\n3\n01/02\n80\n80\n\n\n4\n01/03\n30\n100\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n- 2칸씩 띄며 스트라이딩\n\ndf.loc[:, ::2]  ## 2 간격으로 스트라이딩\n\n\n\n\n\n\n\n\ndate\nX2\nX4\n\n\n\n\n0\n12/30\n55\n40\n\n\n1\n12/31\n100\n80\n\n\n2\n01/01\n90\n30\n\n\n3\n01/02\n80\n80\n\n\n4\n01/03\n30\n100\n\n\n\n\n\n\n\n\n\nB. 행의 선택\n\n방법1 : df[]\n\n\ndf[:2]    ## int:int -- 슬라이싱 // df.iloc[:2, :], df.iloc[:2] 와 같음\n\n\n  \n    \n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf[::2]  ## 스트라이딩, df.iloc[::2]와 같음\n\n\n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n2\n01/01\n65\n90\n60\n30\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n\n\n# df[:2] # int:int -- 슬라이싱 // df.iloc[:2,:], df.iloc[:2] 와 같음\n# df[::2] # int:int -- 스트라이딩\n# ts['12/30':'01/02'] # str:str -- 슬라이싱 &gt; 인덱스가 문자열 등일 경우\n# ts['12/31'::2] # str:str -- 스트라이딩\n# df[['12' in date for date in df.date]] # [bool,bool] `12`가 데이터에 포함되어 있을 경우\n# df[df.X1 &lt; 70] # pd.Series([bool,bool])\n\n\n방법2 : df.iloc[]\n\n\n# df.iloc[0] # int  df.iloc[0, :]에서 생략된 표현\n# df.iloc[-2:] # int:int -- 슬라이싱\n# df.iloc[1::2] # int:int -- 스트라이딩\n# df.iloc[[0]] # [int]\n# df.iloc[[0,1]] # [int,int]\n# df.iloc[['12' in date for date in df.date]] # [bool,bool] 이 경우는 []와 동일하다.\n# df.iloc[range(2)] # range\n\n- 해당 방법은 리스트나 어레이의 원소를 다루는 것과 완전히 동일해서… 아래를 참고하면 된다.\n\nlst = [[1,2,3], [3,4,5]]\nlst[0]\n\n[1, 2, 3]\n\n\n\nary = np.array(lst)\nary[0]\n\narray([1, 2, 3])\n\n\n\n방법3 : df.loc[]\n\n\n# df.loc[0] # int \n# ts.loc['12/30'] # str \n# df.loc[:2] # int:int \n# ts.loc[:'01/02'] # str:str \n# df.loc[[0,1]] # [int,int]\n# ts.loc[['12/30','01/01']] # [str,str]\n# df.loc[['12' in date for date in df.date]] # [bool,bool] 이 경우는 []와 동일하다.\n# df.loc[df.X1&gt;70] # pd.Series([bool,bool]) \n\n\ndf.loc[:2]  ## character와 비슷한 형식이기 때문에 2까지 포함이 된다.\n\n\n  \n    \n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n2\n01/01\n65\n90\n60\n30\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf.loc[df.X1 &gt; 70]\n\n\n  \n    \n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf.loc[df.X1 &gt; 70]\n\n\n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n\n\n위처럼 튜플로 넣을 수도 있다. 근데 iloc의 경우 위와 같은 코드로 입력하면 오류가 난다.\n\n\n## df.iloc[df.X1 &gt; 70] &gt; 오류, bool을 받을 수 있으나, 튜플의 형태로 들어가면 반환하지 않는다.\ndf.iloc[list(df.X1 &gt; 70)]\n\n\n  \n    \n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nD. 교수님 방식\n-가장 안전한 코드\n\ndf.loc[:,:] ## 해당 코드를 써놓고 시작, generally\n\n\n  \n    \n\n\n\n\n\n\ndate\nX1\nX2\nX3\nX4\n\n\n\n\n0\n12/30\n65\n55\n50\n40\n\n\n1\n12/31\n95\n100\n50\n80\n\n\n2\n01/01\n65\n90\n60\n30\n\n\n3\n01/02\n55\n80\n75\n80\n\n\n4\n01/03\n80\n30\n30\n100\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n하나의 col을 뽑으려 할 때\n\n\n# df.X1       ## 제일 간단함. 게다가 눌러보면 변수 이름들이 나옴\n# df['X1']\n# df[['X1']]\n\n\nrow를 슬라이싱\n\n\n# df[:5]\n# ts[:'01/02']  # 시계열일 경우\n\n\n조건에 맞는 row를 뽑을 때 좋은 코드\n\n\n# df[df.X1&lt;60]  ## 이게 좋기는 한데, True, False를 직접 만들어야 하는 경우도 많음.\n# df.loc[['12' in date for date in df.date]]\n\n\n['12' in date for date in df.date]\n\n[True, True, False, False, False]\n\n\n\n하나의 row를 뽑으려 할 때 좋은 코드\n\n\n# df.iloc[0]\n# df.loc[0]\n\n\nts.iloc[[0]]\n# ts.iloc[0]의 경우 오류가 남(인덱스 이름이 숫자열이 아님\n\n\n  \n    \n\n\n\n\n\n\nX1\nX2\nX3\nX4\n\n\n\n\n12/30\n65\n55\n50\n40\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\n\n(row,col)을 뽑으려 할 때 좋은 코드\n\n\n# df.X1[0]    ## &lt;- pd.Series를 뽑고 인덱스로 접근\n# df['X1'][0]\n\n\n# df.iloc[0,0]\n# df.loc[0,'X1']\n\n*위의 상황 이외에는 df.loc[:,:]를 사용하는 것이 유리하다.\n\n\n요약\n\n알아두면 좋은 규칙\n.iloc[] 와 .iloc[,:]는 완전히 동등하다.\n.loc[] 와 .loc[,:]는 완전히 동등하다.\n결과를 pd.Series 형태가 아닌 pd.DataFrame 형태로 얻고 싶다면 [[?]]를 사용하면 된다.\n\n\n\nROW\n\n\n\n\n\n\n\n\n\n\n\ntype of indexer\n.\n[]\n.iloc\n.loc\n내가 쓴다면?\n\n\n\n\nint\nX\nX\nO\n\\(\\Delta\\)\ndf.iloc[3,:]\n\n\nint:int\nX\nO\nO\n\\(\\Delta\\)\ndf[3:5]\n\n\n[int,int]\nX\nX\nO\n\\(\\Delta\\)\ndf.iloc[idx,:]\n\n\nstr\nX\nX\nX\nO\nts.loc['time1',:]\n\n\nstr:str\nX\nO\nX\nO\nts.loc['time1':'time2',:]\n\n\n[str,str]\nX\nX\nX\nO\n안할 듯\n\n\n[bool,bool]\nX\nO\nO\nO\ndf[filtered_idx]\n\n\npd.Series([bool,bool])\nX\nO\nX\nO\ndf[df.X1&gt;20]\n\n\n\n\n\nCOL\n\n\n\n\n\n\n\n\n\n\n\n\ntype of indexer\ntarget\n.\n[]\n.iloc\n.loc\n내가 쓴다면?\n\n\n\n\nint\ncol\nX\nX\nO\nX\ndf.iloc[:,0]\n\n\nint:int\ncol\nX\nX\nO\nX\ndf.iloc[:,0:2]\n\n\n[int,int]\ncol\nX\nX\nO\nX\ndf.iloc[:,idx]\n\n\nstr\ncol\nO\nO\nX\nO\ndf.loc[:,'X1']\n\n\nstr:str\ncol\nX\nX\nX\nO\ndf.loc[:,'X1':'X4']\n\n\n[str,str]\ncol\nX\nO\nX\nO\ndf.loc[:,colname_list]\n\n\n[bool,bool]\ncol\nX\nX\nO\nO\ndf.loc[:,bool_list]"
  },
  {
    "objectID": "posts/Data Visualization/Review/7. Pandas 팁.html",
    "href": "posts/Data Visualization/Review/7. Pandas 팁.html",
    "title": "Pandas 사용 팁",
    "section": "",
    "text": "Pandas에서 유용하게 사용할 수 있는 여러가지 메소드들을 알아보자!"
  },
  {
    "objectID": "posts/Data Visualization/Review/7. Pandas 팁.html#라이브러리-imports",
    "href": "posts/Data Visualization/Review/7. Pandas 팁.html#라이브러리-imports",
    "title": "Pandas 사용 팁",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\nimport numpy as np\nimport pandas as pd\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/Review/7. Pandas 팁.html#pabdas-transform-column",
    "href": "posts/Data Visualization/Review/7. Pandas 팁.html#pabdas-transform-column",
    "title": "Pandas 사용 팁",
    "section": "2. pabdas : transform column",
    "text": "2. pabdas : transform column\nA. lambda\nB. map\n\nC. s.apply(변환함수) | 원소들을 각각 변환\n\n\n변환함수 : 원래 형식을 보존하면서 원소들을 바꾸는 함수\n집계함수 : 벡터 -&gt; 스칼라 (평균을 불러주는 함수 : [1,2,3,4,5] -&gt; 3)\n\n\n라고 하자.\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')   ## DataFrame\ns = df.Height   ## Series\n\n\ns\n\n0        189cm\n1        179cm\n2        172cm\n3        181cm\n4        172cm\n         ...  \n17655    190cm\n17656    195cm\n17657    190cm\n17658    187cm\n17659    186cm\nName: Height, Length: 17660, dtype: object\n\n\n\n뒤에 cm가 붙어있는 범주형 자료로 저장되어있음.\n\n\ns.apply(lambda x : int(x[:3])) ## 집계함수가 아닌 변환함수만 적용할 수 있음. 각 원소에 함수 적용.\n##s.apply(lambda x : x[:3]).apply(int)    ## 연쇄적으로\n##s.apply(lambda x : x[:3]).astype('int64')   ## astype() 이용\n\n0        189\n1        179\n2        172\n3        181\n4        172\n        ... \n17655    190\n17656    195\n17657    190\n17658    187\n17659    186\nName: Height, Length: 17660, dtype: int64\n\n\n\ncm를 제거하고 포맷을 정수형으로 변경하였다."
  },
  {
    "objectID": "posts/Data Visualization/Review/7. Pandas 팁.html#d.-s.str-idx.str-string-오브젝트에만-사용할-수-있는-함수를-사용",
    "href": "posts/Data Visualization/Review/7. Pandas 팁.html#d.-s.str-idx.str-string-오브젝트에만-사용할-수-있는-함수를-사용",
    "title": "Pandas 사용 팁",
    "section": "### D. s.str, idx.str | string 오브젝트에만 사용할 수 있는 함수를 사용",
    "text": "### D. s.str, idx.str | string 오브젝트에만 사용할 수 있는 함수를 사용\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\ns = df.Height\n\n\n\"180cm\"[:3]\n\n'180'\n\n\n\n'180cm'.replace('cm','')\n\n'180'\n\n\n\n위와 같은 연산을 시리즈에 적용시키고 싶다.\n\n\ns.str[:3]\n##s.str.replace('cm', '')   ## 개별 문자열과 동일하게 메소드를 적용시켜도 된다.\n\n0        189\n1        179\n2        172\n3        181\n4        172\n        ... \n17655    190\n17656    195\n17657    190\n17658    187\n17659    186\nName: Height, Length: 17660, dtype: object\n\n\n\n문자열의 메소드를 그대로 적용 가능\n\n- 예시2 : 원소별로 isupper를 수행(대문자인지 판별)\n\n_s = pd.Series(['A','B','C','d','e','F'])\n_s\n\n0    A\n1    B\n2    C\n3    d\n4    e\n5    F\ndtype: object\n\n\n\n_s.str.isupper()\n\n0     True\n1     True\n2     True\n3    False\n4    False\n5     True\ndtype: bool\n\n\n- 예시3 : 원소별로 공백 제거(pd.Serise 뿐만 아니라 pd.index 자료형에도 사용가능)\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DV2022/master/posts/FIFA23_official_data.csv')\nidx = df.columns\n\n\nidx.str.replace(' ', '')\n\nIndex(['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall',\n       'Potential', 'Club', 'ClubLogo', 'Value', 'Wage', 'Special',\n       'PreferredFoot', 'InternationalReputation', 'WeakFoot', 'SkillMoves',\n       'WorkRate', 'BodyType', 'RealFace', 'Position', 'Joined', 'LoanedFrom',\n       'ContractValidUntil', 'Height', 'Weight', 'ReleaseClause', 'KitNumber',\n       'BestOverallRating'],\n      dtype='object')\n\n\n- 쉽게 말해서 string데이터를 지닌 개체에 string에 사용할 수 있는 메소드를 사용할 수 있도록 하는 게 pandas의 str이라고 보면 된다.\n\nE. s.astype() | 조건을 충족한 시리즈의 타입을 변경\n\n- 예시1 : 원소의 타입을 변경\n\ns = pd.Series(list('12345'))\ns\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: object\n\n\n\ns.astype(int)\n##s.apply(int)\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\n\n\n- 예시2 : 원소의 타입을 변환한 이후 브로드캐스팅\n\ns1 = pd.Series(list('12345'))\ns2 = pd.Series([-1,-2,-3,-4,-5])\n\n\ns1+s2\n\nTypeError: ignored\n\n\n\nError : 형식이 달라 불가능\n\n\ns1.astype(int) + s2\n\n0    0\n1    0\n2    0\n3    0\n4    0\ndtype: int64\n\n\n\ns2.astype(str) + s1\n\n0    -11\n1    -22\n2    -33\n3    -44\n4    -55\ndtype: object\n\n\n- 예시3 : 원소의 타입을 변환한 이후 브로드캐스팅(str)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2023/main/posts/titanic.csv\")[:5]\ndf\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nlogFare\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n1.981001\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n4.266662\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n2.070022\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n3.972177\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n2.085672\n\n\n\n\n\n\n\n위의 자료에서 Embarked열과 Pclass열을 사용하여 아래와 같은 New Feature를 만들어라.\n\n\n\nEmbarked\nPclass\nNew Feature\n\n\n\n\n‘S’\n3\n‘S3’\n\n\n‘C’\n1\n‘C1’\n\n\n‘S’\n3\n‘S3’\n\n\n‘S’\n1\n‘S1’\n\n\n‘S’\n3\n‘S3’\n\n\n\n둘다 문자열이면 단순히 +를 이용해 브로드캐스팅하면 되지만, 타입이 달라 불가하다.\n\ndf.Embarked + df.Pclass.apply(str)\n##df.Embarked + df.Pclass.astype(str)\n##df.Embarked + pd.Series(list(map(lambda x : str(x)), df.Pclass))\n\n0    S3\n1    C1\n2    S3\n3    S1\n4    S3\ndtype: object"
  },
  {
    "objectID": "posts/Data Visualization/Review/7. Pandas 팁.html#f.-컴프리헨션-lambda-map을-무시하지-말-것",
    "href": "posts/Data Visualization/Review/7. Pandas 팁.html#f.-컴프리헨션-lambda-map을-무시하지-말-것",
    "title": "Pandas 사용 팁",
    "section": "### F. 컴프리헨션, lambda + map을 무시하지 말 것",
    "text": "### F. 컴프리헨션, lambda + map을 무시하지 말 것\n- 예시1\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2023/main/posts/titanic.csv\")[:5]\ndf\n\n\n  \n    \n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nlogFare\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n1.981001\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n4.266662\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n2.070022\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n3.972177\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n2.085672\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n위 자료에서 아래와 같은 변환을 하고 싶다면 apply만으로 사용하기에 부담이 된다.\n\\[\nf(\\text{sex}, \\text{sibsp}) =\n\\begin{cases}\n0.7 + 0.25 \\times \\text{sibsp} & \\text{if } \\text{sex} = \\text{'female'} \\\\\n0.2 + 0.15 \\times \\text{sibsp} & \\text{otherwise}\n\\end{cases}\n\\]\n\nlist(map(lambda sex, sibsp : 0.7+0.25*sibsp if sex == 'female' else 0.2+0.15*sibsp, df.Sex, df.SibSp))\n\n[0.35, 0.95, 0.7, 0.95, 0.2]\n\n\n\ndf.assign(Probablity = list(map(lambda sex, sibsp : 0.7+0.25*sibsp if sex == 'female' else 0.2+0.15*sibsp, df.Sex, df.SibSp)))\n\n\n  \n    \n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nlogFare\nProbablity\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n1.981001\n0.35\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n4.266662\n0.95\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n2.070022\n0.70\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n3.972177\n0.95\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n2.085672\n0.20\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n- 예시2\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2023/main/posts/titanic.csv\")[:5]\ndf\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nlogFare\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n1.981001\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n4.266662\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n2.070022\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n3.972177\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n2.085672\n\n\n\n\n\n\n\n위의 자료에서 Name열을 아래와 같이 분리하는 작업을 수행하라.\n\n\n\n\ntitle\nName\n\n\n\n\n0\nMr\nOwen Harris Braund\n\n\n1\nMrs\nJohn Bradley (Florence Briggs Thayer) Cumings\n\n\n2\nMiss\nLaina Heikkinen\n\n\n3\nMrs\nJacques Heath (Lily May Peel) Futrelle\n\n\n4\nMr\nWilliam Henry Allen\n\n\n\n- 풀이 1\n\ndf.Name.str.replace(', ','/').str.replace('. ','/').str.split('/')\n\n0                            [Braund, Mr, Owen Harris]\n1    [Cumings, Mrs, John Bradley (Florence Briggs T...\n2                             [Heikkinen, Miss, Laina]\n3       [Futrelle, Mrs, Jacques Heath (Lily May Peel)]\n4                           [Allen, Mr, William Henry]\nName: Name, dtype: object\n\n\n\n[[title, name + ' ' + f_name] for f_name, title, name in df.Name.str.replace(', ','/').str.replace('. ','/').str.split('/')]\n\n[['Mr', 'Owen Harris Braund'],\n ['Mrs', 'John Bradley (Florence Briggs Thayer) Cumings'],\n ['Miss', 'Laina Heikkinen'],\n ['Mrs', 'Jacques Heath (Lily May Peel) Futrelle'],\n ['Mr', 'William Henry Allen']]\n\n\n- 풀이 2 : 이중 컴프리헨션이 될까 해서 해봤는데… 되네?~(솔직히 안될 이유가 없긴 함, 리스트를 반환하는 거니까…)~\n\n[[names[0], names[1] + ' ' + f_name] for f_name, names in [[f_name, names.split('. ')] for f_name, names in df.Name.str.split(', ')]]\n\n[['Mr', 'Owen Harris Braund'],\n ['Mrs', 'John Bradley (Florence Briggs Thayer) Cumings'],\n ['Miss', 'Laina Heikkinen'],\n ['Mrs', 'Jacques Heath (Lily May Peel) Futrelle'],\n ['Mr', 'William Henry Allen']]\n\n\n\nlists = [[names[0], names[1] + ' ' + f_name] for f_name, names in [[f_name, names.split('. ')] for f_name, names in df.Name.str.split(', ')]]\npd.DataFrame({'title' : np.array(lists)[:,0], 'Name' : np.array(lists)[:,1]})\n\n\n\n\n\n\n\n\ntitle\nName\n\n\n\n\n0\nMr\nOwen Harris Braund\n\n\n1\nMrs\nJohn Bradley (Florence Briggs Thayer) Cumings\n\n\n2\nMiss\nLaina Heikkinen\n\n\n3\nMrs\nJacques Heath (Lily May Peel) Futrelle\n\n\n4\nMr\nWilliam Henry Allen"
  },
  {
    "objectID": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html",
    "href": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html",
    "title": "집단 간 비교 : 심슨의 역설",
    "section": "",
    "text": "심슨의 역설"
  },
  {
    "objectID": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#라이브러리-imports",
    "href": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#라이브러리-imports",
    "title": "집단 간 비교 : 심슨의 역설",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\nimport pandas as pd\nimport numpy as np\nfrom plotnine import *"
  },
  {
    "objectID": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#필요한-코드-비교를-위한-시각화",
    "href": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#필요한-코드-비교를-위한-시각화",
    "title": "집단 간 비교 : 심슨의 역설",
    "section": "2. 필요한 코드 | 비교를 위한 시각화",
    "text": "2. 필요한 코드 | 비교를 위한 시각화\n\nA. geom_col()\n\n- 예시1 : geom_col() 기본적인 막대 그래프\n\ndf = pd.DataFrame({'x':[0,1],'y':[40,60]})\ndf\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0\n40\n\n\n1\n1\n60\n\n\n\n\n\n\n\n\nfig = ggplot(df)\nbar = geom_col(aes(x = 'x', y = 'y'))   ## geom_bar()는 그냥 없다고 생각하자.\n\nfig + bar\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n- 예시2 : \\(x\\)축이 범주형인 경우\n\ndf = pd.DataFrame({'sex':['male','female'],'score':[40,60]})\ndf\n\n\n\n\n\n\n\n\nsex\nscore\n\n\n\n\n0\nmale\n40\n\n\n1\nfemale\n60\n\n\n\n\n\n\n\n\nfig = ggplot(df)\nbar = geom_col(aes(x = 'sex', y = 'score'))   ## 설명변수가 문자열이어도 산출해준다.\n\nfig + bar\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n- 예시3 : fill = 'index'예시2에서 범주별 색깔로 구분하고 싶은 경우\n\ndf = pd.DataFrame({'sex':['male','female'],'score':[40,60]})\ndf\n\n\n\n\n\n\n\n\nsex\nscore\n\n\n\n\n0\nmale\n40\n\n\n1\nfemale\n60\n\n\n\n\n\n\n\n\nfig = ggplot(df)\nbar = geom_col(aes(x = 'sex', y = 'score', fill = 'sex'))   ## color 옵션도 있으나, 이것은 바깥의 테두리 색상만 바꾼다.\n\nfig + bar\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n- 예시4 : 예시3에서 scale_fill_manual()을 이용하여 색상 변경하기\n\ndf = pd.DataFrame({'sex':['male','female'],'score':[40,60]})\ndf\n\n\n  \n    \n\n\n\n\n\n\nsex\nscore\n\n\n\n\n0\nmale\n40\n\n\n1\nfemale\n60\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nfig = ggplot(df)\nbar = geom_col(aes(x = 'sex', y = 'score', fill = 'sex'))\n\nfig + bar + scale_fill_manual(['red','blue'])\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n색상 입력에는 이름이 정해진 색상들 뿐만 아니라 plt.plot(color = option)에서의 옵션과 같이 이미 설정된 C0, C1… 또는 hex code도 입력이 가능하다."
  },
  {
    "objectID": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#b.-facet_warp-한-면을-감싸다.",
    "href": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#b.-facet_warp-한-면을-감싸다.",
    "title": "집단 간 비교 : 심슨의 역설",
    "section": "### B. facet_warp() | 한 면을 감싸다.",
    "text": "### B. facet_warp() | 한 면을 감싸다.\n- 예시1 : facet_warp()를 이용한 면분할 – 반별로 면분할\n\ndf = pd.DataFrame({'sex':['male','female','male','female'],'score':[40,60,50,20],'class':['A','A','B','B']})\ndf\n\n\n\n\n\n\n\n\nsex\nscore\nclass\n\n\n\n\n0\nmale\n40\nA\n\n\n1\nfemale\n60\nA\n\n\n2\nmale\n50\nB\n\n\n3\nfemale\n20\nB\n\n\n\n\n\n\n\n\nggplot(df) + geom_col(aes(x='sex',y='score',fill='sex')) + scale_fill_manual(['red','blue']) + facet_wrap('class')\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\nclass별로 그래프의 면을 분할해서 표시\n\n\nggplot(df) + geom_col(aes(x = 'sex', y = 'score', fill = 'sex')) + scale_fill_manual(['red','blue'])  ## 지정해주지 않을 경우 기본적으로 합산하여 지정된다.\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n- 예시2 : 성별로 면분할\n\ndf = pd.DataFrame({'sex':['male','female','male','female'],'score':[40,60,50,20],'class':['A','A','B','B']})\ndf\n\n\n  \n    \n\n\n\n\n\n\nsex\nscore\nclass\n\n\n\n\n0\nmale\n40\nA\n\n\n1\nfemale\n60\nA\n\n\n2\nmale\n50\nB\n\n\n3\nfemale\n20\nB\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nggplot(df) + geom_col(aes(x='class',y='score',fill='sex')) + facet_wrap('sex')\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n이 경우 'sex'로 color를 구분했으므로 면마다 다른 색의 그래프만이 나온다."
  },
  {
    "objectID": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#심슨의-역설",
    "href": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#심슨의-역설",
    "title": "집단 간 비교 : 심슨의 역설",
    "section": "4. 심슨의 역설",
    "text": "4. 심슨의 역설\n- 버클리 대학교의 입학 데이터에서 gender bias가 존재한다는 주장이 있었다.\n\ndf=pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/master/posts/Simpson.csv\",index_col=0,header=[0,1])\\\n.stack().stack().reset_index()\\\n.rename({'level_0':'department','level_1':'result','level_2':'gender',0:'count'},axis=1)\ndf\n\n\n\n\n\n\n\n\ndepartment\nresult\ngender\ncount\n\n\n\n\n0\nA\nfail\nfemale\n19\n\n\n1\nA\nfail\nmale\n314\n\n\n2\nA\npass\nfemale\n89\n\n\n3\nA\npass\nmale\n511\n\n\n4\nB\nfail\nfemale\n7\n\n\n5\nB\nfail\nmale\n208\n\n\n6\nB\npass\nfemale\n18\n\n\n7\nB\npass\nmale\n352\n\n\n8\nC\nfail\nfemale\n391\n\n\n9\nC\nfail\nmale\n204\n\n\n10\nC\npass\nfemale\n202\n\n\n11\nC\npass\nmale\n121\n\n\n12\nD\nfail\nfemale\n244\n\n\n13\nD\nfail\nmale\n279\n\n\n14\nD\npass\nfemale\n131\n\n\n15\nD\npass\nmale\n138\n\n\n16\nE\nfail\nfemale\n299\n\n\n17\nE\nfail\nmale\n137\n\n\n18\nE\npass\nfemale\n94\n\n\n19\nE\npass\nmale\n54\n\n\n20\nF\nfail\nfemale\n103\n\n\n21\nF\nfail\nmale\n149\n\n\n22\nF\npass\nfemale\n238\n\n\n23\nF\npass\nmale\n224\n\n\n\n\n\n\n\n\nA. 시각화 1 : 전체 합격률 시각화 – pandas 초보\n\n- 단순무식하게 query만 이용해서 그룹화\n\ndf.query('gender == \"female\" and result == \"pass\"')['count'].sum()\n\n772\n\n\n\n여성 지원자 중 합격한 사람의 수\n\n\ndf.query('gender == \"female\"')['count'].sum()\n\n1835\n\n\n\n총 여성 지원자 수\n\n\n(df.query('gender == \"female\" and result == \"pass\"')['count'].sum()/df.query('gender == \"female\"')['count'].sum(),\n df.query('gender == \"male\" and result == \"pass\"')['count'].sum()/df.query('gender == \"male\"')['count'].sum())\n\n(0.420708446866485, 0.5202526941657376)\n\n\n\ntidydata_ = pd.DataFrame({'female' : [df.query('gender == \"female\" and result == \"pass\"')['count'].sum()/df.query('gender == \"female\"')['count'].sum()],\n                          'male' : [df.query('gender == \"male\" and result == \"pass\"')['count'].sum()/df.query('gender == \"male\"')['count'].sum()]})\n\ntidydata_\n\n\n\n\n\n\n\n\nfemale\nmale\n\n\n\n\n0\n0.420708\n0.520253\n\n\n\n\n\n\n\n\n이렇게 하면 시각화 못해요…\n\n\ntidydata = pd.DataFrame({'sex' : ['male', 'female'],\n                         'rate' : [df.query('gender == \"female\" and result == \"pass\"')['count'].sum()/df.query('gender == \"female\"')['count'].sum(),\n                                   df.query('gender == \"male\" and result == \"pass\"')['count'].sum()/df.query('gender == \"male\"')['count'].sum()]})\n\ntidydata\n\n\n\n\n\n\n\n\nsex\nrate\n\n\n\n\n0\nmale\n0.420708\n\n\n1\nfemale\n0.520253"
  },
  {
    "objectID": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#b.-시각화-1-전체-합격률-시각화-pandas-고수",
    "href": "posts/Data Visualization/Review/9. 집단 간 비교_심슨의 역설.html#b.-시각화-1-전체-합격률-시각화-pandas-고수",
    "title": "집단 간 비교 : 심슨의 역설",
    "section": "### B. 시각화 1 : 전체 합격률 시각화 – pandas 고수",
    "text": "### B. 시각화 1 : 전체 합격률 시각화 – pandas 고수\ndf.pivot_table(index = row, columns = col, valuse = value_col, aggfunc = func)\n- 피벗 테이블을 만든다. (두 범주형 자료들을 나누는 것)\n\ndf.pivot_table(index='gender',columns='result',values='count',aggfunc=sum)\n\n\n\n\n\n\n\nresult\nfail\npass\n\n\ngender\n\n\n\n\n\n\nfemale\n1063\n772\n\n\nmale\n1291\n1400\n\n\n\n\n\n\n\n\ndf.pivot_table(index='gender',columns='result',values='count')    ## 집계함수의 디폴트 값이 mean이다\n\n\n  \n    \n\n\n\n\n\nresult\nfail\npass\n\n\ngender\n\n\n\n\n\n\nfemale\n177.166667\n128.666667\n\n\nmale\n215.166667\n233.333333\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n이 상태에서 reset_index()를 통해 자료를 쉽게 정리할 수 있다.\n\n\ndf.pivot_table(index='gender',columns='result',values='count',aggfunc=sum)\\\n.assign(rate = lambda _df : _df['pass']/(_df['fail'] + _df['pass']))\n## 비율까지 추가한 모습, lambda _df : _df를 통해 현재 데이터프레임까지 호출한 모습\n\n\n\n\n\n\n\nresult\nfail\npass\nrate\n\n\ngender\n\n\n\n\n\n\n\nfemale\n1063\n772\n0.420708\n\n\nmale\n1291\n1400\n0.520253\n\n\n\n\n\n\n\n\ndf.pivot_table(index='gender',columns='result',values='count',aggfunc=sum)\\\n.assign(rate = lambda _df : _df['pass']/(_df['fail'] + _df['pass'])).reset_index()\n\n\n\n\n\n\n\nresult\ngender\nfail\npass\nrate\n\n\n\n\n0\nfemale\n1063\n772\n0.420708\n\n\n1\nmale\n1291\n1400\n0.520253\n\n\n\n\n\n\n\n- 이제 가공된 데이터를 tidydata라고 하여 그래프를 그려보자.\n\ntidydata = df.pivot_table(index='gender',columns='result',values='count',aggfunc=sum).assign(rate = lambda _df : _df['pass']/(_df['fail'] + _df['pass'])).reset_index()\n\nfig = ggplot(tidydata)\nbar = geom_col(aes(x='gender',fill='gender',y='rate'))\nfig+bar\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n이 그래프를 보고 나온 주장 : 여성이 남성에 비해 합격률이 낮으니까 차별이 있다!!\n\n- 반박\n\ndf.pivot_table(index=['department'],columns=['result','gender'],values='count',aggfunc=sum).stack()\n##df.pivot_table(index = ['department', 'gender'], columns = 'result', values = 'count', aggfunc = sum)\n## 위의 두 코드는 완전히 똑같은 동작을 한다. 아마도...\n\n\n\n\n\n\n\n\nresult\nfail\npass\n\n\ndepartment\ngender\n\n\n\n\n\n\nA\nfemale\n19\n89\n\n\nmale\n314\n511\n\n\nB\nfemale\n7\n18\n\n\nmale\n208\n352\n\n\nC\nfemale\n391\n202\n\n\nmale\n204\n121\n\n\nD\nfemale\n244\n131\n\n\nmale\n279\n138\n\n\nE\nfemale\n299\n94\n\n\nmale\n137\n54\n\n\nF\nfemale\n103\n238\n\n\nmale\n149\n224\n\n\n\n\n\n\n\n\ntemp.pass  ## pass 자체가 파이썬에서 특수하게 사용되는 조건어같은 거여서 안된다.\n\nSyntaxError: invalid syntax (2928908933.py, line 1)\n\n\n\ntemp = df.pivot_table(index=['department'],columns=['result','gender'],values='count',aggfunc=sum).stack()\ntemp['fail'] + temp['pass']\n\ndepartment  gender\nA           female    108\n            male      825\nB           female     25\n            male      560\nC           female    593\n            male      325\nD           female    375\n            male      417\nE           female    393\n            male      191\nF           female    341\n            male      373\ndtype: int64\n\n\n\ndf.pivot_table(index=['department'],columns=['result','gender'],values='count',aggfunc=sum).stack()\\\n.assign(rate = lambda _df: _df['pass']/(_df.fail+_df['pass']))\n##df.pivot_table(index = ['gender', 'department'], columns = 'result', values = 'count', aggfunc = sum).reset_index().assign(rate = lambda _df: _df['pass']/(_df.fail+_df['pass']))\n\n\n\n\n\n\n\n\nresult\nfail\npass\nrate\n\n\ndepartment\ngender\n\n\n\n\n\n\n\nA\nfemale\n19\n89\n0.824074\n\n\nmale\n314\n511\n0.619394\n\n\nB\nfemale\n7\n18\n0.720000\n\n\nmale\n208\n352\n0.628571\n\n\nC\nfemale\n391\n202\n0.340641\n\n\nmale\n204\n121\n0.372308\n\n\nD\nfemale\n244\n131\n0.349333\n\n\nmale\n279\n138\n0.330935\n\n\nE\nfemale\n299\n94\n0.239186\n\n\nmale\n137\n54\n0.282723\n\n\nF\nfemale\n103\n238\n0.697947\n\n\nmale\n149\n224\n0.600536\n\n\n\n\n\n\n\n- tidydata 완성\n\ndf.pivot_table(index=['department'],columns=['result','gender'],values='count',aggfunc=sum).stack()\\\n.assign(rate = lambda _df: _df['pass']/(_df.fail+_df['pass'])).reset_index().drop(['fail', 'pass'], axis = 1)\n\ntidydata = _\ntidydata\n\n\n\n\n\n\n\nresult\ndepartment\ngender\nrate\n\n\n\n\n0\nA\nfemale\n0.824074\n\n\n1\nA\nmale\n0.619394\n\n\n2\nB\nfemale\n0.720000\n\n\n3\nB\nmale\n0.628571\n\n\n4\nC\nfemale\n0.340641\n\n\n5\nC\nmale\n0.372308\n\n\n6\nD\nfemale\n0.349333\n\n\n7\nD\nmale\n0.330935\n\n\n8\nE\nfemale\n0.239186\n\n\n9\nE\nmale\n0.282723\n\n\n10\nF\nfemale\n0.697947\n\n\n11\nF\nmale\n0.600536\n\n\n\n\n\n\n\n\nfig = ggplot(tidydata)\nbar = geom_col(aes(x = 'gender', y = 'rate', fill = 'gender'))\n\nfig + bar + scale_fill_manual(['red', 'blue']) + facet_wrap(['department'])\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\nC와 E를 제외하고는 오히려 여성의 합격 비율이 더 높은 것을 알 수 있다.\n\n\nD. 해석\n\n- 시각화 1 : 남자의 합격률이 더 높다 -&gt; 성차별이 있어보인다(?)\n- 시각화 2 : 학과별로 살펴보니 오히려 A, B, F, D의 경우 여성의 합격률이 높다.\n- 교재에서 설명한 이유 : 여성이 합격률이 낮은 학과에만 많이 지원하였기 때문.\n\ndf.pivot_table(index='department', columns='gender', values='count',aggfunc='sum')\\\n.stack().reset_index().rename({0:'count'},axis=1)\n\n\n\n\n\n\n\n\ndepartment\ngender\ncount\n\n\n\n\n0\nA\nfemale\n108\n\n\n1\nA\nmale\n825\n\n\n2\nB\nfemale\n25\n\n\n3\nB\nmale\n560\n\n\n4\nC\nfemale\n593\n\n\n5\nC\nmale\n325\n\n\n6\nD\nfemale\n375\n\n\n7\nD\nmale\n417\n\n\n8\nE\nfemale\n393\n\n\n9\nE\nmale\n191\n\n\n10\nF\nfemale\n341\n\n\n11\nF\nmale\n373\n\n\n\n\n\n\n\n\ntidydata = df.pivot_table(index='department', columns='gender', values='count',aggfunc='sum')\\\n.stack().reset_index().rename({0:'count'},axis=1)\n\n \nfig = ggplot(tidydata) \ncol = geom_col(aes(x='department',y='count',fill='gender'),position='dodge')\nfig+col\n\n\n\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\nA, B학과가 신체적 역량을 많이 요구로 하거나 하는 학과일 경우 아무래도 기피하겠지…\n은닉변수에 의해 왜곡이 될 수 있다"
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html",
    "href": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html",
    "title": "[문제 풀이] 데이터프레임 : 특정 열의 재가공",
    "section": "",
    "text": "주어진 자료에서 입학년도를 추가하고 싶다면 어떻게 해야 할까?"
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html#사전작업",
    "href": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html#사전작업",
    "title": "[문제 풀이] 데이터프레임 : 특정 열의 재가공",
    "section": "1. 사전작업",
    "text": "1. 사전작업\n\n라이브러리 설치\n\n\nimport numpy as np\nimport pandas as pd\n\n\n자료 받아오기 및 확인\n\n\nnp.random.seed(43052)\natt = np.random.choice(np.arange(10,21)*5,20)\nrep = np.random.choice(np.arange(5,21)*5,20)\nmid = np.random.choice(np.arange(0,21)*5,20)\nfin = np.random.choice(np.arange(0,21)*5,20)\nstudent_id = [ '2023-12362', '2022-12471', '2023-12333', '2022-12400', '2022-12377',\n               '2022-12469', '2023-12314', '2022-12363', '2023-12445', '2023-12336',\n               '2023-12426', '2022-12380', '2023-12422', '2022-12488', '2022-12370',\n               '2023-12443', '2022-12463', '2023-12491', '2023-12340', '2022-12312' ]\ndf = pd.DataFrame({'student_id':student_id,'att':att,'rep':rep,'mid':mid,'fin':fin})\ndf.head()\n\n\n\n\n\n\n\n\nstudent_id\natt\nrep\nmid\nfin\n\n\n\n\n0\n2023-12362\n65\n55\n50\n40\n\n\n1\n2022-12471\n95\n100\n50\n80\n\n\n2\n2023-12333\n65\n90\n60\n30\n\n\n3\n2022-12400\n55\n80\n75\n80\n\n\n4\n2022-12377\n80\n30\n30\n100\n\n\n\n\n\n\n\n\n학번(student_id)에서 앞 네자리에 해당하는 숫자를 빼내어 새로운 열로 저장하면 좋을 것 같다."
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html#가공",
    "href": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html#가공",
    "title": "[문제 풀이] 데이터프레임 : 특정 열의 재가공",
    "section": "2. 가공",
    "text": "2. 가공\n\n아래의 코드는 student_id 열을 '-'를 기준으로 앞뒤로 나누고 첫번째 것을 취한다. 숫자형으로 바꾼 뒤, 리스트로 산출한다.\n\n\n[int(i.split('-')[0]) for i in df.student_id]\n\n[2023,\n 2022,\n 2023,\n 2022,\n 2022,\n 2022,\n 2023,\n 2022,\n 2023,\n 2023,\n 2023,\n 2022,\n 2023,\n 2022,\n 2022,\n 2023,\n 2022,\n 2023,\n 2023,\n 2022]\n\n\n\nlambda를 이용해 가공할 수도 있다.\n\n\nlist(map((lambda x : int(x.split('-')[0])), df.student_id))\n\n[2023,\n 2022,\n 2023,\n 2022,\n 2022,\n 2022,\n 2023,\n 2022,\n 2023,\n 2023,\n 2023,\n 2022,\n 2023,\n 2022,\n 2022,\n 2023,\n 2022,\n 2023,\n 2023,\n 2022]\n\n\n\n첫번째 코드와 똑같은 결과를 산출한다."
  },
  {
    "objectID": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html#출력",
    "href": "posts/Data Visualization/Solution Assemble/특정 열의 재가공.html#출력",
    "title": "[문제 풀이] 데이터프레임 : 특정 열의 재가공",
    "section": "3. 출력",
    "text": "3. 출력\n\n상기의 코드를 df에 새로운 열 year에 삽입한다.\n\n\ndf.assign(year = [int(i.split('-')[0]) for i in df.student_id])\n\n\n\n\n\n\n\n\nstudent_id\natt\nrep\nmid\nfin\nyear\n\n\n\n\n0\n2023-12362\n65\n55\n50\n40\n2023\n\n\n1\n2022-12471\n95\n100\n50\n80\n2022\n\n\n2\n2023-12333\n65\n90\n60\n30\n2023\n\n\n3\n2022-12400\n55\n80\n75\n80\n2022\n\n\n4\n2022-12377\n80\n30\n30\n100\n2022\n\n\n5\n2022-12469\n75\n40\n100\n15\n2022\n\n\n6\n2023-12314\n65\n45\n45\n90\n2023\n\n\n7\n2022-12363\n60\n60\n25\n0\n2022\n\n\n8\n2023-12445\n95\n65\n20\n10\n2023\n\n\n9\n2023-12336\n90\n80\n80\n20\n2023\n\n\n10\n2023-12426\n55\n75\n35\n25\n2023\n\n\n11\n2022-12380\n95\n95\n45\n0\n2022\n\n\n12\n2023-12422\n95\n55\n15\n35\n2023\n\n\n13\n2022-12488\n50\n80\n40\n30\n2022\n\n\n14\n2022-12370\n50\n55\n15\n85\n2022\n\n\n15\n2023-12443\n95\n30\n30\n95\n2023\n\n\n16\n2022-12463\n50\n50\n45\n10\n2022\n\n\n17\n2023-12491\n65\n55\n15\n45\n2023\n\n\n18\n2023-12340\n70\n70\n40\n35\n2023\n\n\n19\n2022-12312\n90\n90\n80\n90\n2022\n\n\n\n\n\n\n\n완료\n-감사합니다-"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "",
    "text": "예측해야 할 유형이 범주형일 때 사용할 수 있는 분석 기법 중 하나인 로지스틱 회귀분석을 해보자!"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#라이브러리-imports",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn.linear_model"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#로지스틱-회귀분석",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#로지스틱-회귀분석",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "2. 로지스틱 회귀분석",
    "text": "2. 로지스틱 회귀분석\n- 연속형 설명변수와 범주형 반응변수와의 관계\n\nA. 성적과 취업 여부 데이터\n\n\n학점과 토익 성적, 그리고 취업 여부를 나타낸 데이터가 있다.(교수님이 만드신 페이크 데이터이다.)\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/MP2023/main/posts/employment.csv')\ndf  ## 페이크 데이터입니다.\n\n\n\n\n\n\n\n\ntoeic\ngpa\nemployment\n\n\n\n\n0\n135\n0.051535\n0\n\n\n1\n935\n0.355496\n0\n\n\n2\n485\n2.228435\n0\n\n\n3\n65\n1.179701\n0\n\n\n4\n445\n3.962356\n1\n\n\n...\n...\n...\n...\n\n\n495\n280\n4.288465\n1\n\n\n496\n310\n2.601212\n1\n\n\n497\n225\n0.042323\n0\n\n\n498\n320\n1.041416\n0\n\n\n499\n375\n3.626883\n1\n\n\n\n\n500 rows × 3 columns\n\n\n\n\nplt.plot(df.toeic[df.employment == 0], df.gpa[df.employment == 0], 'o')\nplt.plot(df.toeic[df.employment == 1], df.gpa[df.employment == 1], 'o')\nplt.show()\n\n\n\n\n- 뭔가 관련성을 찾을 수 있을 것 같지 않은가?~(당연하지 그렇게 만드셨으니까)~\n\n그래서 토익 성적ㆍ학점과 취업여부의 관계를 구하고 싶다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#b.-분석",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#b.-분석",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "### B. 분석",
    "text": "### B. 분석\n\n# step 1\nX = pd.get_dummies(df[['toeic', 'gpa']])\ny = df.employment\n\n# step 2\npredictr = sklearn.linear_model.LogisticRegression()\n\n# step 3\npredictr.fit(X, y)\n\n# step 4\ndf = df.assign(employment_hat = predictr.predict(X))\n\n\nsklearn.linear_model.LogisticRegression()\n\n\ndf\n\n\n\n\n\n\n\n\ntoeic\ngpa\nemployment\nemployment_hat\n\n\n\n\n0\n135\n0.051535\n0\n0\n\n\n1\n935\n0.355496\n0\n0\n\n\n2\n485\n2.228435\n0\n0\n\n\n3\n65\n1.179701\n0\n0\n\n\n4\n445\n3.962356\n1\n1\n\n\n...\n...\n...\n...\n...\n\n\n495\n280\n4.288465\n1\n1\n\n\n496\n310\n2.601212\n1\n0\n\n\n497\n225\n0.042323\n0\n0\n\n\n498\n320\n1.041416\n0\n0\n\n\n499\n375\n3.626883\n1\n1\n\n\n\n\n500 rows × 4 columns\n\n\n\n\n로지스틱 회귀분석으로 적합 및 예측이 완료되었다.\n\n\nC. 평가\n\n\npredictr.score(X, y)\n\n0.882\n\n\n\n이건 y와 y_hat이 동일한 정도를 나타낸다, 나름 잘 맞춘 것 같지 않은가?\n\n- 시각화를 해야 정확히 알 수 있겠지? 현재 예측치와 기존 예측치를 비교해보자.\n\ndf\n\n\n\n\n\n\n\n\ntoeic\ngpa\nemployment\nemployment_hat\n\n\n\n\n0\n135\n0.051535\n0\n0\n\n\n1\n935\n0.355496\n0\n0\n\n\n2\n485\n2.228435\n0\n0\n\n\n3\n65\n1.179701\n0\n0\n\n\n4\n445\n3.962356\n1\n1\n\n\n...\n...\n...\n...\n...\n\n\n495\n280\n4.288465\n1\n1\n\n\n496\n310\n2.601212\n1\n0\n\n\n497\n225\n0.042323\n0\n0\n\n\n498\n320\n1.041416\n0\n0\n\n\n499\n375\n3.626883\n1\n1\n\n\n\n\n500 rows × 4 columns\n\n\n\n\ndf_filtered = df[predictr.predict(X) == 1]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12,5))\n\nfig.suptitle('Constrat Pradiction and Real')\n\nax1.plot(df.toeic, df.gpa, 'o', color = 'C0', label = 'employed')\nax1.plot(df.loc[df.employment == 1].toeic, df.loc[df.employment == 1].gpa, 'o', color = 'C1', label = 'not yet employed')\nax1.set_title('Real Data')\n\nax2.plot(df.toeic, df.gpa, 'o', color = 'C0', label = 'employed')\nax2.plot(df_filtered.toeic, df_filtered.gpa, 'o', color = 'C1', label = 'not yet employed')\nax2.set_title('Estimated Data')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n어때요, 나름 합리적이지 않나요?"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#로지스틱-회귀분석의-실적용",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#로지스틱-회귀분석의-실적용",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "3. 로지스틱 회귀분석의 실적용",
    "text": "3. 로지스틱 회귀분석의 실적용\n\n그럼 타이타닉 데이터에서 로지스틱 회귀분석을 통해 결과를 잘 예측할 수 있지 않을까요?\n\n\ndf_train = pd.read_csv('https://raw.githubusercontent.com/HollyRiver/Machine_learning_in_practice/main/kaggle/titanic/data/train.csv')\ndf_test = pd.read_csv('https://raw.githubusercontent.com/HollyRiver/Machine_learning_in_practice/main/kaggle/titanic/data/test.csv')\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\nkaggle 입문하기에서 보았던 타이타닉 데이터이다.\n- 여기서 반응변수를 쉽게 구하려면…\n\nset(df_train.columns) - set(df_test.columns)\n\n{'Survived'}\n\n\n- 하나만 남는 것을 볼 수 있다.\n\n아! 테스트 셋에 없는 열이니까 저게 y겠구나!"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#a.-늘-해왔던-것처럼-분석하면-안된다",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#a.-늘-해왔던-것처럼-분석하면-안된다",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "### A. 늘 해왔던 것처럼 분석…~(하면 안된다)~",
    "text": "### A. 늘 해왔던 것처럼 분석…~(하면 안된다)~\n\n# step 1\nX = pd.get_dummies(df_train.drop(['Survived'], axis = 1))\ny = df_train.Survived\nXX = pd.get_dummies(df_test)\n\n# step 2\npredictr = sklearn.linear_model.LogisticRegression()\n\n# step 3\npredictr.fit(X, y)\n\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n\n\n\n오류가 나온다.\n\nInput X contains NaN.\n선형 회귀에서 설명변수의 input값에는 결측치가 있으면 안된다!!!\n\ndf_train.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n\n결측치가 있는 열을 제거, 행을 제거, 둘 다. 또는 결측치를 impute해야 하는데…\n\n- 일단 Cabin 열은 결측치가 너무 많으니까 빼자!\n- Name이나 Ticket과 같은 변수는 이성적으로 봤을 때 바로 one-hot 인코딩 하기에는 어색하니 빼자!\n\nlen(set(df_train.Name)), len(set(df_train.Ticket))  ## 다 다름, 거의 다 다름\n\n(891, 681)\n\n\n- Age, Embarked에 포함된 약간의 결측치가 마음에 걸리니까 빼자!!\n\ndropna() 메소드나 preprocessing을 써도 되지만… 그건 나중에 해보자.\n\n\ndf_test.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n\n\n- Fare에 포함된 결측치도 걸린다 -&gt; 빼자! (평균으로 해주는 방법도 있는ㄷ ~나중에 하자고 좀~)\n\nB. 데이터 정리\n\n- 위에서 말한 조건들을 적용해서 데이터를 재가공한 뒤, 로지스틱 회귀를 해보자\n\ndf_train.columns\n\nIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n      dtype='object')\n\n\n\n# step 1\nX = pd.get_dummies(df_train.drop(['Survived', 'Cabin', 'Name', 'Ticket', 'Age', 'Embarked', 'Fare'], axis = 1))\ny = df_train.Survived\nXX = pd.get_dummies(df_test.drop(['Cabin', 'Name', 'Ticket', 'Age', 'Embarked', 'Fare'], axis = 1))\n\n# step 2\npredictr = sklearn.linear_model.LogisticRegression()\n\n# step 3\npredictr.fit(X, y)\n\n# step 4\nXX.assign(Survived = predictr.predict(XX))\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nSibSp\nParch\nSex_female\nSex_male\nSurvived\n\n\n\n\n0\n892\n3\n0\n0\nFalse\nTrue\n0\n\n\n1\n893\n3\n1\n0\nTrue\nFalse\n1\n\n\n2\n894\n2\n0\n0\nFalse\nTrue\n0\n\n\n3\n895\n3\n0\n0\nFalse\nTrue\n0\n\n\n4\n896\n3\n1\n1\nTrue\nFalse\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n413\n1305\n3\n0\n0\nFalse\nTrue\n0\n\n\n414\n1306\n1\n0\n0\nTrue\nFalse\n1\n\n\n415\n1307\n3\n0\n0\nFalse\nTrue\n0\n\n\n416\n1308\n3\n0\n0\nFalse\nTrue\n0\n\n\n417\n1309\n3\n1\n1\nFalse\nTrue\n0\n\n\n\n\n418 rows × 7 columns\n\n\n\n\n정상적으로 잘 수행한 것 같다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#c.-평가-1",
    "href": "posts/Machine Learning in Practice/practice/2. 로지스틱 회귀분석.html#c.-평가-1",
    "title": "범주형 반응변수의 예측 | LogisticRegression()",
    "section": "### C. 평가",
    "text": "### C. 평가\n\npredictr.score(X, y)\n\n0.8002244668911336\n\n\n\n생각보단 잘 한 것 같다.\n\n\nD. 제출\n\n\nyy = pd.DataFrame({'Survived' : predictr.predict(XX)})\nsubmit_df = pd.concat([df_test.PassengerId, yy], axis = 1)\nsubmit_df\n\n#submit_df.to_csv(directory, index = False)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\n\n\n\n\n0\n892\n0\n\n\n1\n893\n1\n\n\n2\n894\n0\n\n\n3\n895\n0\n\n\n4\n896\n1\n\n\n...\n...\n...\n\n\n413\n1305\n0\n\n\n414\n1306\n1\n\n\n415\n1307\n0\n\n\n416\n1308\n0\n\n\n417\n1309\n0\n\n\n\n\n418 rows × 2 columns\n\n\n\n\nkaggle에 제출하고 두근대는 결과는… 0.77511, 그리 높진 않다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html",
    "href": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html",
    "title": "sklearn.linear_model의 작동원리",
    "section": "",
    "text": "LogisticRegression의 작동원리와 sklearn.linear_model에 대해서 자세히 알아보자."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#라이브러리-imports",
    "title": "sklearn.linear_model의 작동원리",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn.linear_model\nimport itertools"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#로지스틱-회귀분석의-원리",
    "href": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#로지스틱-회귀분석의-원리",
    "title": "sklearn.linear_model의 작동원리",
    "section": "2. 로지스틱 회귀분석의 원리",
    "text": "2. 로지스틱 회귀분석의 원리\n\n저번에 봤었던 취업 자료를 가져와보자.\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/MP2023/main/posts/employment.csv')\ndf\n\n\n\n\n\n\n\n\ntoeic\ngpa\nemployment\n\n\n\n\n0\n135\n0.051535\n0\n\n\n1\n935\n0.355496\n0\n\n\n2\n485\n2.228435\n0\n\n\n3\n65\n1.179701\n0\n\n\n4\n445\n3.962356\n1\n\n\n...\n...\n...\n...\n\n\n495\n280\n4.288465\n1\n\n\n496\n310\n2.601212\n1\n\n\n497\n225\n0.042323\n0\n\n\n498\n320\n1.041416\n0\n\n\n499\n375\n3.626883\n1\n\n\n\n\n500 rows × 3 columns\n\n\n\nemployment를 예측하려면…\n\n## 1\nX = df.drop(['employment'], axis = 1)\ny = df.employment\n\n## 2\npredictr = sklearn.linear_model.LogisticRegression()\n\n## 3\npredictr.fit(X, y)\n\npredictr.predict(X)  ## yhat\n\narray([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1], dtype=int64)\n\n\n\n\\(\\hat{y}\\)은 어떻게 나왔는가?\n- 아래 수식에 의하여 나왔음…\n\npredictr.coef_, predictr.intercept_  ## 로지스틱임에도 기울기와 절편이 있다.\n\n(array([[0.00571598, 2.46520018]]), array([-8.45433334]))\n\n\n\nu = X.toeic*0.00571598 + X.gpa*2.46520018 - 8.45433334  ## yhat\nv = 1/(1+np.exp(-u))  # v : 확률같은 거\n\nv\n\n0      0.000523\n1      0.096780\n2      0.453003\n3      0.005627\n4      0.979312\n         ...   \n495    0.976295\n496    0.432939\n497    0.000855\n498    0.016991\n499    0.932777\nLength: 500, dtype: float64\n\n\n\n((v &gt; 0.5) == predictr.predict(X)).mean()  ## v가 0.5보다 클 경우 전부 True였음을 알 수 있음\n\n1.0\n\n\n해당 개체에 처리가 취해질 확률을 구하고, 그것이 0.5보다 크면 처리를 취한다.\n- 만약 적합된 v값을 알고 싶다면…\n\nv[:5].round(3)\n\n0    0.001\n1    0.097\n2    0.453\n3    0.006\n4    0.979\ndtype: float64\n\n\n\npredictr.predict_proba(X)[:5].round(3)\n\narray([[0.999, 0.001],\n       [0.903, 0.097],\n       [0.547, 0.453],\n       [0.994, 0.006],\n       [0.021, 0.979]])\n\n\n\n우측의 값과 일치하는 것을 알 수 있다.(0번째 : 0일 확률, 1번째 : 1일 확률)"
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#predictor-파고들기",
    "href": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#predictor-파고들기",
    "title": "sklearn.linear_model의 작동원리",
    "section": "3. predictor 파고들기",
    "text": "3. predictor 파고들기\n\n아래와 같은 데이터를 가공해서 0~7까지는 train, 8~9까지는 test 셋으로 쓰도록 하자.\n\n\ndf = pd.DataFrame({'X':np.arange(20,30),'y':-np.arange(10)+1+np.random.randn(10)*0.1})\ndf\n\n\n\n\n\n\n\n\nX\ny\n\n\n\n\n0\n20\n0.992487\n\n\n1\n21\n-0.040013\n\n\n2\n22\n-0.984351\n\n\n3\n23\n-2.085536\n\n\n4\n24\n-3.023587\n\n\n5\n25\n-4.287162\n\n\n6\n26\n-5.085849\n\n\n7\n27\n-6.110568\n\n\n8\n28\n-6.798420\n\n\n9\n29\n-8.028488\n\n\n\n\n\n\n\n\ndf_train = df[:8]\ndf_test = df[8:]\n\ndf_train_X = df_train[['X']]\ndf_train_y = df_train[['y']]\ndf_test_X = df_test[['X']]\ndf_test_y = df_test[['y']]\n\n\n## predictor 두 개를 만들도록 리스트 컴프리헨션\npredictors = [sklearn.linear_model.LinearRegression() for i in range(2)]\npredictors\n\n[LinearRegression(), LinearRegression()]\n\n\n\npredictors[0].fit(df_train_X, df_train_y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n첫 번째 predictr에 적합하면 .score, .intercept_, .coef_가 해금된다. 두 번째 predictr에는 적용되지 않는다.~(당연한 거 아님?)~\n\n\nX, y에 들어갈 수 있는 형식\n\n\nXs = {'DataFrame(2d)': df_train_X, \n      'Seires(1d)': df_train_X.X,\n      'ndarray(2d)': np.array(df_train_X),\n      'ndarray(1d)': np.array(df_train_X).reshape(-1),\n      'list(2d)': np.array(df_train_X).tolist(),\n      'list(1d)': np.array(df_train_X).reshape(-1).tolist()}\n\n\nys = {'DataFrame(2d)': df_train_y, \n      'Seires(1d)': df_train_y.y,\n      'ndarray(2d)': np.array(df_train_y),\n      'ndarray(1d)': np.array(df_train_y).reshape(-1),\n      'list(2d)': np.array(df_train_y).tolist(),\n      'list(1d)': np.array(df_train_y).reshape(-1).tolist()}\n\n\ndef test(X,y):\n    try: \n        predictr = sklearn.linear_model.LinearRegression()\n        predictr.fit(X,y)\n        return 'no error'\n    except:\n        return 'error'  ## 예외사항(error) 발생 시의 output\n\n\n가능한 형식들을 모두 모아놨다. 그럼 이것들을 가지고 어떤 녀석이 되는 지 딕셔너리 컴프리헨션을 해보자.\n\n\n{('X='+i,'y='+j): test(Xs[i],ys[j]) for i,j in itertools.product(Xs.keys(),ys.keys())}\n\n## itertools.product() : 원소들의 데카르트 곱을 리스트로 반환.\n## itertools.product('ABCD', repeat = 2)의 경우 크기가 2인 앞의 string 조합을 모두 반환\n\n{('X=DataFrame(2d)', 'y=DataFrame(2d)'): 'no error',\n ('X=DataFrame(2d)', 'y=Seires(1d)'): 'no error',\n ('X=DataFrame(2d)', 'y=ndarray(2d)'): 'no error',\n ('X=DataFrame(2d)', 'y=ndarray(1d)'): 'no error',\n ('X=DataFrame(2d)', 'y=list(2d)'): 'no error',\n ('X=DataFrame(2d)', 'y=list(1d)'): 'no error',\n ('X=Seires(1d)', 'y=DataFrame(2d)'): 'error',\n ('X=Seires(1d)', 'y=Seires(1d)'): 'error',\n ('X=Seires(1d)', 'y=ndarray(2d)'): 'error',\n ('X=Seires(1d)', 'y=ndarray(1d)'): 'error',\n ('X=Seires(1d)', 'y=list(2d)'): 'error',\n ('X=Seires(1d)', 'y=list(1d)'): 'error',\n ('X=ndarray(2d)', 'y=DataFrame(2d)'): 'no error',\n ('X=ndarray(2d)', 'y=Seires(1d)'): 'no error',\n ('X=ndarray(2d)', 'y=ndarray(2d)'): 'no error',\n ('X=ndarray(2d)', 'y=ndarray(1d)'): 'no error',\n ('X=ndarray(2d)', 'y=list(2d)'): 'no error',\n ('X=ndarray(2d)', 'y=list(1d)'): 'no error',\n ('X=ndarray(1d)', 'y=DataFrame(2d)'): 'error',\n ('X=ndarray(1d)', 'y=Seires(1d)'): 'error',\n ('X=ndarray(1d)', 'y=ndarray(2d)'): 'error',\n ('X=ndarray(1d)', 'y=ndarray(1d)'): 'error',\n ('X=ndarray(1d)', 'y=list(2d)'): 'error',\n ('X=ndarray(1d)', 'y=list(1d)'): 'error',\n ('X=list(2d)', 'y=DataFrame(2d)'): 'no error',\n ('X=list(2d)', 'y=Seires(1d)'): 'no error',\n ('X=list(2d)', 'y=ndarray(2d)'): 'no error',\n ('X=list(2d)', 'y=ndarray(1d)'): 'no error',\n ('X=list(2d)', 'y=list(2d)'): 'no error',\n ('X=list(2d)', 'y=list(1d)'): 'no error',\n ('X=list(1d)', 'y=DataFrame(2d)'): 'error',\n ('X=list(1d)', 'y=Seires(1d)'): 'error',\n ('X=list(1d)', 'y=ndarray(2d)'): 'error',\n ('X=list(1d)', 'y=ndarray(1d)'): 'error',\n ('X=list(1d)', 'y=list(2d)'): 'error',\n ('X=list(1d)', 'y=list(1d)'): 'error'}\n\n\n- 결론 | X에는 2차원 데이터만 들어올 수 있지만, y에는 1ㆍ2차원 데이터 모두가 들어올 수 있다.\n- 그리고 일반적으로, X에는 2차원 데이터 배열이 imput되기를 기대하고, y에는 1차원 데이터 배열이 imput되기를 기대한다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#첨언-데이터셋-이름-설정에-대하여",
    "href": "posts/Machine Learning in Practice/practice/4. predictor의 이해.html#첨언-데이터셋-이름-설정에-대하여",
    "title": "sklearn.linear_model의 작동원리",
    "section": "4. 첨언 | 데이터셋 이름 설정에 대하여",
    "text": "4. 첨언 | 데이터셋 이름 설정에 대하여\n\n설명변수와 반응변수, 테스트 셋과 트레인 셋을 부르는 변수 명을 어떻게 설정해야 할 지 나타내겠다.\n\nX : 설명변수 & Train\ny : 반응변수 & Train\nXX : 설명변수 & Test\nyy : 반응변수 & Test\nyhat : predictr.predict(X)\nyyhat : predictr.predict(XX)"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html",
    "title": "Kaggle | 1st practice",
    "section": "",
    "text": "Kaggle의 competition에 대해 차근차근히 알아보고 첫 제출까지 해보도록 하자."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html#라이브러리-imports",
    "title": "Kaggle | 1st practice",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\nimport numpy as np\nimport pandas as pd\n\n\n# 캐글에 있는 노트북을 이용하면 가상 컴퓨터에 세 개의 파일들이 직접 들어온다.\n\ntr = pd.read_csv(\"./data/train.csv\")\ntr.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\ntst = pd.read_csv('./data/test.csv')\ntst.head()\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n892\n3\nKelly, Mr. James\nmale\n34.5\n0\n0\n330911\n7.8292\nNaN\nQ\n\n\n1\n893\n3\nWilkes, Mrs. James (Ellen Needs)\nfemale\n47.0\n1\n0\n363272\n7.0000\nNaN\nS\n\n\n2\n894\n2\nMyles, Mr. Thomas Francis\nmale\n62.0\n0\n0\n240276\n9.6875\nNaN\nQ\n\n\n3\n895\n3\nWirz, Mr. Albert\nmale\n27.0\n0\n0\n315154\n8.6625\nNaN\nS\n\n\n4\n896\n3\nHirvonen, Mrs. Alexander (Helga E Lindqvist)\nfemale\n22.0\n1\n1\n3101298\n12.2875\nNaN\nS"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html#kaggle-competition",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html#kaggle-competition",
    "title": "Kaggle | 1st practice",
    "section": "2. Kaggle Competition",
    "text": "2. Kaggle Competition\n\nA. 데이터 구경\n\n- 데이터의 설명을 빠르게 파악하는 방법\n1. 변수 위주로 kaggle 홈페이지에서 파악\n1. 구글 번역기 사용\n1. ChatGPT 이용\n\nChatGPT가 옳지 않은 소리를 할 때도 있지만, 처음에 데이터에 대한 개념을 빠르게 정리하고자 할 때 도움이 된다.\n변수 이름이 약어로 된 경우가 많은데, 이럴 경우 GPT가 유용하다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html#b.-메뉴",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html#b.-메뉴",
    "title": "Kaggle | 1st practice",
    "section": "### B. 메뉴",
    "text": "### B. 메뉴\n\nOverview(개요)\n\n\n경진대회 주최자가 경진 대회의 배경, 목표, 데이터셋 설명 등을 기술.\n\n\nData(데이터)\n\n\n경진대회에 사용되는 데이터셋에 관한 정보를 찾을 수 있음.\n데이터의 구성, 변수 설명, 예시 데이터 등이 제공되며, 데이터를 이해하고 분석할 수 있는데 필요한 정보들이 포함됨.\n\n\nCode(코드)\n\n\n경진대회 참가자들이 코드를 공유하고 토론하는 공간.\n주로 주어진 문제에 대한 데이터 분석 및 모델링 코드, 데이터 전처리 방법, 모델 학습 등에 관련된 내용이 포함됨.\n\n\nDiscussion(토론)\n\n\n참가자들이 서로 의견을 교환하고 질문을 주고받을 수 있는 공간.\n데이터 분석 방법, 모델 구축 전략, 문제 해결 과정 등에 대한 토론이 이뤄짐.\n\n\nLeaderboard(리더보드)\n\n\n경진대회 참가자들의 모델에 대한 성능 평가 지표와 순위가 나열.\n참가자들의 모델 성능을 비교하고 경쟁 상황을 실시간으로 확인할 수 있음.\n\n\nRule(규칙)\n\n\n참가자들이 따라야 할 규칙, 데이터 사용 작업, 평가 지표 등이 명시되어 있음.\n\n- 체크하면 좋은 것들 * Overview : martic, prize, timeline * Rules : matric, 외부데이터 사용 가능 여부, 하루 최대 제출 수, 최종 선택 가능한 솔루션 수(limit)\n- 대회의 유형 * Getting Started : 상을 제공하지 않음. 튜토리얼 전용. * Featured : 가장 일반적인 유형, 스폰서 회사의 비즈니스 관련 문제이므로 상금이 후함. 솔루션을 소개하는 자세한 리포트를 준비해야 하고 발표할 것을 요구받을 수 있음. * Analytics : 질적 평가. 참가자의 PPT를 제출로 받음."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html#데이터-분석",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html#데이터-분석",
    "title": "Kaggle | 1st practice",
    "section": "3. 데이터 분석",
    "text": "3. 데이터 분석\n\nA.test\n\n- 제출 결과는 리더보드에서 확인 가능\n- 답을 알 수 없고 제출해야 스코어만 확인할 수 있음"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html#b.-train---스스로-풀어보고-채점할-수-있음",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html#b.-train---스스로-풀어보고-채점할-수-있음",
    "title": "Kaggle | 1st practice",
    "section": "### B. train - 스스로 풀어보고 채점할 수 있음",
    "text": "### B. train - 스스로 풀어보고 채점할 수 있음\n- train 데이터를 채점해보자.\n# accuracy의 계산\n\ndf = pd.DataFrame({'surv' : [1,0,1,1,0], 'sex' : ['f','m','f','m','m']})\n\n- surv+열과 sex열에서 sex == f이면 생존(1), 그렇지 않으면 사망(0)이라고 예측\n\ndf.surv\n\n0    1\n1    0\n2    1\n3    1\n4    0\nName: surv, dtype: int64\n\n\n\ndf.sex\n\n0    f\n1    m\n2    f\n3    m\n4    m\nName: sex, dtype: object\n\n\n\n(df.sex == 'f')*1  ## bool이 원소인 list에 1을 곱해준다. f이면 1\n\n0    1\n1    0\n2    1\n3    0\n4    0\nName: sex, dtype: int32\n\n\n- 결과를 정리하면 아래와 같다.\n\npd.DataFrame({'real' : df.surv, 'estimate' : (df.sex == 'f')*1})\n\n\n\n\n\n\n\n\nreal\nestimate\n\n\n\n\n0\n1\n1\n\n\n1\n0\n0\n\n\n2\n1\n1\n\n\n3\n1\n0\n\n\n4\n0\n0\n\n\n\n\n\n\n\n\nprint((df.surv == (df.sex == 'f')*1).sum()/5)\n##print((df.surv == (df.sex == 'f')*1).mean()) ## 동일한 코드\n\n0.8\n\n\n- 실제 train 자료에 접목해서 여성만 생존한다고 하여 accuracy를 구해보자.\n\n(tr.Survived == (tr.Sex == 'female')*1).mean()\n\n0.7867564534231201\n\n\n\n(tr.Survived == (tr.Sex == 'female')).mean()  ## True or False는 0, 1로도 구분되나보다.\n\n0.7867564534231201\n\n\n- 그러면 예측한 데이터프레임을 파일로 만들어서 보내보자.\n\ntst[['PassengerId']].assign(Survived = (tst.Sex == 'female')*1)\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\n\n\n\n\n0\n892\n0\n\n\n1\n893\n1\n\n\n2\n894\n0\n\n\n3\n895\n0\n\n\n4\n896\n1\n\n\n...\n...\n...\n\n\n413\n1305\n0\n\n\n414\n1306\n1\n\n\n415\n1307\n0\n\n\n416\n1308\n0\n\n\n417\n1309\n0\n\n\n\n\n418 rows × 2 columns\n\n\n\n\ntst[['PassengerId']].assign(Survived = (tst.Sex == 'female')*1).to_csv(\"gender_submission.csv\", index = False)\n\n\n해당 파일을 캐글에 업로드하면 submission이 완료된다.\n\n\nindex를 날려줘야 원하는 형식이 된다. (index = False를 하지 않으면 csv파일에 index의 숫자가 같이 저장된다…)"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/1. practice.html#개념",
    "href": "posts/Machine Learning in Practice/Titanic/1. practice.html#개념",
    "title": "Kaggle | 1st practice",
    "section": "4. 개념",
    "text": "4. 개념\n- 캐글 대회는 시험과 비슷하다. * 캐글대회를 여는 사람은 보통 (1) 모의고사문제+답 (training set) (2) 실제시험문제 (test set)를 준다. * (1)의 자료에서는 문제(X,독립변수,설명변수)와 답(y,종속변수,반응변수)이 함께 주어진다. * (2)의 자료에서는 문제(X,독립변수,설명변수)만 주어진다. * 우리는 (1)을 이용하여 문제(X,독립변수,설명변수)와 답(y,종속변수,반응변수)사이의 관계를 찾아내는 훈련을 한다. * 그리고 그 훈련이 잘 되었는지를 평가하기 위해서 (2)를 풀어보고 그 결과를 제출한다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html",
    "title": "Kaggle | Autogluon",
    "section": "",
    "text": "자동 예측 프로그램인 Autogluon을 활용하여 titanic data를 적합해보자!"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#라이브러리-imports",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#라이브러리-imports",
    "title": "Kaggle | Autogluon",
    "section": "1. 라이브러리 imports",
    "text": "1. 라이브러리 imports\n\n#pip install autogluon\n\n\nimport pandas as pd\nimport numpy as np\n\n## tabular(테이블) 형식의 데이터를 다루는 모듈을 다운로드한다.\nfrom autogluon.tabular import TabularDataset, TabularPredictor\n\nC:\\Users\\hollyriver\\anaconda3\\envs\\py\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#분석",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#분석",
    "title": "Kaggle | Autogluon",
    "section": "2. 분석",
    "text": "2. 분석\n\nA. 데이터 입력\n\n\n문제를 받아오는 과정으로 비유할 수 있다.\n\n\ntr = TabularDataset('./data/train.csv')  ## 학습할 데이터\ntst = TabularDataset('./data/test.csv')\n\n## tr = TabularDataset('/kaggle/input/titanic/train.csv')  ## 학습할 데이터\n## tst = TabularDataset('/kaggle/input/titanic/test.csv')\n\n## tr = pd.read_csv('/kaggle/input/titanic/train.csv')\n## tst"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#b.-predictor-생성",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#b.-predictor-생성",
    "title": "Kaggle | Autogluon",
    "section": "### B. Predictor 생성",
    "text": "### B. Predictor 생성\n\n문제를 풀 학생을 생성하는 과정으로 비유할 수 있다.\n\n\npredictr = TabularPredictor('Survived') ## target variable이 들어있는 데이터프레임, 변수 철자는 임의로 틀리게 설정\n\nNo path specified. Models will be saved in: \"AutogluonModels\\ag-20231017_130536\"\n\n\n\npredictr는 뭔데?\n\n\ntype(predictr)\n\nautogluon.tabular.predictor.predictor.TabularPredictor\n\n\n\n대충 autogluon에서의 class인듯.\n\n\nC. 적합(fit)\n\n\n학습 과정에 해당한다.\n\n\npredictr.fit(tr) ## 학생(predictr)에게 문제(tr)를 주어 학습을 시킴(predictr.fit(tr))\n##tr 그 자체로 학습할 수 있는 건 다 시킨다. sklearn의 모델과는 차이가 있음\n\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels\\ag-20231017_130536\"\nAutoGluon Version:  0.8.2\nPython Version:     3.10.13\nOperating System:   Windows\nPlatform Machine:   AMD64\nPlatform Version:   10.0.19045\nDisk Space Avail:   57.71 GB / 255.01 GB (22.6%)\nTrain Data Rows:    891\nTrain Data Columns: 11\nLabel Column: Survived\nPreprocessing data ...\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nSelected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    1930.98 MB\n    Train Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n            Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n        Fitting CategoryFeatureGenerator...\n            Fitting CategoryMemoryMinimizeFeatureGenerator...\n        Fitting TextSpecialFeatureGenerator...\n            Fitting BinnedFeatureGenerator...\n            Fitting DropDuplicatesFeatureGenerator...\n        Fitting TextNgramFeatureGenerator...\n            Fitting CountVectorizer for text features: ['Name']\n            CountVectorizer fit with vocabulary size = 8\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', [])        : 2 | ['Age', 'Fare']\n        ('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n        ('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n        ('object', ['text']) : 1 | ['Name']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n        ('float', [])                       : 2 | ['Age', 'Fare']\n        ('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n        ('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n        ('int', ['bool'])                   : 1 | ['Sex']\n        ('int', ['text_ngram'])             : 9 | ['__nlp__.henry', '__nlp__.john', '__nlp__.master', '__nlp__.miss', '__nlp__.mr', ...]\n    0.3s = Fit runtime\n    11 features in original data used to generate 28 features in processed data.\n    Train Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.36s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n    0.6536   = Validation score   (accuracy)\n    1.83s    = Training   runtime\n    0.22s    = Validation runtime\nFitting model: KNeighborsDist ...\n    0.6536   = Validation score   (accuracy)\n    0.01s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBMXT ...\n    0.8156   = Validation score   (accuracy)\n    1.08s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM ...\n    0.8212   = Validation score   (accuracy)\n    0.43s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestGini ...\n    0.8156   = Validation score   (accuracy)\n    0.64s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: RandomForestEntr ...\n    0.8156   = Validation score   (accuracy)\n    0.54s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: CatBoost ...\n    0.8268   = Validation score   (accuracy)\n    7.47s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: ExtraTreesGini ...\n    0.8156   = Validation score   (accuracy)\n    0.52s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: ExtraTreesEntr ...\n    0.8101   = Validation score   (accuracy)\n    0.52s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: NeuralNetFastAI ...\nNo improvement since epoch 9: early stopping\n    0.8324   = Validation score   (accuracy)\n    3.28s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: XGBoost ...\n    0.8101   = Validation score   (accuracy)\n    1.32s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: NeuralNetTorch ...\n    0.8212   = Validation score   (accuracy)\n    7.74s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge ...\n    0.8324   = Validation score   (accuracy)\n    0.93s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n    0.8324   = Validation score   (accuracy)\n    0.67s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 28.23s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231017_130536\")\n\n\n&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x20df4525d50&gt;\n\n\n학습 완료, 이에 따라 리더보드를 확인한다. (모의고사 채점)\n\npredictr.leaderboard()\n\n                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0         LightGBMLarge   0.832402       0.009000  0.928348                0.009000           0.928348            1       True         13\n1       NeuralNetFastAI   0.832402       0.028001  3.279027                0.028001           3.279027            1       True         10\n2   WeightedEnsemble_L2   0.832402       0.029001  3.949707                0.001000           0.670681            2       True         14\n3              CatBoost   0.826816       0.006002  7.468165                0.006002           7.468165            1       True          7\n4              LightGBM   0.821229       0.006004  0.432719                0.006004           0.432719            1       True          4\n5        NeuralNetTorch   0.821229       0.031999  7.740229                0.031999           7.740229            1       True         12\n6            LightGBMXT   0.815642       0.005002  1.084200                0.005002           1.084200            1       True          3\n7        ExtraTreesGini   0.815642       0.061763  0.516426                0.061763           0.516426            1       True          8\n8      RandomForestEntr   0.815642       0.064586  0.538568                0.064586           0.538568            1       True          6\n9      RandomForestGini   0.815642       0.064718  0.637898                0.064718           0.637898            1       True          5\n10              XGBoost   0.810056       0.013002  1.323482                0.013002           1.323482            1       True         11\n11       ExtraTreesEntr   0.810056       0.062742  0.519159                0.062742           0.519159            1       True          9\n12       KNeighborsDist   0.653631       0.005996  0.012003                0.005996           0.012003            1       True          2\n13       KNeighborsUnif   0.653631       0.215770  1.826697                0.215770           1.826697            1       True          1\n\n\n\n\n\n\n\n\n\nmodel\nscore_val\npred_time_val\nfit_time\npred_time_val_marginal\nfit_time_marginal\nstack_level\ncan_infer\nfit_order\n\n\n\n\n0\nLightGBMLarge\n0.832402\n0.009000\n0.928348\n0.009000\n0.928348\n1\nTrue\n13\n\n\n1\nNeuralNetFastAI\n0.832402\n0.028001\n3.279027\n0.028001\n3.279027\n1\nTrue\n10\n\n\n2\nWeightedEnsemble_L2\n0.832402\n0.029001\n3.949707\n0.001000\n0.670681\n2\nTrue\n14\n\n\n3\nCatBoost\n0.826816\n0.006002\n7.468165\n0.006002\n7.468165\n1\nTrue\n7\n\n\n4\nLightGBM\n0.821229\n0.006004\n0.432719\n0.006004\n0.432719\n1\nTrue\n4\n\n\n5\nNeuralNetTorch\n0.821229\n0.031999\n7.740229\n0.031999\n7.740229\n1\nTrue\n12\n\n\n6\nLightGBMXT\n0.815642\n0.005002\n1.084200\n0.005002\n1.084200\n1\nTrue\n3\n\n\n7\nExtraTreesGini\n0.815642\n0.061763\n0.516426\n0.061763\n0.516426\n1\nTrue\n8\n\n\n8\nRandomForestEntr\n0.815642\n0.064586\n0.538568\n0.064586\n0.538568\n1\nTrue\n6\n\n\n9\nRandomForestGini\n0.815642\n0.064718\n0.637898\n0.064718\n0.637898\n1\nTrue\n5\n\n\n10\nXGBoost\n0.810056\n0.013002\n1.323482\n0.013002\n1.323482\n1\nTrue\n11\n\n\n11\nExtraTreesEntr\n0.810056\n0.062742\n0.519159\n0.062742\n0.519159\n1\nTrue\n9\n\n\n12\nKNeighborsDist\n0.653631\n0.005996\n0.012003\n0.005996\n0.012003\n1\nTrue\n2\n\n\n13\nKNeighborsUnif\n0.653631\n0.215770\n1.826697\n0.215770\n1.826697\n1\nTrue\n1\n\n\n\n\n\n\n\nscore_val이 의미하는 것 * 실제로 predictr가 학습한 것은? &gt; predictor와 train set이 있고, train set에 데이터가 1000개 있다고 하면 해당 데이터를 전부 가용하지 않는다. &gt; * 800개를 사용한다고 하면 200개는 학습하지 않고 답을 맞춰 보는 식이다. &gt; &gt; * 200개는 왜 남겨두지? &gt; &gt; 문제에서 답을 찾는 규칙이 맞는지, 다른 데이터들에 대해서도 일반화시킬 수 있는 지 테스트 해보면 좋을 것 같다. 따라서 나머지 데이터셋에서 분석을 해본다. &gt; &gt; 실제 테스트에서 잘하기 위한 자체적 테스트셋에 해당, 200개의 나머지 테스트용 데이터셋을 validation set이라 일컫는다.\n\n\n\n\ntrain\nval\n\n\n\n\n학생1\n95%\n72%\n\n\n학생2\n80%\n80%\n\n\n…\n…\n…\n\n\n\ntrain(연습문제)만 계속 푼 것 보다, val(모의고사)에서 가장 높은 점수를 받은 것이 유의미할 것.\n\n그러니까 score_val는 모의고사 점수라고 보면 된다.\n\n- 따라서 가장 높은 점수를 받은 WeightedEnsemble_L2모델을 사용해보자.[1]\n\n[1] 처음 실습할 땐 분명 이게 제일 높았었는데…"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#d.-예측predict",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#d.-예측predict",
    "title": "Kaggle | Autogluon",
    "section": "### D. 예측(predict)",
    "text": "### D. 예측(predict)\n\n학습 이후에 문제를 푸는 과정으로 비유.\n\n기존에 했던 분석들\n\n무조건 남자는 죽고, 여자는 사는 형식 0.7x / 0.76555\nRandomForestClassifier를 사용한 형식 0.8x / 0.77511\nRandomForestClassifier에서 하이퍼파라미터를 조정한 형식 0.8x / 0.76555 (트레인 셋에서의 분석에서는 더 높았는데 실제 결과는 오히려 더 낮았다.)\n\n4. WeightedEnsemble_L2모델 사용(알아서 사용하긴 함)\ntrain set을 일단 풀어보자(predict)\n\ntype(tr) ## 처음 보는 것으로 저장되는데 데이터프레임에서 쓸 수 있는 모든 기능들을 다 사용할 수 있다.\n\nautogluon.core.dataset.TabularDataset\n\n\n\ntr.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\n(tr.Survived == predictr.predict(tr)).mean()\n\n0.8810325476992144\n\n\n\n정확도가 0.9349나 된다. 상당히 기대가 되는 부분\n\n\npredictr.predict(tst)\n\n0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n413    0\n414    1\n415    0\n416    0\n417    0\nName: Survived, Length: 418, dtype: int64\n\n\n\ntst.assign(Survived = predictr.predict(tst)).loc[:, ['PassengerId', 'Survived']]\\\n.to_csv('autogluon_submission.csv', index = False)\n\n\n제출 결과 정확도는 0.78947로 지금껏 가장 높은 수치가 나왔다."
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#개선",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#개선",
    "title": "Kaggle | Autogluon",
    "section": "3. 개선",
    "text": "3. 개선\n\n결과를 좀 더 개선할 수 있지 않을까?\n\n\nA. Fsize로 feature engeenering\n\n1) 데이터\n\ntr = TabularDataset('./data/train.csv')  ## 학습할 데이터\ntst = TabularDataset('./data/test.csv')\n\nLoaded data from: ./data/train.csv | Columns = 12 / 12 | Rows = 891 -&gt; 891\nLoaded data from: ./data/test.csv | Columns = 11 / 11 | Rows = 418 -&gt; 418\n\n\n-피쳐 엔지니어링\n\ntr.assign(Fsize = tr.SibSp + tr.Parch)\ntst.assign(Fsize = tst.SibSp + tst.Parch)\n\n#tr.eval('Fsize = SibSp + Parch')\n#tst.eval('Fsize = SibSp + Parch')\n\ntr.head()  ## 원본 데이터를 손상시키지 않음, Fsize 열이 추가되지 않은 것을 알 수 있음\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n2) Predictor 생성\n\npredictr = TabularPredictor(\"Survived\")\n\nNo path specified. Models will be saved in: \"AutogluonModels\\ag-20231017_132447\"\n\n\n3) 적합(fit)\n\npredictr.fit(tr.assign(Fsize = tr.SibSp + tr.Parch))  ## 새로운 데이터셋을 추가하여 학습\n\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels\\ag-20231017_132447\"\nAutoGluon Version:  0.8.2\nPython Version:     3.10.13\nOperating System:   Windows\nPlatform Machine:   AMD64\nPlatform Version:   10.0.19045\nDisk Space Avail:   57.59 GB / 255.01 GB (22.6%)\nTrain Data Rows:    891\nTrain Data Columns: 12\nLabel Column: Survived\nPreprocessing data ...\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nSelected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    1923.41 MB\n    Train Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n            Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n        Fitting CategoryFeatureGenerator...\n            Fitting CategoryMemoryMinimizeFeatureGenerator...\n        Fitting TextSpecialFeatureGenerator...\n            Fitting BinnedFeatureGenerator...\n            Fitting DropDuplicatesFeatureGenerator...\n        Fitting TextNgramFeatureGenerator...\n            Fitting CountVectorizer for text features: ['Name']\n            CountVectorizer fit with vocabulary size = 8\n        Warning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n        Reducing Vectorizer vocab size from 8 to 4 to avoid OOM error\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', [])        : 2 | ['Age', 'Fare']\n        ('int', [])          : 5 | ['PassengerId', 'Pclass', 'SibSp', 'Parch', 'Fsize']\n        ('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n        ('object', ['text']) : 1 | ['Name']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n        ('float', [])                       : 2 | ['Age', 'Fare']\n        ('int', [])                         : 5 | ['PassengerId', 'Pclass', 'SibSp', 'Parch', 'Fsize']\n        ('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n        ('int', ['bool'])                   : 1 | ['Sex']\n        ('int', ['text_ngram'])             : 5 | ['__nlp__.miss', '__nlp__.mr', '__nlp__.mrs', '__nlp__.william', '__nlp__._total_']\n    0.3s = Fit runtime\n    12 features in original data used to generate 25 features in processed data.\n    Train Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.37s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n    0.648    = Validation score   (accuracy)\n    0.01s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: KNeighborsDist ...\n    0.6425   = Validation score   (accuracy)\n    0.01s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBMXT ...\n    0.8268   = Validation score   (accuracy)\n    0.43s    = Training   runtime\n    0.0s     = Validation runtime\nFitting model: LightGBM ...\n    0.8492   = Validation score   (accuracy)\n    0.55s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestGini ...\n    0.7989   = Validation score   (accuracy)\n    0.51s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: RandomForestEntr ...\n    0.8156   = Validation score   (accuracy)\n    0.5s     = Training   runtime\n    0.06s    = Validation runtime\nFitting model: CatBoost ...\n    0.8268   = Validation score   (accuracy)\n    6.8s     = Training   runtime\n    0.01s    = Validation runtime\nFitting model: ExtraTreesGini ...\n    0.8045   = Validation score   (accuracy)\n    0.45s    = Training   runtime\n    0.07s    = Validation runtime\nFitting model: ExtraTreesEntr ...\n    0.8045   = Validation score   (accuracy)\n    0.44s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: NeuralNetFastAI ...\n    0.8324   = Validation score   (accuracy)\n    2.76s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: XGBoost ...\n    0.8212   = Validation score   (accuracy)\n    0.68s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: NeuralNetTorch ...\n    0.8324   = Validation score   (accuracy)\n    9.58s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge ...\n    0.838    = Validation score   (accuracy)\n    0.83s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n    0.8492   = Validation score   (accuracy)\n    0.65s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 25.25s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231017_132447\")\n\n\n&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x20d8e852770&gt;\n\n\n-리더보드 확인\n\npredictr.leaderboard()\n\n                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0              LightGBM   0.849162       0.010999  0.554687                0.010999           0.554687            1       True          4\n1   WeightedEnsemble_L2   0.849162       0.012000  1.201853                0.001000           0.647166            2       True         14\n2         LightGBMLarge   0.837989       0.005001  0.827996                0.005001           0.827996            1       True         13\n3       NeuralNetFastAI   0.832402       0.024005  2.761039                0.024005           2.761039            1       True         10\n4        NeuralNetTorch   0.832402       0.034000  9.577353                0.034000           9.577353            1       True         12\n5            LightGBMXT   0.826816       0.004981  0.426716                0.004981           0.426716            1       True          3\n6              CatBoost   0.826816       0.005996  6.798872                0.005996           6.798872            1       True          7\n7               XGBoost   0.821229       0.008010  0.680577                0.008010           0.680577            1       True         11\n8      RandomForestEntr   0.815642       0.063459  0.504724                0.063459           0.504724            1       True          6\n9        ExtraTreesEntr   0.804469       0.062692  0.443597                0.062692           0.443597            1       True          9\n10       ExtraTreesGini   0.804469       0.065061  0.448723                0.065061           0.448723            1       True          8\n11     RandomForestGini   0.798883       0.064575  0.510397                0.064575           0.510397            1       True          5\n12       KNeighborsUnif   0.648045       0.007998  0.008998                0.007998           0.008998            1       True          1\n13       KNeighborsDist   0.642458       0.007999  0.011001                0.007999           0.011001            1       True          2\n\n\n\n\n\n\n\n\n\nmodel\nscore_val\npred_time_val\nfit_time\npred_time_val_marginal\nfit_time_marginal\nstack_level\ncan_infer\nfit_order\n\n\n\n\n0\nLightGBM\n0.849162\n0.010999\n0.554687\n0.010999\n0.554687\n1\nTrue\n4\n\n\n1\nWeightedEnsemble_L2\n0.849162\n0.012000\n1.201853\n0.001000\n0.647166\n2\nTrue\n14\n\n\n2\nLightGBMLarge\n0.837989\n0.005001\n0.827996\n0.005001\n0.827996\n1\nTrue\n13\n\n\n3\nNeuralNetFastAI\n0.832402\n0.024005\n2.761039\n0.024005\n2.761039\n1\nTrue\n10\n\n\n4\nNeuralNetTorch\n0.832402\n0.034000\n9.577353\n0.034000\n9.577353\n1\nTrue\n12\n\n\n5\nLightGBMXT\n0.826816\n0.004981\n0.426716\n0.004981\n0.426716\n1\nTrue\n3\n\n\n6\nCatBoost\n0.826816\n0.005996\n6.798872\n0.005996\n6.798872\n1\nTrue\n7\n\n\n7\nXGBoost\n0.821229\n0.008010\n0.680577\n0.008010\n0.680577\n1\nTrue\n11\n\n\n8\nRandomForestEntr\n0.815642\n0.063459\n0.504724\n0.063459\n0.504724\n1\nTrue\n6\n\n\n9\nExtraTreesEntr\n0.804469\n0.062692\n0.443597\n0.062692\n0.443597\n1\nTrue\n9\n\n\n10\nExtraTreesGini\n0.804469\n0.065061\n0.448723\n0.065061\n0.448723\n1\nTrue\n8\n\n\n11\nRandomForestGini\n0.798883\n0.064575\n0.510397\n0.064575\n0.510397\n1\nTrue\n5\n\n\n12\nKNeighborsUnif\n0.648045\n0.007998\n0.008998\n0.007998\n0.008998\n1\nTrue\n1\n\n\n13\nKNeighborsDist\n0.642458\n0.007999\n0.011001\n0.007999\n0.011001\n1\nTrue\n2\n\n\n\n\n\n\n\n4) 예측(predict)\n\n(tr.Survived == predictr.predict(tr.assign(Fsize = tr.SibSp + tr.Parch))).mean()\n\n0.9696969696969697\n\n\n\ntst.assign(Survived = predictr.predict(tst.assign(Fsize = tst.SibSp + tst.Parch))).loc[:,['PassengerId','Survived']]\\\n.to_csv(\"autogluon(Fsize)_submission.csv\",index=False)\n\n\n제출 결과 : 점수가 오히려 더 낮아졌음\n\n더 개선해보자"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#b.-fsize-drop",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#b.-fsize-drop",
    "title": "Kaggle | Autogluon",
    "section": "### B. Fsize + drop",
    "text": "### B. Fsize + drop\n1) data\n-피처 엔지니어링 (데이터 불러오는 건 위에서 했으니 일단 생략\n\n_tr = tr.assign(Fsize = lambda _df : _df.SibSp + _df.Parch).drop(['SibSp','Parch'],axis=1)\n_tst = tst.assign(Fsize = tst.SibSp + tst.Parch).drop(['SibSp','Parch'],axis=1)\n\n_tr.head()\n## df.drop(columns = [])\n## df.drop([], axis = 1) columns라고 지정해주지 않으면 디폴트로 행을 삭제하기 때문에\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nTicket\nFare\nCabin\nEmbarked\nFsize\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\nA/5 21171\n7.2500\nNaN\nS\n1\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nfemale\n38.0\nPC 17599\n71.2833\nC85\nC\n1\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n0\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n113803\n53.1000\nC123\nS\n1\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n373450\n8.0500\nNaN\nS\n0\n\n\n\n\n\n\n\n2) Predictor 생성\n\npredictr = TabularPredictor('Survived')\n\nNo path specified. Models will be saved in: \"AutogluonModels\\ag-20231017_132627\"\n\n\n3) 적합(fit)\n\npredictr.fit(_tr)\n\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels\\ag-20231017_132627\"\nAutoGluon Version:  0.8.2\nPython Version:     3.10.13\nOperating System:   Windows\nPlatform Machine:   AMD64\nPlatform Version:   10.0.19045\nDisk Space Avail:   57.56 GB / 255.01 GB (22.6%)\nTrain Data Rows:    891\nTrain Data Columns: 10\nLabel Column: Survived\nPreprocessing data ...\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nSelected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    1899.15 MB\n    Train Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n            Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n        Fitting CategoryFeatureGenerator...\n            Fitting CategoryMemoryMinimizeFeatureGenerator...\n        Fitting TextSpecialFeatureGenerator...\n            Fitting BinnedFeatureGenerator...\n            Fitting DropDuplicatesFeatureGenerator...\n        Fitting TextNgramFeatureGenerator...\n            Fitting CountVectorizer for text features: ['Name']\n            CountVectorizer fit with vocabulary size = 8\n        Warning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n        Reducing Vectorizer vocab size from 8 to 4 to avoid OOM error\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', [])        : 2 | ['Age', 'Fare']\n        ('int', [])          : 3 | ['PassengerId', 'Pclass', 'Fsize']\n        ('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n        ('object', ['text']) : 1 | ['Name']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n        ('float', [])                       : 2 | ['Age', 'Fare']\n        ('int', [])                         : 3 | ['PassengerId', 'Pclass', 'Fsize']\n        ('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n        ('int', ['bool'])                   : 1 | ['Sex']\n        ('int', ['text_ngram'])             : 5 | ['__nlp__.miss', '__nlp__.mr', '__nlp__.mrs', '__nlp__.william', '__nlp__._total_']\n    0.3s = Fit runtime\n    10 features in original data used to generate 23 features in processed data.\n    Train Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.36s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.2, Train Rows: 712, Val Rows: 179\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ...\n    0.6536   = Validation score   (accuracy)\n    0.01s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: KNeighborsDist ...\n    0.648    = Validation score   (accuracy)\n    0.02s    = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMXT ...\n    0.8212   = Validation score   (accuracy)\n    0.47s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: LightGBM ...\n    0.838    = Validation score   (accuracy)\n    0.64s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: RandomForestGini ...\n    0.8045   = Validation score   (accuracy)\n    0.54s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: RandomForestEntr ...\n    0.8101   = Validation score   (accuracy)\n    0.53s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: CatBoost ...\n    0.8324   = Validation score   (accuracy)\n    7.6s     = Training   runtime\n    0.01s    = Validation runtime\nFitting model: ExtraTreesGini ...\n    0.7989   = Validation score   (accuracy)\n    0.53s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: ExtraTreesEntr ...\n    0.8045   = Validation score   (accuracy)\n    0.52s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: NeuralNetFastAI ...\nNo improvement since epoch 9: early stopping\n    0.8268   = Validation score   (accuracy)\n    1.95s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: XGBoost ...\n    0.8268   = Validation score   (accuracy)\n    0.45s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: NeuralNetTorch ...\n    0.8436   = Validation score   (accuracy)\n    10.87s   = Training   runtime\n    0.03s    = Validation runtime\nFitting model: LightGBMLarge ...\n    0.8324   = Validation score   (accuracy)\n    0.82s    = Training   runtime\n    0.01s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n    0.8492   = Validation score   (accuracy)\n    0.65s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 26.66s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231017_132627\")\n\n\n&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x20d858cd060&gt;\n\n\n\npredictr.leaderboard()\n\n                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0   WeightedEnsemble_L2   0.849162       0.043977  12.163954                0.000984           0.653803            2       True         14\n1        NeuralNetTorch   0.843575       0.032010  10.867509                0.032010          10.867509            1       True         12\n2              LightGBM   0.837989       0.010982   0.642641                0.010982           0.642641            1       True          4\n3         LightGBMLarge   0.832402       0.006009   0.821788                0.006009           0.821788            1       True         13\n4              CatBoost   0.832402       0.006051   7.597862                0.006051           7.597862            1       True          7\n5               XGBoost   0.826816       0.013022   0.450137                0.013022           0.450137            1       True         11\n6       NeuralNetFastAI   0.826816       0.017003   1.949074                0.017003           1.949074            1       True         10\n7            LightGBMXT   0.821229       0.006997   0.471555                0.006997           0.471555            1       True          3\n8      RandomForestEntr   0.810056       0.063482   0.526611                0.063482           0.526611            1       True          6\n9      RandomForestGini   0.804469       0.061717   0.544051                0.061717           0.544051            1       True          5\n10       ExtraTreesEntr   0.804469       0.064033   0.519959                0.064033           0.519959            1       True          9\n11       ExtraTreesGini   0.798883       0.064803   0.533057                0.064803           0.533057            1       True          8\n12       KNeighborsUnif   0.653631       0.006997   0.011003                0.006997           0.011003            1       True          1\n13       KNeighborsDist   0.648045       0.031997   0.016009                0.031997           0.016009            1       True          2\n\n\n\n\n\n\n\n\n\nmodel\nscore_val\npred_time_val\nfit_time\npred_time_val_marginal\nfit_time_marginal\nstack_level\ncan_infer\nfit_order\n\n\n\n\n0\nWeightedEnsemble_L2\n0.849162\n0.043977\n12.163954\n0.000984\n0.653803\n2\nTrue\n14\n\n\n1\nNeuralNetTorch\n0.843575\n0.032010\n10.867509\n0.032010\n10.867509\n1\nTrue\n12\n\n\n2\nLightGBM\n0.837989\n0.010982\n0.642641\n0.010982\n0.642641\n1\nTrue\n4\n\n\n3\nLightGBMLarge\n0.832402\n0.006009\n0.821788\n0.006009\n0.821788\n1\nTrue\n13\n\n\n4\nCatBoost\n0.832402\n0.006051\n7.597862\n0.006051\n7.597862\n1\nTrue\n7\n\n\n5\nXGBoost\n0.826816\n0.013022\n0.450137\n0.013022\n0.450137\n1\nTrue\n11\n\n\n6\nNeuralNetFastAI\n0.826816\n0.017003\n1.949074\n0.017003\n1.949074\n1\nTrue\n10\n\n\n7\nLightGBMXT\n0.821229\n0.006997\n0.471555\n0.006997\n0.471555\n1\nTrue\n3\n\n\n8\nRandomForestEntr\n0.810056\n0.063482\n0.526611\n0.063482\n0.526611\n1\nTrue\n6\n\n\n9\nRandomForestGini\n0.804469\n0.061717\n0.544051\n0.061717\n0.544051\n1\nTrue\n5\n\n\n10\nExtraTreesEntr\n0.804469\n0.064033\n0.519959\n0.064033\n0.519959\n1\nTrue\n9\n\n\n11\nExtraTreesGini\n0.798883\n0.064803\n0.533057\n0.064803\n0.533057\n1\nTrue\n8\n\n\n12\nKNeighborsUnif\n0.653631\n0.006997\n0.011003\n0.006997\n0.011003\n1\nTrue\n1\n\n\n13\nKNeighborsDist\n0.648045\n0.031997\n0.016009\n0.031997\n0.016009\n1\nTrue\n2\n\n\n\n\n\n\n\n4) 예측(predict)\n\n(_tr.Survived == predictr.predict(_tr)).mean()\n\n0.9472502805836139\n\n\n\npredictr.predict(_tr)\n\n0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n886    0\n887    1\n888    0\n889    1\n890    0\nName: Survived, Length: 891, dtype: int64\n\n\n\n_tst.assign(Survived = predictr.predict(_tst)).loc[:, ['PassengerId', 'Survived']]\\\n.to_csv('autogluon(Fsize,Drop)_submission.csv', index = False)\n\n\n지금껏 가장 높은 결과가 나왔다!\n\n\n다중 공선성 문제를 개선한 결과라고 볼 수 있지… 음음.\n\n아니, 모자라. 더 개선해!!!"
  },
  {
    "objectID": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#c.-best_quality",
    "href": "posts/Machine Learning in Practice/Titanic/3. autogluon.html#c.-best_quality",
    "title": "Kaggle | Autogluon",
    "section": "### C. best_quality",
    "text": "### C. best_quality\n1) data\n\ntr = TabularDataset(\"./data/train.csv\")\ntst = TabularDataset(\"./data/test.csv\")\n\nLoaded data from: ./data/train.csv | Columns = 12 / 12 | Rows = 891 -&gt; 891\nLoaded data from: ./data/test.csv | Columns = 11 / 11 | Rows = 418 -&gt; 418\n\n\n2) predictor 생성\n\npredictr = TabularPredictor(\"Survived\")\n\nNo path specified. Models will be saved in: \"AutogluonModels\\ag-20231017_132948\"\n\n\n3) 적합(fit)\n\n어떤 자원이 들어가든, 전부 지원해줄 테니 가장 좋은 퀄리티로 산출해!!\n\n\npredictr.fit(tr, presets = 'best_quality') \n\nPresets specified: ['best_quality']\nStack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels\\ag-20231017_132948\"\nAutoGluon Version:  0.8.2\nPython Version:     3.10.13\nOperating System:   Windows\nPlatform Machine:   AMD64\nPlatform Version:   10.0.19045\nDisk Space Avail:   57.53 GB / 255.01 GB (22.6%)\nTrain Data Rows:    891\nTrain Data Columns: 11\nLabel Column: Survived\nPreprocessing data ...\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n    2 unique label values:  [0, 1]\n    If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nSelected class &lt;--&gt; label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n    Available Memory:                    1996.57 MB\n    Train Data (Original)  Memory Usage: 0.31 MB (0.0% of available memory)\n    Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n    Stage 1 Generators:\n        Fitting AsTypeFeatureGenerator...\n            Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n    Stage 2 Generators:\n        Fitting FillNaFeatureGenerator...\n    Stage 3 Generators:\n        Fitting IdentityFeatureGenerator...\n        Fitting CategoryFeatureGenerator...\n            Fitting CategoryMemoryMinimizeFeatureGenerator...\n        Fitting TextSpecialFeatureGenerator...\n            Fitting BinnedFeatureGenerator...\n            Fitting DropDuplicatesFeatureGenerator...\n        Fitting TextNgramFeatureGenerator...\n            Fitting CountVectorizer for text features: ['Name']\n            CountVectorizer fit with vocabulary size = 8\n        Warning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n        Reducing Vectorizer vocab size from 8 to 4 to avoid OOM error\n    Stage 4 Generators:\n        Fitting DropUniqueFeatureGenerator...\n    Stage 5 Generators:\n        Fitting DropDuplicatesFeatureGenerator...\n    Types of features in original data (raw dtype, special dtypes):\n        ('float', [])        : 2 | ['Age', 'Fare']\n        ('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n        ('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n        ('object', ['text']) : 1 | ['Name']\n    Types of features in processed data (raw dtype, special dtypes):\n        ('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n        ('float', [])                       : 2 | ['Age', 'Fare']\n        ('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n        ('int', ['binned', 'text_special']) : 9 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n        ('int', ['bool'])                   : 1 | ['Sex']\n        ('int', ['text_ngram'])             : 5 | ['__nlp__.miss', '__nlp__.mr', '__nlp__.mrs', '__nlp__.william', '__nlp__._total_']\n    0.4s = Fit runtime\n    11 features in original data used to generate 24 features in processed data.\n    Train Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.39s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n    To change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n    'NN_TORCH': {},\n    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n    'CAT': {},\n    'XGB': {},\n    'FASTAI': {},\n    'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif_BAG_L1 ...\n    0.6296   = Validation score   (accuracy)\n    0.01s    = Training   runtime\n    0.02s    = Validation runtime\nFitting model: KNeighborsDist_BAG_L1 ...\n    0.6352   = Validation score   (accuracy)\n    0.01s    = Training   runtime\n    0.0s     = Validation runtime\nFitting model: LightGBMXT_BAG_L1 ...\nWill use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel for TabularPredictor or HPO for MultiModalPredictor. A quick tip is to install via `pip install ray==2.6.3`\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.835    = Validation score   (accuracy)\n    3.82s    = Training   runtime\n    0.05s    = Validation runtime\nFitting model: LightGBM_BAG_L1 ...\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.8373   = Validation score   (accuracy)\n    5.36s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: RandomForestGini_BAG_L1 ...\n    0.8339   = Validation score   (accuracy)\n    0.55s    = Training   runtime\n    0.1s     = Validation runtime\nFitting model: RandomForestEntr_BAG_L1 ...\n    0.8305   = Validation score   (accuracy)\n    0.54s    = Training   runtime\n    0.1s     = Validation runtime\nFitting model: CatBoost_BAG_L1 ...\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.8552   = Validation score   (accuracy)\n    72.17s   = Training   runtime\n    0.04s    = Validation runtime\nFitting model: ExtraTreesGini_BAG_L1 ...\n    0.8238   = Validation score   (accuracy)\n    0.51s    = Training   runtime\n    0.11s    = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L1 ...\n    0.8316   = Validation score   (accuracy)\n    0.49s    = Training   runtime\n    0.1s     = Validation runtime\nFitting model: NeuralNetFastAI_BAG_L1 ...\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\nNo improvement since epoch 7: early stopping\nNo improvement since epoch 6: early stopping\nNo improvement since epoch 7: early stopping\n    0.853    = Validation score   (accuracy)\n    20.42s   = Training   runtime\n    0.13s    = Validation runtime\nFitting model: XGBoost_BAG_L1 ...\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.8373   = Validation score   (accuracy)\n    3.6s     = Training   runtime\n    0.06s    = Validation runtime\nFitting model: NeuralNetTorch_BAG_L1 ...\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.8462   = Validation score   (accuracy)\n    68.5s    = Training   runtime\n    0.19s    = Validation runtime\nFitting model: LightGBMLarge_BAG_L1 ...\n    Fitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n    0.8429   = Validation score   (accuracy)\n    8.68s    = Training   runtime\n    0.06s    = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n    0.8552   = Validation score   (accuracy)\n    0.84s    = Training   runtime\n    0.0s     = Validation runtime\nAutoGluon training complete, total runtime = 188.35s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231017_132948\")\n\n\n&lt;autogluon.tabular.predictor.predictor.TabularPredictor at 0x20d90435000&gt;\n\n\n\n대신 시간이 상당히 오래 걸린다…\n\n- 리더보드 확인\n\npredictr.leaderboard()\n\n                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0           CatBoost_BAG_L1   0.855219       0.036927  72.167391                0.036927          72.167391            1       True          7\n1       WeightedEnsemble_L2   0.855219       0.038929  73.009209                0.002002           0.841818            2       True         14\n2    NeuralNetFastAI_BAG_L1   0.852974       0.130997  20.415231                0.130997          20.415231            1       True         10\n3     NeuralNetTorch_BAG_L1   0.846240       0.194014  68.497755                0.194014          68.497755            1       True         12\n4      LightGBMLarge_BAG_L1   0.842873       0.056998   8.680638                0.056998           8.680638            1       True         13\n5            XGBoost_BAG_L1   0.837262       0.055978   3.598592                0.055978           3.598592            1       True         11\n6           LightGBM_BAG_L1   0.837262       0.061885   5.357185                0.061885           5.357185            1       True          4\n7         LightGBMXT_BAG_L1   0.835017       0.049997   3.816595                0.049997           3.816595            1       True          3\n8   RandomForestGini_BAG_L1   0.833895       0.096996   0.553528                0.096996           0.553528            1       True          5\n9     ExtraTreesEntr_BAG_L1   0.831650       0.095051   0.494969                0.095051           0.494969            1       True          9\n10  RandomForestEntr_BAG_L1   0.830527       0.101071   0.535026                0.101071           0.535026            1       True          6\n11    ExtraTreesGini_BAG_L1   0.823793       0.111044   0.513969                0.111044           0.513969            1       True          8\n12    KNeighborsDist_BAG_L1   0.635241       0.004996   0.006006                0.004996           0.006006            1       True          2\n13    KNeighborsUnif_BAG_L1   0.629630       0.015998   0.005992                0.015998           0.005992            1       True          1\n\n\n\n\n\n\n\n\n\nmodel\nscore_val\npred_time_val\nfit_time\npred_time_val_marginal\nfit_time_marginal\nstack_level\ncan_infer\nfit_order\n\n\n\n\n0\nCatBoost_BAG_L1\n0.855219\n0.036927\n72.167391\n0.036927\n72.167391\n1\nTrue\n7\n\n\n1\nWeightedEnsemble_L2\n0.855219\n0.038929\n73.009209\n0.002002\n0.841818\n2\nTrue\n14\n\n\n2\nNeuralNetFastAI_BAG_L1\n0.852974\n0.130997\n20.415231\n0.130997\n20.415231\n1\nTrue\n10\n\n\n3\nNeuralNetTorch_BAG_L1\n0.846240\n0.194014\n68.497755\n0.194014\n68.497755\n1\nTrue\n12\n\n\n4\nLightGBMLarge_BAG_L1\n0.842873\n0.056998\n8.680638\n0.056998\n8.680638\n1\nTrue\n13\n\n\n5\nXGBoost_BAG_L1\n0.837262\n0.055978\n3.598592\n0.055978\n3.598592\n1\nTrue\n11\n\n\n6\nLightGBM_BAG_L1\n0.837262\n0.061885\n5.357185\n0.061885\n5.357185\n1\nTrue\n4\n\n\n7\nLightGBMXT_BAG_L1\n0.835017\n0.049997\n3.816595\n0.049997\n3.816595\n1\nTrue\n3\n\n\n8\nRandomForestGini_BAG_L1\n0.833895\n0.096996\n0.553528\n0.096996\n0.553528\n1\nTrue\n5\n\n\n9\nExtraTreesEntr_BAG_L1\n0.831650\n0.095051\n0.494969\n0.095051\n0.494969\n1\nTrue\n9\n\n\n10\nRandomForestEntr_BAG_L1\n0.830527\n0.101071\n0.535026\n0.101071\n0.535026\n1\nTrue\n6\n\n\n11\nExtraTreesGini_BAG_L1\n0.823793\n0.111044\n0.513969\n0.111044\n0.513969\n1\nTrue\n8\n\n\n12\nKNeighborsDist_BAG_L1\n0.635241\n0.004996\n0.006006\n0.004996\n0.006006\n1\nTrue\n2\n\n\n13\nKNeighborsUnif_BAG_L1\n0.629630\n0.015998\n0.005992\n0.015998\n0.005992\n1\nTrue\n1\n\n\n\n\n\n\n\n4) 예측(predict)\n\n(tr.Survived == predictr.predict(tr)).mean()\n\n0.9158249158249159\n\n\n\ntst[['PassengerId']].assign(Survived = predictr.predict(tst))\\\n.to_csv(\"autogluon(best_quality)_submission.csv\",index=False)\n\n\n하지만 결과는 확실하다. 무려 0.813…"
  },
  {
    "objectID": "posts/R Programming/Economatrics_hw1.html",
    "href": "posts/R Programming/Economatrics_hw1.html",
    "title": "강신성(202014107)_hw1.html",
    "section": "",
    "text": "수열문제 a.\n\nx = 0   ## x와 i의 초기값 설정\ni = 0\n\nwhile (i &lt;= 21) {\n  x = x + 1/(2 * (-2)^(i))    ## 분모에 (-2)^i 제곱을 하여 부호 변경\n  i = i + 1\n  \n  if (i == 20) {    ## 반복문이 종료될 때 결과값(x) 산출\n    print(x)    ## output : 0.333333\n  }\n}\n\n[1] 0.333333\n\n\n\n\n수열문제 b.\n\ny = 1   ## y와 i의 초기값 설정\nj = 1\n\nwhile (j &lt;= 19) {\n  y = y + 1/((j+1)*j)\n  j = j + 1\n  \n  if (j == 19) {\n    print(y)    ## output : 1.967368\n  }\n}\n\n[1] 1.947368"
  }
]